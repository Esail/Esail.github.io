<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="决策树,">





  <link rel="alternate" href="/atom.xml" title="Yifan Guo Personal Blog" type="application/atom+xml">






<meta name="description" content="[TOC] 决策树概述 用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布 决策树场景 决策树是通过不停缩小猜测的范围，最后得到答案 如下图：  决策树的定义 决策树由节点node和有向边(directed edge)组成 node有两类，内部节点和叶节点，内部节点表示一个特征(feature), 叶节点表示一个label 决策树的预测 当需要使用">
<meta name="keywords" content="决策树">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树">
<meta property="og:url" content="http://www.yifanguo.top/2018/12/25/决策树/index.html">
<meta property="og:site_name" content="Yifan Guo Personal Blog">
<meta property="og:description" content="[TOC] 决策树概述 用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布 决策树场景 决策树是通过不停缩小猜测的范围，最后得到答案 如下图：  决策树的定义 决策树由节点node和有向边(directed edge)组成 node有两类，内部节点和叶节点，内部节点表示一个特征(feature), 叶节点表示一个label 决策树的预测 当需要使用">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/dt.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/entropy.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf_2.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/boosting.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/bagging.png">
<meta property="og:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/ada.png">
<meta property="og:updated_time" content="2018-12-26T05:17:24.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="决策树">
<meta name="twitter:description" content="[TOC] 决策树概述 用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布 决策树场景 决策树是通过不停缩小猜测的范围，最后得到答案 如下图：  决策树的定义 决策树由节点node和有向边(directed edge)组成 node有两类，内部节点和叶节点，内部节点表示一个特征(feature), 叶节点表示一个label 决策树的预测 当需要使用">
<meta name="twitter:image" content="http://www.yifanguo.top/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/dt.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.yifanguo.top/2018/12/25/决策树/">





  <title>决策树 | Yifan Guo Personal Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/esail" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yifan Guo Personal Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-http">
          <a href="/http/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            http
          </a>
        </li>
      
        
        <li class="menu-item menu-item-netty">
          <a href="/netty/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            netty
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yifanguo.top/2018/12/25/决策树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yifan Guo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/timg.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yifan Guo Personal Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">决策树</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-25T10:22:20+08:00">
                2018-12-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  12
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<h1><span id="决策树概述">决策树概述</span></h1>
<p>用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布</p>
<h1><span id="决策树场景">决策树场景</span></h1>
<p>决策树是通过不停缩小猜测的范围，最后得到答案</p>
<p>如下图：</p>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/dt.png" alt="dt"></p>
<h1><span id="决策树的定义">决策树的定义</span></h1>
<p>决策树由节点node和有向边(directed edge)组成</p>
<p>node有两类，内部节点和叶节点，内部节点表示一个特征(feature), 叶节点表示一个label</p>
<h1><span id="决策树的预测">决策树的预测</span></h1>
<p>当需要使用决策树对一个目标进行分类时，从根节点开始，对目标的某一特征开始进行测试，</p>
<p>根据测试结果将该目标分配到某一子节点。每一个子节点对应着该特征的一个取值。dfs到达叶节点</p>
<p>选择该叶节点作为预测label</p>
<h1><span id="决策树的术语">决策树的术语</span></h1>
<p>信息熵又名信息增益</p>
<p>熵： entropy 指的是体系的混乱程度</p>
<p>信息论：information theory 是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。例如：火柴有序放在火柴盒里，熵值很低，相反，熵值很高。</p>
<p>信息增益：information gain 在划分数据集前后信息发生的变化称为信息增益</p>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/entropy.png" alt="entropy"></p>
<h1><span id="决策树的种类">决策树的种类</span></h1>
<p>针对如何生成决策树一般有三类：</p>
<p>https://zhuanlan.zhihu.com/p/30059442</p>
<p>https://blog.csdn.net/xbinworld/article/details/44660339</p>
<h2><span id="id3">ID3</span></h2>
<p>会overfitting 因为id3会尝试将错误率通过分割非常细来达到0</p>
<h2><span id="c45">C4.5</span></h2>
<p>c4.5对ID3进行了改进，C4.5中，增加的熵要除以分割太细的代价，这个比值叫做信息增益率，显然分割太细分母增加，信息增益率会降低。除此之外，其他的原理和ID3相同</p>
<h2><span id="cart">CART</span></h2>
<p>分类回归树</p>
<p>CART只能将一个父节点分为2个子节点。CART用GINI指数来决定如何分裂</p>
<p>GINI指数：总体内包含的类别越杂乱，GINI指数就越大（跟熵的概念很相似）</p>
<p>选择GINI指数最小的开始分</p>
<p>CART还是一个回归树，回归解析用来决定分布是否终止。理想地说每一个叶节点里都只有一个类别时分类应该停止，但是很多数据并不容易完全划分，或者完全划分需要很多次分裂，必然造成很长的运行时间，所以CART可以对每个叶节点里的数据分析其均值方差，当方差小于一定值可以终止分裂，以换取计算成本的降低。</p>
<p>CART和ID3一样，存在偏向细小分割，即过度学习（过度拟合的问题），为了解决这一问题，对特别长的树进行剪枝处理，直接剪掉。</p>
<h1><span id="随机森林">随机森林</span></h1>
<h2><span id="概述">概述</span></h2>
<p>首先，从原始的数据集中采取有放回的抽样，构造子数据集，子数据集的数据量是和原始数据集相同的。不同子数据集的元素可以重复，同一个子数据集中的元素也可以重复。第二，利用子数据集来构建子决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。最后，如果有了新的数据需要通过随机森林得到分类结果，就可以通过对子决策树的判断结果的投票，得到随机森林的输出结果了。如下图，假设随机森林中有3棵子决策树，2棵子树的分类结果是A类，1棵子树的分类结果是B类，那么随机森林的分类结果就是A类。</p>
<h2><span id="例子">例子</span></h2>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf.png" alt="rf"></p>
<p>待选特征的随机选取：
与数据集的随机选取类似，随机森林中的子树的每一个分裂过程并未用到所有的待选特征，而是从所有的待选特征中随机选取一定的特征，之后再在随机选取的特征中选取最优的特征。这样能够使得随机森林中的决策树都能够彼此不同，提升系统的多样性，从而提升分类性能。</p>
<p>下图中，蓝色的方块代表所有可以被选择的特征，也就是目前的待选特征。黄色的方块是分裂特征。左边是一棵决策树的特征选取过程，通过在待选特征中选取最优的分裂特征（别忘了前文提到的ID3算法，C4.5算法，CART算法等等），完成分裂。右边是一个随机森林中的子树的特征选取过程。</p>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf_2.png" alt="rf_2"></p>
<p>http://www.cnblogs.com/pinard/p/6131423.html</p>
<p>#Ensemble learning集成学习</p>
<h2><span id="集成学习概念">集成学习概念</span></h2>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph TD;</span><br><span class="line">    个体学习器A1--&gt;强学习器B;</span><br><span class="line">    个体学习器A2--&gt;强学习器B;</span><br><span class="line">    个体学习器A3--&gt;强学习器B;</span><br><span class="line">    个体学习器A4--&gt;强学习器B;</span><br></pre></td></tr></table></figure></p>
<p>集成学习是通过训练出若干个个体学习器，通过一定的结合策略，最终形成一个强学习器，达到<strong>博采众长</strong>的目的</p>
<h2><span id="集成学习需要解决的两个问题">集成学习需要解决的两个问题</span></h2>
<p>1.如何得到若干个个体学习器</p>
<p>2.如何选择一种结合策略，将这些个体学习器集成一个强学习器</p>
<h2><span id="个体学习器">个体学习器</span></h2>
<p>个体学习器强依赖关系，需要串行--boosting算法</p>
<p>个体学习器不存在强依赖关系，可以并行—bagging和rf</p>
<h2><span id="boosting">Boosting</span></h2>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/boosting.png" alt="boosting"></p>
<p>从图中可以看出，Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。</p>
<p>Boosting系列算法里最著名算法主要有AdaBoost算法和提升树(boosting tree)系列算法。提升树系列算法里面应用最广泛的是梯度提升树(Gradient Boosting Tree)</p>
<h2><span id="bagging">Bagging</span></h2>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/bagging.png" alt="bagging"></p>
<p>从上图可以看出，bagging的个体弱学习器的训练集是通过随机采样得到的。通过T次的随机采样，我们就可以得到T个采样集，对于这T个采样集，我们可以分别独立的训练出T个弱学习器，再对这T个弱学习器通过集合策略来得到最终的强学习器。</p>
<p>对于这里的随机采样有必要做进一步的介绍，这里一般采用的是自助采样法（Bootstap sampling）,即对于m个样本的原始训练集，我们每次先随机采集一个样本放入采样集，接着把该样本放回，也就是说下次采样时该样本仍有可能被采集到，这样采集m次，最终可以得到m个样本的采样集，由于是随机采样，这样每次的采样集是和原始训练集不同的，和其他采样集也是不同的，这样得到多个不同的弱学习器。</p>
<p>随机森林是bagging的一个特化进阶版，所谓的特化是因为随机森林的弱学习器都是决策树。所谓的进阶是随机森林在bagging的样本随机采样基础上，又加上了特征的随机选择，其基本思想没有脱离bagging的范畴。</p>
<h2><span id="结合策略">结合策略</span></h2>
<h3><span id="平均法">平均法</span></h3>
<p>最终的预测是各个弱学习器的平均值</p>
<p>如果弱学习器有权重，则是一个加权平均</p>
<h3><span id="投票法">投票法</span></h3>
<p>投票法可以有少数服从多数法，绝对票数，以及加权投票</p>
<h3><span id="学习法">学习法</span></h3>
<p>上两节的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，也就是说，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。</p>
<p>在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。</p>
<h2><span id="boosting算法需要解决的问题">boosting算法需要解决的问题</span></h2>
<ol>
<li>如何计算学习误差率e</li>
<li>如何得到弱学习器权重系数a</li>
<li>如何更新样本权重d</li>
<li>使用何种结合策略</li>
</ol>
<p>#Adaboosting</p>
<ul>
<li>
<p>样本权重</p>
<ul>
<li>
<p>没有先验知识的情况下，初始的分布为等概分布，即计算集如果有N个样本，每个样本的分布概率为1/N</p>
</li>
<li>
<p>m每次循环后提高误分样本的分布概率，误分样本在训练集中所占的权重增大，使得下一次循环的弱学习器能够集中力量对这些误分样本进行判断</p>
</li>
<li>
<p>准确率越高的弱学习机权重较高</p>
</li>
</ul>
</li>
</ul>
<h2><span id="m1算法">M1算法</span></h2>
<p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/ada.png" alt="ada"></p>
<h2><span id="前向逐步递增">前向逐步递增</span></h2>
<h2><span id="优缺点">优缺点</span></h2>
<p>Adaboost的主要优点有：</p>
<p>1）Adaboost作为分类器时，分类精度很高</p>
<p>2）在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。</p>
<p>3）作为简单的二元分类器时，构造简单，结果可理解。</p>
<p>4）不容易发生过拟合</p>
<p>Adaboost的主要缺点有：</p>
<p>1）对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。</p>
<h1><span id="gbdtgradient-boosting-decision-tree">GBDT（Gradient Boosting Decision Tree)</span></h1>
<p>GBDT也是集成学习Boosting家族的成员，但是却和传统的Adaboost有很大的不同。回顾下Adaboost，我们是利用前一轮迭代弱学习器的误差率来更新训练集的权重，这样一轮轮的迭代下去。GBDT也是迭代，使用了前向分布算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。</p>
<p>在GBDT的迭代中，假设我们前一轮迭代得到的强学习器是ft−1(x)ft−1(x), 损失函数是L(y,ft−1(x))L(y,ft−1(x)), 我们本轮迭代的目标是找到一个CART回归树模型的弱学习器ht(x)ht(x)，让本轮的损失函数L(y,ft(x)=L(y,ft−1(x)+ht(x))L(y,ft(x)=L(y,ft−1(x)+ht(x))最小。也就是说，本轮迭代找到决策树，要让样本的损失尽量变得更小。</p>
<p>GBDT的思想可以用一个通俗的例子解释，假如有个人30岁，我们首先用20岁去拟合，发现损失有10岁，这时我们用6岁去拟合剩下的损失，发现差距还有4岁，第三轮我们用3岁拟合剩下的差距，差距就只有一岁了。如果我们的迭代轮数还没有完，可以继续迭代下面，每一轮迭代，拟合的岁数误差都会减小。</p>
<p>从上面的例子看这个思想还是蛮简单的，但是有个问题是这个损失的拟合不好度量，损失函数各种各样，怎么找到一种通用的拟合方法呢？</p>
<h2><span id="gbdt的负梯度拟合">GBDT的负梯度拟合</span></h2>
<h2><span id="gbdt回归算法">GBDT回归算法</span></h2>
<p>GBDT主要的优点有：</p>
<ol>
<li>
<p>可以灵活处理各种类型的数据，包括连续值和离散值。</p>
</li>
<li>
<p>在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。</p>
</li>
</ol>
<p>3）使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</p>
<p>GBDT的主要缺点有：</p>
<p>1)由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行</p>
<h2><span id="gradient-boosting">Gradient Boosting</span></h2>
<p>用一个弱学习器近似负梯度</p>
<h1><span id="xgboost">XGBoost</span></h1>
<h1><span id="有用的资料">有用的资料</span></h1>
<p>http://codewithzhangyi.com/2018/06/01/XGBOOST%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</p>
<p>https://zxth93.github.io/2017/09/29/XGBoost%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/index.html</p>
<p>https://www.bilibili.com/video/av26088803?from=search&amp;seid=4150235187907599632</p>
<p>https://www.bilibili.com/video/av24476653?from=search&amp;seid=11865982546931463007 （非常好的视频，不过适合有基础的看）</p>
<p>https://www.jiqizhixin.com/articles/2018-03-18-4 (非常好的讲xgboost的直方图和lgb的GOSS算法对比)</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/决策树/" rel="tag"># 决策树</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/24/ml-list/" rel="next" title="ml_list">
                <i class="fa fa-chevron-left"></i> ml_list
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/26/ctr/" rel="prev" title="ctr">
                ctr <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/timg.jpeg" alt="Yifan Guo">
            
              <p class="site-author-name" itemprop="name">Yifan Guo</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">65</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">37</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">决策树概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">决策树场景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">决策树的定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">决策树的预测</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">决策树的术语</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">决策树的种类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">6.1.</span> <span class="nav-text">ID3</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">6.2.</span> <span class="nav-text">C4.5</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">6.3.</span> <span class="nav-text">CART</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">随机森林</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.2.</span> <span class="nav-text">例子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.3.</span> <span class="nav-text">集成学习概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.4.</span> <span class="nav-text">集成学习需要解决的两个问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.5.</span> <span class="nav-text">个体学习器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.6.</span> <span class="nav-text">Boosting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.7.</span> <span class="nav-text">Bagging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.8.</span> <span class="nav-text">结合策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.8.1.</span> <span class="nav-text">平均法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.8.2.</span> <span class="nav-text">投票法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.8.3.</span> <span class="nav-text">学习法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.9.</span> <span class="nav-text">boosting算法需要解决的问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.10.</span> <span class="nav-text">M1算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.11.</span> <span class="nav-text">前向逐步递增</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.12.</span> <span class="nav-text">优缺点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">GBDT（Gradient Boosting Decision Tree)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">8.1.</span> <span class="nav-text">GBDT的负梯度拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">8.2.</span> <span class="nav-text">GBDT回归算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">8.3.</span> <span class="nav-text">Gradient Boosting</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">XGBoost</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">10.</span> <span class="nav-text">有用的资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yifan Guo</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">72.7k</span>
  

  
  <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize("");
    }
  </script>
  

</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.yifanguo.top/2018/12/25/决策树/';
          this.page.identifier = '2018/12/25/决策树/';
          this.page.title = '决策树';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://www-yifanguo-top.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

  
</body>
</html>
