<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="Yifan Guo Personal Blog" type="application/atom+xml" />






<meta name="description" content="[toc] Machine learning- crash course Framing Label A label is the thing we&apos;re predicting—the y variable in simple linear regression  label is the true thing we are predicting: y  the y variable in bas">
<meta property="og:type" content="article">
<meta property="og:title" content="Yifan Guo Personal Blog">
<meta property="og:url" content="http://www.yifanguo.top/2018/08/22/Machine learning- crash course/index.html">
<meta property="og:site_name" content="Yifan Guo Personal Blog">
<meta property="og:description" content="[toc] Machine learning- crash course Framing Label A label is the thing we&apos;re predicting—the y variable in simple linear regression  label is the true thing we are predicting: y  the y variable in bas">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-08-22T10:32:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yifan Guo Personal Blog">
<meta name="twitter:description" content="[toc] Machine learning- crash course Framing Label A label is the thing we&apos;re predicting—the y variable in simple linear regression  label is the true thing we are predicting: y  the y variable in bas">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.yifanguo.top/2018/08/22/Machine learning- crash course/"/>





  <title> | Yifan Guo Personal Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/esail" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yifan Guo Personal Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-http">
          <a href="/http/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            http
          </a>
        </li>
      
        
        <li class="menu-item menu-item-netty">
          <a href="/netty/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            netty
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.yifanguo.top/2018/08/22/Machine learning- crash course/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yifan Guo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/timg.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yifan Guo Personal Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline"></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-22T18:32:08+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[toc]</p>
<h1><span id="machine-learning-crash-course">Machine learning- crash course</span></h1>
<h2><span id="framing">Framing</span></h2>
<h3><span id="label">Label</span></h3>
<p>A label is the thing we're predicting—the y variable in simple linear regression</p>
<ul>
<li>label is the true thing we are predicting: y
<ul>
<li>the y variable in basic linear regression</li>
</ul>
</li>
<li>Labeled example has {features, label} (x,y)
<ul>
<li>used to train the model</li>
</ul>
</li>
<li>unlabeled example has {features, ?} :(x,?)
<ul>
<li>used for making predictions on new data</li>
</ul>
</li>
<li>model maps examples to predicted labels&quot; y'
<ul>
<li>defined by internal parameters, which are learned</li>
</ul>
</li>
</ul>
<h3><span id="supervised-machine-learning">(supervised) machine learning</span></h3>
<p>ML systems learn how to combine input to produce useful predictions on never-before-seen data.</p>
<h3><span id="models">Models</span></h3>
<p>Training means creating or learning the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.</p>
<p>Inference means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y'). For example, during inference, you can predict medianHouseValue for new unlabeled examples.</p>
<h3><span id="regression-vs-classification">Regression vs. classification</span></h3>
<p>A regression model predicts continuous values. For example, regression models make predictions that answer questions like the following:</p>
<p>What is the value of a house in California?</p>
<p>What is the probability that a user will click on this ad?</p>
<p>A classification model predicts discrete values. For example, classification models make predictions that answer questions like the following:</p>
<p>Is a given email message spam or not spam?</p>
<p>Is this an image of a dog, a cat, or a hamster?</p>
<h3><span id="feature">feature</span></h3>
<p>good fetures are concrete and quantifiable</p>
<h2><span id="empirical-risk-minimization-erm">empirical risk minimization ERM</span></h2>
<p>Loss is the penalty for a bad prediction</p>
<h2><span id="squared-loss">squared loss</span></h2>
<p>squared loss (also known as L2 loss)</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">= the square of the difference between the label and the prediction</span><br><span class="line">  = (observation - prediction(x))2</span><br><span class="line">  = (y - y&apos;)2</span><br></pre></td></tr></table></figure></p>
<h2><span id="mean-square-error-mse">Mean square error MSE</span></h2>
<p>Mean square error (MSE) is the average squared loss per example over the whole dataset. To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples:</p>
<h1><span id="reducing-loss">Reducing loss</span></h1>
<h2><span id="coverged-收敛">coverged 收敛</span></h2>
<p>Usually, you iterate until overall loss stops changing or at least changes extremely slowly. When that happens, we say that the model has converged.</p>
<h3><span id="convex-凸面的">convex 凸面的</span></h3>
<p>Regression problems yield convex loss vs weight plots</p>
<p>Convex problems have only one minimum; that is, only one place where the slope is exactly 0. That minimum is where the loss function converges.</p>
<h2><span id="gradient-descent">gradient descent</span></h2>
<p>the gradient is a vector of partial derivatives with respect to the weights</p>
<p>In machine learning, gradients are used in gradient descent. We often have a loss function of many variables that we are trying to minimize, and we try to do this by following the negative of the gradient of the function.</p>
<h2><span id="learning-rate">Learning rate</span></h2>
<p>As noted, the gradient vector has both a direction and a magnitude(大小）</p>
<p>Gradient descent algorithms multiply the gradient by a scalar known as the learning rate (also sometimes called step size) to determine the next point. For example, if the gradient magnitude is 2.5 and the learning rate is 0.01, then the gradient descent algorithm will pick the next point 0.025 away from the previous point.</p>
<h2><span id="batch">batch</span></h2>
<p>In gradient descent, a batch is the total number of examples you use to calculate the gradient in a single iteration.</p>
<h2><span id="sgd-stochastic-gradient-descent-随机梯度下降">SGD  Stochastic Gradient Descent 随机梯度下降</span></h2>
<p>Stochastic gradient descent (SGD) takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration. Given enough iterations, SGD works but is very noisy. The term &quot;stochastic&quot; indicates that the one example comprising each batch is chosen at random.</p>
<h2><span id="mini-batch-stochastic-gradient-descent-mini-batch-sgd">Mini-batch stochastic gradient descent (mini-batch SGD)</span></h2>
<p>is a compromise between full-batch iteration and SGD. A mini-batch is typically between 10 and 1,000 examples, chosen at random. Mini-batch SGD reduces the amount of noise in SGD but is still more efficient than full-batch.</p>
<p>#Panda
DataFrame, which you can imagine as a relational data table, with rows and named columns.
Series, which is a single column. A DataFrame contains one or more Series and a name for each Series.</p>
<p>#Generalization 泛化</p>
<h2><span id="overfitting-过拟合">overfitting  过拟合</span></h2>
<p>An overfit model gets a low loss during training but does a poor job predicting new data</p>
<p>The fundamental tension of machine learning is between fitting our data well, but also fitting the data as simply as possible.</p>
<p>Empirically 经验化</p>
<h2><span id="splitting-data-unexpected-high-accurate-rate">splitting data -- unexpected high accurate rate</span></h2>
<p>For example, consider a model that predicts whether an email is spam, using the subject line, email body, and sender's email address as features. We apportion the data into training and test sets, with an 80-20 split. After training, the model achieves 99% precision on both the training set and the test set. We'd expect a lower precision on the test set, so we take another look at the data and discover that many of the examples in the test set are duplicates of examples in the training set (we neglected to scrub duplicate entries for the same spam email from our input database before splitting the data). We've inadvertently trained on some of our test data, and as a result, we're no longer accurately measuring how well our model generalizes to new data.</p>
<h2><span id="overfitting">overfitting</span></h2>
<p>Yes indeed! The more often we evaluate on a given test set, the more we are at risk for implicitly overfitting to that one test set. We'll look at a better protocol next.</p>
<h2><span id="train-test">Train-Test</span></h2>
<p>Training set, validation set, test set
if teset set metric is pool, a good signal of overfitting the validation set.</p>
<h1><span id="feature-enginerring">Feature Enginerring</span></h1>
<p>That is, one way developers hone a model is by adding and improving its features.</p>
<p>Feature engineering means transforming raw data into a feature vector. Expect to spend significant time doing feature engineering.</p>
<h2><span id="properties-of-good-feature">properties of good feature</span></h2>
<h2><span id="sparse-representation-稀疏表示">Sparse Representation 稀疏表示</span></h2>
<p>A representation of a tensor that only stores nonzero elements.</p>
<p>Feature sparsity refers to the sparsity of a feature vector; model sparsity refers to the sparsity of the model weights.</p>
<h1><span id="feature-crosses-特征交叉">Feature Crosses 特征交叉</span></h1>
<h1><span id="regularization-正则化-解决overfitting">Regularization 正则化 解决overfitting</span></h1>
<p>two ways:
-- early stopping
-- Penalizing the model complexity</p>
<p>how to define complexity
prefer smaller weights</p>
<p>we'll now minimize loss+complexity, which is called structural risk minimization:</p>
<h2><span id="l2-regularization">L2 Regularization</span></h2>
<p>We can quantify complexity using the L2 regularization formula, which defines the regularization term as the sum of the squares of all the feature weight</p>
<h2><span id="regularization-rate-lamda">regularization rate -- lamda</span></h2>
<p>If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data.</p>
<h1><span id="logistic-regression">Logistic Regression</span></h1>
<p>calibrated 校正</p>
<p>regularization is super important for logistic regression</p>
<p>Two strategies are especially useful:
L2 regularization (aka L2 weight decay) - penalizes huge weights.
Early stopping - limiting training steps or learning rate.</p>
<h1><span id="classification">Classification</span></h1>
<p>Sometimes, we use logistic regression for the probability outputs -- this is a regression in (0, 1)
Other times, we'll threshold the value for a discrete binary classification
Choice of threshold is an important choice, and can be tuned</p>
<ul>
<li>
<p>Precission
What proportion of positive identifications was actually correct?</p>
</li>
<li>
<p>Recall
What proportion of actual positives was identified correctly?</p>
</li>
</ul>
<h2><span id="roc-curve-receiver-operating-characteristic-curve">ROC curve receiver operating characteristic curve</span></h2>
<p>is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:</p>
<h2><span id="auc-area-under-the-roc-curve">AUC area under the roc curve</span></h2>
<p>predication bias</p>
<p>Don't fix bias with a calibration layer, fix it in the model.</p>
<h2><span id="classification-threshold-decision-threshold">classification threshold -- decision threshold</span></h2>
<p>in order to map a logistic regression value to a binary category, you must define a classification threshold (also called the decision threshold). A value above that threshold indicates &quot;spam&quot;; a value below indicates &quot;not spam.&quot;</p>
<h1><span id="regularization-sparsity">Regularization: Sparsity</span></h1>
<p>Caveat: Sparse feature crosses may significantly increase feature space
Possible issues:
Model size (RAM) may become huge
&quot;Noise&quot; coefficients (causes overfitting)</p>
<p>Sparse vectors often contain many dimensions. Creating a feature cross results in even more dimensions. Given such high-dimensional feature vectors, model size may become huge and require huge amounts of RAM.</p>
<h2><span id="l1-regularization">L1 Regularization</span></h2>
<p>L1 vs L2 regularization.
L2 and L1 penalize weights differently:</p>
<p>L2 penalizes weight^2.
L1 penalizes |weight|.
Consequently, L2 and L1 have different derivatives:</p>
<p>The derivative of L2 is 2 * weight.
The derivative of L1 is k (a constant, whose value is independent of weight).</p>
<h1><span id="neural-nets-神经网络">Neural Nets 神经网络</span></h1>
<h2><span id="activation-function">activation function</span></h2>
<p>To model a nonlinear problem, we can directly introduce a nonlinearity. We can pipe each hidden layer node through a nonlinear function.</p>
<p>In the model represented by the following graph, the value of each node in Hidden Layer 1 is transformed by a nonlinear function before being passed on to the weighted sums of the next layer. This nonlinear function is called the activation function.</p>
<h2><span id="back-propgation">back propgation</span></h2>
<h1><span id="multi-class-neural-nets-多类别神经网络">Multi-class Neural Nets 多类别神经网络</span></h1>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/13/python-tutorial/" rel="next" title="python_tutorial">
                <i class="fa fa-chevron-left"></i> python_tutorial
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/07/GBDT/" rel="prev" title="GBDT">
                GBDT <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/timg.jpeg"
                alt="Yifan Guo" />
            
              <p class="site-author-name" itemprop="name">Yifan Guo</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">Machine learning- crash course</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.</span> <span class="nav-text">Framing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.1.</span> <span class="nav-text">Label</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.2.</span> <span class="nav-text">(supervised) machine learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.3.</span> <span class="nav-text">Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.4.</span> <span class="nav-text">Regression vs. classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.1.5.</span> <span class="nav-text">feature</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">1.2.</span> <span class="nav-text">empirical risk minimization ERM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">1.3.</span> <span class="nav-text">squared loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">1.4.</span> <span class="nav-text">Mean square error MSE</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">Reducing loss</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.1.</span> <span class="nav-text">coverged 收敛</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">2.1.1.</span> <span class="nav-text">convex 凸面的</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.2.</span> <span class="nav-text">gradient descent</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.3.</span> <span class="nav-text">Learning rate</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.4.</span> <span class="nav-text">batch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.5.</span> <span class="nav-text">SGD  Stochastic Gradient Descent 随机梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.6.</span> <span class="nav-text">Mini-batch stochastic gradient descent (mini-batch SGD)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.7.</span> <span class="nav-text">overfitting  过拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.8.</span> <span class="nav-text">splitting data -- unexpected high accurate rate</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.9.</span> <span class="nav-text">overfitting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.10.</span> <span class="nav-text">Train-Test</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">Feature Enginerring</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.1.</span> <span class="nav-text">properties of good feature</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.2.</span> <span class="nav-text">Sparse Representation 稀疏表示</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">Feature Crosses 特征交叉</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">Regularization 正则化 解决overfitting</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">5.1.</span> <span class="nav-text">L2 Regularization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">5.2.</span> <span class="nav-text">regularization rate -- lamda</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">Logistic Regression</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.1.</span> <span class="nav-text">ROC curve receiver operating characteristic curve</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.2.</span> <span class="nav-text">AUC area under the roc curve</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.3.</span> <span class="nav-text">classification threshold -- decision threshold</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">Regularization: Sparsity</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">8.1.</span> <span class="nav-text">L1 Regularization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">Neural Nets 神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">9.1.</span> <span class="nav-text">activation function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">9.2.</span> <span class="nav-text">back propgation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">10.</span> <span class="nav-text">Multi-class Neural Nets 多类别神经网络</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yifan Guo</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">65.3k</span>
  

  
  <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize("");
    }
  </script>
  

</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.yifanguo.top/2018/08/22/Machine learning- crash course/';
          this.page.identifier = '2018/08/22/Machine learning- crash course/';
          this.page.title = '';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://www-yifanguo-top.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

  
</body>
</html>
