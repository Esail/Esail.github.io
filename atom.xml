<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yifan Guo Personal Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.yifanguo.top/"/>
  <updated>2018-10-22T11:50:57.000Z</updated>
  <id>http://www.yifanguo.top/</id>
  
  <author>
    <name>Yifan Guo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>socket</title>
    <link href="http://www.yifanguo.top/2018/10/22/socket/"/>
    <id>http://www.yifanguo.top/2018/10/22/socket/</id>
    <published>2018-10-22T11:33:40.000Z</published>
    <updated>2018-10-22T11:50:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="socket是什么">socket是什么</span></h1><p><img src="socket.png" alt=""></p><p>Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议</p><p><img src="server.png" alt=""></p><p>先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。</p><h1><span id="网络中进程之间如何通信">网络中进程之间如何通信</span></h1><p>本地的进程间通信（IPC）有很多种方式，但可以总结为下面4类：</p><ul><li>消息传递（管道、FIFO、消息队列）</li><li>同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）</li><li>共享内存（匿名的和具名的）</li><li>远程过程调用（Solaris门和Sun RPC）</li></ul><p>但这些都不是本文的主题！我们要讨论的是网络中进程之间如何通信？首要解决的问题是如何唯一标识一个进程，否则通信无从谈起！在本地可以通过进程PID来唯一标识一个进程，但是在网络中这是行不通的。其实TCP/IP协议族已经帮我们解决了这个问题，网络层的“ip地址”可以唯一标识网络中的主机，而传输层的“协议+端口”可以唯一标识主机中的应用程序（进程）。这样利用三元组（ip地址，协议，端口）就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互。</p><p>使用TCP/IP协议的应用程序通常采用应用编程接口：UNIX BSD的套接字（socket）和UNIX System V的TLI（已经被淘汰），来实现网络进程之间的通信。就目前而言，几乎所有的应用程序都是采用socket，而现在又是网络时代，网络中进程通信是无处不在，这就是我为什么说“一切皆socket”</p><h1><span id="什么是socket">什么是socket</span></h1><p>上面我们已经知道网络中的进程是通过socket来通信的，那什么是socket呢？socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭</p><h1><span id="socket的基本操作">socket的基本操作</span></h1><p>既然socket是“open—write/read—close”模式的一种实现，那么socket就提供了这些操作对应的函数接口。下面以TCP为例，介绍几个基本的socket接口函数</p><h2><span id="31-socket函数">3.1 socket()函数</span></h2><p>int socket(int domain, int type, int protocol);</p><p>socket函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而socket()用于创建一个socket描述符（socket descriptor），它唯一标识一个socket。这个socket描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。</p><p>正如可以给fopen的传入不同参数值，以打开不同的文件。创建socket的时候，也可以指定不同的参数创建不同的socket描述符，socket函数的三个参数分别为：</p><ul><li>domain：即协议域，又称为协议族（family）。常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。</li><li>type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等（socket的类型有哪些？）。</li><li>protocol：故名思意，就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议</li></ul><p>注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。</p><p>当我们调用socket创建一个socket时，返回的socket描述字它存在于协议族（address family，AF_XXX）空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用bind()函数，否则就当调用connect()、listen()时系统会自动随机分配一个端口</p><h2><span id="32-bind函数">3.2 bind()函数</span></h2><p>int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</p><p>通常服务器在启动的时候都会绑定一个众所周知的地址（如ip地址+端口号），用于提供服务，客户就可以通过它来接连服务器；而客户端就不用指定，有系统自动分配一个端口号和自身的ip地址组合。这就是为什么通常服务器端在listen之前会调用bind()，而客户端就不会调用，而是在connect()时由系统随机生成一个</p><h2><span id="33-listen-connect函数">3.3 listen()、connect()函数</span></h2><p>如果作为一个服务器，在调用socket()、bind()之后就会调用listen()来监听这个socket，如果客户端这时调用connect()发出连接请求，服务器端就会接收到这个请求。int listen(int sockfd, int backlog);int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</p><p>listen函数的第一个参数即为要监听的socket描述字，第二个参数为相应socket可以排队的最大连接个数。socket()函数创建的socket默认是一个主动类型的，listen函数将socket变为被动类型的，等待客户的连接请求。</p><p>connect函数的第一个参数即为客户端的socket描述字，第二参数为服务器的socket地址，第三个参数为socket地址的长度。客户端通过调用connect函数来建立与TCP服务器的连接。</p><h2><span id="34-accept函数">3.4 accept()函数</span></h2><p>TCP服务器端依次调用socket()、bind()、listen()之后，就会监听指定的socket地址了。TCP客户端依次调用socket()、connect()之后就想TCP服务器发送了一个连接请求。TCP服务器监听到这个请求之后，就会调用accept()函数取接收请求，这样连接就建立好了。之后就可以开始网络I/O操作了，即类同于普通文件的读写I/O操作。</p><p>int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);accept函数的第一个参数为服务器的socket描述字，第二个参数为指向struct sockaddr *的指针，用于返回客户端的协议地址，第三个参数为协议地址的长度。如果accpet成功，那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的TCP连接。</p><p>注意：accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept函数返回的是已连接的socket描述字。一个服务器通常通常仅仅只创建一个监听socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接受的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就被关闭。</p><h1><span id="35-read-write等函数">3.5 read()、write()等函数</span></h1><p>read函数是负责从fd中读取内容.当读成功时，read返回实际所读的字节数，如果返回的值是0表示已经读到文件的结束了，小于0表示出现了错误。如果错误为EINTR说明读是由中断引起的，如果是ECONNREST表示网络连接出了问题。</p><p>write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节 数。失败时返回-1，并设置errno变量。在网络程序中，当我们向套接字文件描述符写时有俩种可能。1)write的返回值大于0，表示写了部分或者是 全部的数据。2)返回的值小于0，此时出现了错误。我们要根据错误类型来处理。如果错误为EINTR表示在写的时候出现了中断错误。如果为EPIPE表示 网络连接出现了问题(对方已经关闭了连接)。</p><p>其它的我就不一一介绍这几对I/O函数了，具体参见man文档或者baidu、Google，下面的例子中将使用到send/recv。</p><h1><span id="36-close函数">3.6 close()函数</span></h1><p>在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的socket描述字，好比操作完打开的文件要调用fclose关闭打开的文件。</p><p>#includeint close(int fd);close一个TCP socket的缺省行为时把该socket标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为read或write的第一个参数。</p><p>注意：close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求。</p><h1><span id="4-socket中tcp的三次握手建立连接详解">4、socket中TCP的三次握手建立连接详解</span></h1><p>我们知道tcp建立连接要进行“三次握手”，即交换三个分组。大致流程如下：</p><p>客户端向服务器发送一个SYN J服务器向客户端响应一个SYN K，并对SYN J进行确认ACK J+1客户端再想服务器发一个确认ACK K+1只有就完了三次握手，但是这个三次握手发生在socket的那几个函数中呢？请看下图：</p><p><img src="shakehands.png" alt=""></p><p>从图中可以看出，当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。</p><p>总结：客户端的connect在三次握手的第二个次返回，而服务器端的accept在三次握手的第三次返回。</p><h1><span id="5-socket中tcp的四次握手释放连接详解">5、socket中TCP的四次握手释放连接详解</span></h1><p>上面介绍了socket中TCP的三次握手建立过程，及其涉及的socket函数。现在我们介绍socket中的四次握手释放连接的过程，请看下图：</p><p><img src="offhands.png" alt=""></p><p>图示过程如下：</p><ul><li>某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；</li><li>另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；</li><li>一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；</li><li>接收到这个FIN的源发送端TCP对它进行确认。这样每个方向上都有一个FIN和ACK。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;socket是什么&quot;&gt;socket是什么&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;socket.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实
      
    
    </summary>
    
    
      <category term="socket" scheme="http://www.yifanguo.top/tags/socket/"/>
    
  </entry>
  
  <entry>
    <title>xgboost</title>
    <link href="http://www.yifanguo.top/2018/10/17/xgboost/"/>
    <id>http://www.yifanguo.top/2018/10/17/xgboost/</id>
    <published>2018-10-18T02:41:44.000Z</published>
    <updated>2018-10-19T02:10:13.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="xgboost" scheme="http://www.yifanguo.top/tags/xgboost/"/>
    
  </entry>
  
  <entry>
    <title>lightgbm</title>
    <link href="http://www.yifanguo.top/2018/10/17/lightgbm-0/"/>
    <id>http://www.yifanguo.top/2018/10/17/lightgbm-0/</id>
    <published>2018-10-18T01:49:34.000Z</published>
    <updated>2018-10-18T02:42:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="background">background</span></h1><p>In recent years, with the emergence of big data (in terms of both the number of features and the number of instances), GBDT is facing new challenges, especially in the tradeoff between accuracy and efficiency.</p><h1><span id="why-introduct-lightgbm">why introduct lightgbm</span></h1><p>A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming.</p><h1><span id="what-is-lightgbm">what is lightgbm</span></h1><p>GOSS: Gradient-based One-Side SamplingEFB: Exclusive Feature Bundling</p><h1><span id="goss">GOSS</span></h1><p>ince the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size.</p><h1><span id="efb">EFB</span></h1><p>With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features.</p><h1><span id="gbdt">GBDT</span></h1><p>GBDT is an ensemble model of decision trees,In each iteration, GBDT learns the decision trees by fitting the negative gradients (also known as residual errors).</p><p>The main cost in GBDT lies in learning the decision trees, and the most time-consuming part in learning a decision tree is to find the best split points</p><h1><span id="goss-implementaion">GOSS implementaion</span></h1><p>GOSS keeps all the instances with large gradients and performs random sampling on the instances with small gradients.</p><p><img src="/Users/yifanguo/Desktop/xgb.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;background&quot;&gt;background&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;In recent years, with the emergence of big data (in terms of both the number of features
      
    
    </summary>
    
    
      <category term="lightgbm" scheme="http://www.yifanguo.top/tags/lightgbm/"/>
    
  </entry>
  
  <entry>
    <title>lightGBM on spark</title>
    <link href="http://www.yifanguo.top/2018/10/08/mmlSpark/"/>
    <id>http://www.yifanguo.top/2018/10/08/mmlSpark/</id>
    <published>2018-10-08T09:28:18.000Z</published>
    <updated>2018-10-12T07:44:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="lightgbm-on-spark-参数配置">LightGBM on Spark 参数配置</span></h1><h1><span id="官方参数说明">官方参数说明</span></h1><p>http://lightgbm.apachecn.org/cn/latest/Parameters.html</p><h1><span id="工程地址">工程地址</span></h1><p>https://g.hz.netease.com/guoyifan01/lightgbmOnSpark</p><h1><span id="configuration">configuration</span></h1><h2><span id="通用">通用</span></h2><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>prePartition</td><td>is_pre_partition</td><td>True</td><td>bool</td><td>true 如果训练数据 pre-partitioned, 不同的机器使用不同的分区</td></tr><tr><td>boostingType</td><td>boosting_type</td><td>gbdt</td><td>string</td><td>gbdt,rf, dart, goss</td></tr><tr><td>parallelism</td><td>tree_learner</td><td>data_parallel</td><td>string</td><td>数据并行的 tree learner</td></tr><tr><td>defaultListenPort</td><td>无</td><td>12400</td><td>int</td><td>The default listen port on executors, used for testing</td></tr><tr><td>numIterations</td><td>num_iterations</td><td>100</td><td>int</td><td>boosting 的迭代次数</td></tr><tr><td>learningRate</td><td>learning_rate</td><td>0.1</td><td>double</td><td>学习率</td></tr><tr><td>numLeaves</td><td>num_leaves</td><td>31</td><td>int</td><td>一棵树上的叶子数</td></tr><tr><td>maxBin</td><td>max_bin</td><td>255</td><td>int</td><td>工具箱的最大数特征值决定了容量 工具箱的最小数特征值可能会降低训练的准确性, 但是可能会增加一些一般的影响（处理过度学习）LightGBM 将根据 max_bin 自动压缩内存。 例如, 如果 maxbin=255, 那么 LightGBM 将使用 uint8t 的特性值</td></tr><tr><td>baggingFraction</td><td>bagging_fraction</td><td>1.0</td><td>double</td><td>类似于 feature_fraction, 但是它将在不进行重采样的情况下随机选择部分数据 可以用来加速训练 可以用来处理过拟合 Note: 为了启用 bagging, bagging_freq 应该设置为非零值</td></tr><tr><td>baggingFreq</td><td>bagging_freq</td><td>0</td><td>int</td><td>bagging 的频率, 0 意味着禁用 bagging. k 意味着每 k 次迭代执行bagging Note: 为了启用 bagging, bagging_fraction 设置适当</td></tr><tr><td>baggingSeed</td><td>bagging_seed</td><td>3</td><td>int</td><td>Bagging seed</td></tr><tr><td>earlyStoppingRound</td><td>early_stopping_round</td><td>0</td><td>int</td><td>Early stopping round</td></tr><tr><td>featureFraction</td><td>feature_fraction</td><td>1.0</td><td>double</td><td>Feature fraction</td></tr><tr><td>maxDepth</td><td>max_depth</td><td>-1</td><td>int</td><td>-1意味着没有限制</td></tr><tr><td>minSumHessianInLeaf</td><td>min_sum_hessian_in_leaf</td><td>1e-3</td><td>Double</td><td>Minimal sum hessian in one leaf</td></tr><tr><td>无</td><td>num_machines</td><td>1</td><td>int</td><td>并行运行的机器数量，在spark上，有多少个executor就有多少个机器</td></tr><tr><td>timeout</td><td>无</td><td>120s</td><td>second</td><td>socket超时</td></tr><tr><td>objective</td><td>application</td><td>regression</td><td>enum</td><td>regression, regression_l1, huber, fair, poisson, quantile, quantile_l2, binary, multiclass, multiclassova, xentropy, xentlambda, lambdarank</td></tr><tr><td>min_data_in_leaf</td><td>min_data_in_leaf</td><td>20</td><td>int</td><td>min_data_in_leaf</td></tr><tr><td>min_data_in_bin</td><td>min_data_in_bin</td><td>3</td><td>int</td><td>min_data_in_bin</td></tr><tr><td>lambda_l1</td><td>lambda_l1</td><td>0</td><td>double</td><td>lambda_l1</td></tr><tr><td>lambda_l2</td><td>lambda_l2</td><td>0</td><td>double</td><td>lambda_l2</td></tr><tr><td>modelString</td><td>无</td><td>“”</td><td>String</td><td>model存成String格式</td></tr></tbody></table><p>##分类</p><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>无</td><td>metric</td><td>binary_logloss,auc</td><td>String</td><td>度量</td></tr></tbody></table><p>##回归</p><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>alpha</td><td>alpha</td><td>0.9</td><td>double</td><td>Huber loss 和 Quantile regression 的参数. 将用于 regression 任务</td></tr><tr><td>tweedieVariancePower</td><td>tweedie_variance_power</td><td>1.5</td><td>double</td><td>control the variance of tweedie distribution, must be between 1 and 2</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;lightgbm-on-spark-参数配置&quot;&gt;LightGBM on Spark 参数配置&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;官方参数说明&quot;&gt;官方参数说明&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;http://lig
      
    
    </summary>
    
    
      <category term="ml" scheme="http://www.yifanguo.top/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM</title>
    <link href="http://www.yifanguo.top/2018/10/08/LightGBM/"/>
    <id>http://www.yifanguo.top/2018/10/08/LightGBM/</id>
    <published>2018-10-08T08:07:39.000Z</published>
    <updated>2018-10-08T08:08:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="light-gbm">light gbm</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;light-gbm&quot;&gt;light gbm&lt;/span&gt;&lt;/h1&gt;

      
    
    </summary>
    
    
      <category term="ml" scheme="http://www.yifanguo.top/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>Scala的一些解释</title>
    <link href="http://www.yifanguo.top/2018/10/07/Scala/"/>
    <id>http://www.yifanguo.top/2018/10/07/Scala/</id>
    <published>2018-10-08T05:35:26.000Z</published>
    <updated>2018-10-08T08:07:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="with-vs-extends">with vs extends</span></h1><p>https://stackoverflow.com/questions/41031166/scala-extends-vs-with</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;with-vs-extends&quot;&gt;with vs extends&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;https://stackoverflow.com/questions/41031166/scala-extends-vs-with&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="scala" scheme="http://www.yifanguo.top/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>GBDT</title>
    <link href="http://www.yifanguo.top/2018/10/07/GBDT/"/>
    <id>http://www.yifanguo.top/2018/10/07/GBDT/</id>
    <published>2018-10-08T01:43:15.000Z</published>
    <updated>2018-10-08T04:34:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="reference">Reference：</span></h1><p>https://www.cnblogs.com/ModifyRong/p/7744987.html</p><h1><span id="residual-残差">residual 残差</span></h1><h1><span id="gbdt-gradient-boosting-decision-tree">GBDT - Gradient Boosting Decision Tree</span></h1><h2><span id="dt-决策树">DT-- 决策树</span></h2><p>特点： 可以做分类和回归，分类速度快，可以可视化缺点：容易过拟合</p><h2><span id="boosting">Boosting</span></h2><p>在分类问题中，它通过改变训练样本的权重（增加分错样本的权重，减小分队样本的的权重），学习多个分类器，并将这些分类器线性组合，提高分类器性能。</p><p>Boosting 是一族可将弱学习器提升为强学习器的算法，属于集成学习（ensemble learning）的范畴。Boosting 方法基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断要好。通俗地说，就是&quot;三个臭皮匠顶个诸葛亮&quot;的道理。</p><p>基于梯度提升算法的学习器叫做 GBM(Gradient Boosting Machine)。理论上，GBM 可以选择各种不同的学习算法作为基学习器。GBDT 实际上是 GBM 的一种情况。</p><h2><span id="gradient-boosting">Gradient Boosting</span></h2><p>Gradient Boosting是一种Boosting方法，主要思想是：每一次建立模型是在之前建立模型损失函数的梯度下降方向。损失函数是评价模型性能(一般为拟合程度+正则项)，认为损失函数越小，性能越好。让损失函数持续下降，就能使模型不断改进提升性能，最好的方法就是使损失函数沿着梯度方向下降。</p><h1><span id="gbdt-introduction">GBDT introduction</span></h1><p><img src="gb.png" alt=""></p><p>gbdt训练过程</p><p>gbdt通过多轮迭代,每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的残差基础上进行训练。对弱分类器的要求一般是足够简单，并且是低方差和高偏差的。因为训练的过程是通过降低偏差来不断提高最终分类器的精度</p><p>弱分类器一般会选择为CART TREE（也就是分类回归树）</p><p>$$$$</p><p>Fm−1(x) 为当前的模型，gbdt 通过经验风险极小化来确定下一个弱分类器的参数。具体到损失函数本身的选择也就是L的选择，有平方损失函数，0-1损失函数，对数损失函数等等。如果我们选择平方损失函数，那么这个差值其实就是我们平常所说的残差</p><h1><span id="gbdt-key-points">GBDT key points</span></h1><ul><li>希望loss_f 能够不断减小，沿着剃度方向</li><li>希望loss_f 能够尽快的减小</li></ul><p>利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值去拟合一个回归树。gbdt 每轮迭代的时候，都去拟合损失函数在当前模型下的负梯度。这样每轮训练的时候都能够让损失函数尽可能快的减小，尽快的收敛达到局部最优解或者全局最优解</p><h1><span id="gbdt如何选择特征">GBDT如何选择特征</span></h1><p>gbdt的弱分类器默认选择的是CART TREE。其实也可以选择其他弱分类器的，选择的前提是低方差和高偏差。框架服从boosting 框架即可</p><p>下面我们具体来说CART TREE(是一种二叉树) 如何生成。CART TREE 生成的过程其实就是一个选择特征的过程。假设我们目前总共有 M 个特征。第一步我们需要从中选择出一个特征 j，做为二叉树的第一个节点。然后对特征 j 的值选择一个切分点 m. 一个 样本的特征j的值 如果小于m，则分为一类，如果大于m,则分为另外一类。如此便构建了CART 树的一个节点。其他节点的生成过程和这个是一样的。现在的问题是在每轮迭代的时候，如何选择这个特征 j,以及如何选择特征 j 的切分点 m:</p><ul><li>原始的gbdt的做法非常的暴力，首先遍历每个特征，然后对每个特征遍历它所有可能的切分点，找到最优特征 m 的最优切分点 j。</li><li>如何衡量我们找到的特征 m和切分点 j 是最优的呢？ 我们用定义一个函数 FindLossAndSplit 来展示一下求解过程：</li></ul><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def findLossAndSplit(x,y):</span><br><span class="line">    # 我们用 x 来表示训练数据</span><br><span class="line">    # 我们用 y 来表示训练数据的label</span><br><span class="line">    # x[i]表示训练数据的第i个特征</span><br><span class="line">    # x_i 表示第i个训练样本</span><br><span class="line"></span><br><span class="line">    # minLoss 表示最小的损失</span><br><span class="line">    minLoss = Integet.max_value</span><br><span class="line">    # feature 表示是训练的数据第几纬度的特征</span><br><span class="line">    feature = 0</span><br><span class="line">    # split 表示切分点的个数</span><br><span class="line">    split = 0</span><br><span class="line"></span><br><span class="line">    # M 表示 样本x的特征个数</span><br><span class="line">    for j in range(0,M):</span><br><span class="line">        # 该维特征下，特征值的每个切分点，这里具体的切分方式可以自己定义</span><br><span class="line">        for c in range(0,x[j]):</span><br><span class="line">            L = 0</span><br><span class="line">            # 第一类</span><br><span class="line">            R1 = &#123;x|x[j] &lt;= c&#125;</span><br><span class="line">            # 第二类</span><br><span class="line">            R2 = &#123;x|x[j] &gt; c&#125;</span><br><span class="line">            # 属于第一类样本的y值的平均值</span><br><span class="line">            y1 = ave&#123;y|x 属于 R1&#125;</span><br><span class="line">            # 属于第二类样本的y值的平均值</span><br><span class="line">            y2 = ave&#123;y| x 属于 R2&#125;</span><br><span class="line">            # 遍历所有的样本，找到 loss funtion 的值</span><br><span class="line">            for x_1 in all x</span><br><span class="line">                if x_1 属于 R1： </span><br><span class="line">                    L += (y_1 - y1)^2 </span><br><span class="line">                else:</span><br><span class="line">                    L += (y_1 - y2)^2</span><br><span class="line">            if L &lt; minLoss:</span><br><span class="line">               minLoss = L</span><br><span class="line">               feature  = i</span><br><span class="line">               split = c</span><br><span class="line">    return minLoss,feature ,split</span><br></pre></td></tr></table></figure></p><h1><span id="gbdt如何构建特征">gbdt如何构建特征</span></h1><p><img src="gbdt_lr.png" alt=""></p><p>迭代几次，就会产生几棵树</p><p>我们 使用 GBDT 生成了两棵树，两颗树一共有五个叶子节点。我们将样本 X 输入到两颗树当中去，样本X 落在了第一棵树的第二个叶子节点，第二颗树的第一个叶子节点，于是我们便可以依次构建一个五纬的特征向量，每一个纬度代表了一个叶子节点，样本落在这个叶子节点上面的话那么值为1，没有落在该叶子节点的话，那么值为 0.</p><p>于是对于该样本，我们可以得到一个向量[0,1,0,1,0] 作为该样本的组合特征，和原来的特征一起输入到逻辑回归当中进行训练。实验证明这样会得到比较显著的效果提升。</p><h1><span id="gbdt-vs-xgboost">GBDT vs xGboost</span></h1><p>Xgboost 和 GBDT 的区别：</p><p>GBDT：</p><p>GBDT 它的非线性变换比较多，表达能力强，而且不需要做复杂的特征工程和特征变换。GBDT 的缺点也很明显，Boost 是一个串行过程，不好并行化，而且计算复杂度高，同时不太适合高维稀疏特征；传统 GBDT 在优化时只用到一阶导数信息。Xgboost：</p><p>它有以下几个优良的特性：</p><ol><li>显示的把树模型复杂度作为正则项加到优化目标中。</li><li>公式推导中用到了二阶导数，用了二阶泰勒展开。（GBDT 用牛顿法貌似也是二阶信息）</li><li>实现了分裂点寻找近似算法。</li><li>利用了特征的稀疏性。</li><li>数据事先排序并且以 block 形式存储，有利于并行计算。</li><li>基于分布式通信框架 rabit，可以运行在 MPI 和 yarn 上。（最新已经不基于 rabit 了）</li><li>实现做了面向体系结构的优化，针对 cache 和内存做了性能优化。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;reference&quot;&gt;Reference：&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;https://www.cnblogs.com/ModifyRong/p/7744987.html&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;residual
      
    
    </summary>
    
    
      <category term="ml" scheme="http://www.yifanguo.top/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://www.yifanguo.top/2018/08/22/Machine%20learning-%20crash%20course/"/>
    <id>http://www.yifanguo.top/2018/08/22/Machine learning- crash course/</id>
    <published>2018-08-22T10:32:08.000Z</published>
    <updated>2018-08-22T10:32:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="machine-learning-crash-course">Machine learning- crash course</span></h1><h2><span id="framing">Framing</span></h2><h3><span id="label">Label</span></h3><p>A label is the thing we're predicting—the y variable in simple linear regression</p><ul><li>label is the true thing we are predicting: y<ul><li>the y variable in basic linear regression</li></ul></li><li>Labeled example has {features, label} (x,y)<ul><li>used to train the model</li></ul></li><li>unlabeled example has {features, ?} :(x,?)<ul><li>used for making predictions on new data</li></ul></li><li>model maps examples to predicted labels&quot; y'<ul><li>defined by internal parameters, which are learned</li></ul></li></ul><h3><span id="supervised-machine-learning">(supervised) machine learning</span></h3><p>ML systems learn how to combine input to produce useful predictions on never-before-seen data.</p><h3><span id="models">Models</span></h3><p>Training means creating or learning the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.</p><p>Inference means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y'). For example, during inference, you can predict medianHouseValue for new unlabeled examples.</p><h3><span id="regression-vs-classification">Regression vs. classification</span></h3><p>A regression model predicts continuous values. For example, regression models make predictions that answer questions like the following:</p><p>What is the value of a house in California?</p><p>What is the probability that a user will click on this ad?</p><p>A classification model predicts discrete values. For example, classification models make predictions that answer questions like the following:</p><p>Is a given email message spam or not spam?</p><p>Is this an image of a dog, a cat, or a hamster?</p><h3><span id="feature">feature</span></h3><p>good fetures are concrete and quantifiable</p><h2><span id="empirical-risk-minimization-erm">empirical risk minimization ERM</span></h2><p>Loss is the penalty for a bad prediction</p><h2><span id="squared-loss">squared loss</span></h2><p>squared loss (also known as L2 loss)</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">= the square of the difference between the label and the prediction</span><br><span class="line">  = (observation - prediction(x))2</span><br><span class="line">  = (y - y&apos;)2</span><br></pre></td></tr></table></figure></p><h2><span id="mean-square-error-mse">Mean square error MSE</span></h2><p>Mean square error (MSE) is the average squared loss per example over the whole dataset. To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples:</p><h1><span id="reducing-loss">Reducing loss</span></h1><h2><span id="coverged-收敛">coverged 收敛</span></h2><p>Usually, you iterate until overall loss stops changing or at least changes extremely slowly. When that happens, we say that the model has converged.</p><h3><span id="convex-凸面的">convex 凸面的</span></h3><p>Regression problems yield convex loss vs weight plots</p><p>Convex problems have only one minimum; that is, only one place where the slope is exactly 0. That minimum is where the loss function converges.</p><h2><span id="gradient-descent">gradient descent</span></h2><p>the gradient is a vector of partial derivatives with respect to the weights</p><p>In machine learning, gradients are used in gradient descent. We often have a loss function of many variables that we are trying to minimize, and we try to do this by following the negative of the gradient of the function.</p><h2><span id="learning-rate">Learning rate</span></h2><p>As noted, the gradient vector has both a direction and a magnitude(大小）</p><p>Gradient descent algorithms multiply the gradient by a scalar known as the learning rate (also sometimes called step size) to determine the next point. For example, if the gradient magnitude is 2.5 and the learning rate is 0.01, then the gradient descent algorithm will pick the next point 0.025 away from the previous point.</p><h2><span id="batch">batch</span></h2><p>In gradient descent, a batch is the total number of examples you use to calculate the gradient in a single iteration.</p><h2><span id="sgd-stochastic-gradient-descent-随机梯度下降">SGD  Stochastic Gradient Descent 随机梯度下降</span></h2><p>Stochastic gradient descent (SGD) takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration. Given enough iterations, SGD works but is very noisy. The term &quot;stochastic&quot; indicates that the one example comprising each batch is chosen at random.</p><h2><span id="mini-batch-stochastic-gradient-descent-mini-batch-sgd">Mini-batch stochastic gradient descent (mini-batch SGD)</span></h2><p>is a compromise between full-batch iteration and SGD. A mini-batch is typically between 10 and 1,000 examples, chosen at random. Mini-batch SGD reduces the amount of noise in SGD but is still more efficient than full-batch.</p><p>#PandaDataFrame, which you can imagine as a relational data table, with rows and named columns.Series, which is a single column. A DataFrame contains one or more Series and a name for each Series.</p><p>#Generalization 泛化</p><h2><span id="overfitting-过拟合">overfitting  过拟合</span></h2><p>An overfit model gets a low loss during training but does a poor job predicting new data</p><p>The fundamental tension of machine learning is between fitting our data well, but also fitting the data as simply as possible.</p><p>Empirically 经验化</p><h2><span id="splitting-data-unexpected-high-accurate-rate">splitting data -- unexpected high accurate rate</span></h2><p>For example, consider a model that predicts whether an email is spam, using the subject line, email body, and sender's email address as features. We apportion the data into training and test sets, with an 80-20 split. After training, the model achieves 99% precision on both the training set and the test set. We'd expect a lower precision on the test set, so we take another look at the data and discover that many of the examples in the test set are duplicates of examples in the training set (we neglected to scrub duplicate entries for the same spam email from our input database before splitting the data). We've inadvertently trained on some of our test data, and as a result, we're no longer accurately measuring how well our model generalizes to new data.</p><h2><span id="overfitting">overfitting</span></h2><p>Yes indeed! The more often we evaluate on a given test set, the more we are at risk for implicitly overfitting to that one test set. We'll look at a better protocol next.</p><h2><span id="train-test">Train-Test</span></h2><p>Training set, validation set, test setif teset set metric is pool, a good signal of overfitting the validation set.</p><h1><span id="feature-enginerring">Feature Enginerring</span></h1><p>That is, one way developers hone a model is by adding and improving its features.</p><p>Feature engineering means transforming raw data into a feature vector. Expect to spend significant time doing feature engineering.</p><h2><span id="properties-of-good-feature">properties of good feature</span></h2><h2><span id="sparse-representation-稀疏表示">Sparse Representation 稀疏表示</span></h2><p>A representation of a tensor that only stores nonzero elements.</p><p>Feature sparsity refers to the sparsity of a feature vector; model sparsity refers to the sparsity of the model weights.</p><h1><span id="feature-crosses-特征交叉">Feature Crosses 特征交叉</span></h1><h1><span id="regularization-正则化-解决overfitting">Regularization 正则化 解决overfitting</span></h1><p>two ways:-- early stopping-- Penalizing the model complexity</p><p>how to define complexityprefer smaller weights</p><p>we'll now minimize loss+complexity, which is called structural risk minimization:</p><h2><span id="l2-regularization">L2 Regularization</span></h2><p>We can quantify complexity using the L2 regularization formula, which defines the regularization term as the sum of the squares of all the feature weight</p><h2><span id="regularization-rate-lamda">regularization rate -- lamda</span></h2><p>If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data.</p><h1><span id="logistic-regression">Logistic Regression</span></h1><p>calibrated 校正</p><p>regularization is super important for logistic regression</p><p>Two strategies are especially useful:L2 regularization (aka L2 weight decay) - penalizes huge weights.Early stopping - limiting training steps or learning rate.</p><h1><span id="classification">Classification</span></h1><p>Sometimes, we use logistic regression for the probability outputs -- this is a regression in (0, 1)Other times, we'll threshold the value for a discrete binary classificationChoice of threshold is an important choice, and can be tuned</p><ul><li><p>PrecissionWhat proportion of positive identifications was actually correct?</p></li><li><p>RecallWhat proportion of actual positives was identified correctly?</p></li></ul><h2><span id="roc-curve-receiver-operating-characteristic-curve">ROC curve receiver operating characteristic curve</span></h2><p>is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:</p><h2><span id="auc-area-under-the-roc-curve">AUC area under the roc curve</span></h2><p>predication bias</p><p>Don't fix bias with a calibration layer, fix it in the model.</p><h2><span id="classification-threshold-decision-threshold">classification threshold -- decision threshold</span></h2><p>in order to map a logistic regression value to a binary category, you must define a classification threshold (also called the decision threshold). A value above that threshold indicates &quot;spam&quot;; a value below indicates &quot;not spam.&quot;</p><h1><span id="regularization-sparsity">Regularization: Sparsity</span></h1><p>Caveat: Sparse feature crosses may significantly increase feature spacePossible issues:Model size (RAM) may become huge&quot;Noise&quot; coefficients (causes overfitting)</p><p>Sparse vectors often contain many dimensions. Creating a feature cross results in even more dimensions. Given such high-dimensional feature vectors, model size may become huge and require huge amounts of RAM.</p><h2><span id="l1-regularization">L1 Regularization</span></h2><p>L1 vs L2 regularization.L2 and L1 penalize weights differently:</p><p>L2 penalizes weight^2.L1 penalizes |weight|.Consequently, L2 and L1 have different derivatives:</p><p>The derivative of L2 is 2 * weight.The derivative of L1 is k (a constant, whose value is independent of weight).</p><h1><span id="neural-nets-神经网络">Neural Nets 神经网络</span></h1><h2><span id="activation-function">activation function</span></h2><p>To model a nonlinear problem, we can directly introduce a nonlinearity. We can pipe each hidden layer node through a nonlinear function.</p><p>In the model represented by the following graph, the value of each node in Hidden Layer 1 is transformed by a nonlinear function before being passed on to the weighted sums of the next layer. This nonlinear function is called the activation function.</p><h2><span id="back-propgation">back propgation</span></h2><h1><span id="multi-class-neural-nets-多类别神经网络">Multi-class Neural Nets 多类别神经网络</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;machine-learning-crash-course&quot;&gt;Machine learning- crash course&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;span id=&quot;framing&quot;&gt;Framing&lt;/span&gt;&lt;/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>python_tutorial</title>
    <link href="http://www.yifanguo.top/2018/08/13/python-tutorial/"/>
    <id>http://www.yifanguo.top/2018/08/13/python-tutorial/</id>
    <published>2018-08-13T12:08:05.000Z</published>
    <updated>2018-08-13T12:08:23.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="python" scheme="http://www.yifanguo.top/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>java_concurrent_02</title>
    <link href="http://www.yifanguo.top/2018/08/01/java-concurrent-02/"/>
    <id>http://www.yifanguo.top/2018/08/01/java-concurrent-02/</id>
    <published>2018-08-02T01:53:47.000Z</published>
    <updated>2018-08-02T03:17:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="java-concurrent-api-2">JAVA concurrent API 2</span></h1><h1><span id="futuretask">FutureTask</span></h1><p>FutureTask implements RunnableFutureRunnableFuture --&gt; Future and Runnable</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Sets this Future to the result of its computation</span><br><span class="line">     * unless it has been cancelled.</span><br><span class="line">     */</span><br><span class="line">    void run();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>功能： 将计算结果从执行计算的线程传递到获取这个结果的线程，而futuretask的规范确保了这种传递过程能实现结果的安全发布</p><p>使用futuretask来提前加载稍后需要的数据</p><h1><span id="callable">Callable</span></h1><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * A task that returns a result and may throw an exception.</span><br><span class="line"> * Implementors define a single method with no arguments called</span><br><span class="line"> * &#123;@code call&#125;.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;The &#123;@code Callable&#125; interface is similar to &#123;@link</span><br><span class="line"> * java.lang.Runnable&#125;, in that both are designed for classes whose</span><br><span class="line"> * instances are potentially executed by another thread.  A</span><br><span class="line"> * &#123;@code Runnable&#125;, however, does not return a result and cannot</span><br><span class="line"> * throw a checked exception.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;The &#123;@link Executors&#125; class contains utility methods to</span><br><span class="line"> * convert from other common forms to &#123;@code Callable&#125; classes.</span><br><span class="line"> *</span><br><span class="line"> * @see Executor</span><br><span class="line"> * @since 1.5</span><br><span class="line"> * @author Doug Lea</span><br><span class="line"> * @param &lt;V&gt; the result type of method &#123;@code call&#125;</span><br><span class="line"> */</span><br><span class="line">@FunctionalInterface</span><br><span class="line">public interface Callable&lt;V&gt; &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Computes a result, or throws an exception if unable to do so.</span><br><span class="line">     *</span><br><span class="line">     * @return computed result</span><br><span class="line">     * @throws Exception if unable to compute a result</span><br><span class="line">     */</span><br><span class="line">    V call() throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1><span id="future">Future</span></h1><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">* A &#123;@code Future&#125; represents the result of an asynchronous</span><br><span class="line">* computation.  Methods are provided to check if the computation is</span><br><span class="line">* complete, to wait for its completion, and to retrieve the result of</span><br><span class="line">* the computation.  The result can only be retrieved using method</span><br><span class="line">* &#123;@code get&#125; when the computation has completed, blocking if</span><br><span class="line">* necessary until it is ready.  Cancellation is performed by the</span><br><span class="line">* &#123;@code cancel&#125; method.  Additional methods are provided to</span><br><span class="line">* determine if the task completed normally or was cancelled. Once a</span><br><span class="line">* computation has completed, the computation cannot be cancelled.</span><br><span class="line">* If you would like to use a &#123;@code Future&#125; for the sake</span><br><span class="line">* of cancellability but not provide a usable result, you can</span><br><span class="line">* declare types of the form &#123;@code Future&lt;?&gt;&#125; and</span><br><span class="line">* return &#123;@code null&#125; as a result of the underlying task.</span><br></pre></td></tr></table></figure></p><p>good example usage<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">* interface ArchiveSearcher &#123; String search(String target); &#125;</span><br><span class="line">* class App &#123;</span><br><span class="line">*   ExecutorService executor = ...</span><br><span class="line">*   ArchiveSearcher searcher = ...</span><br><span class="line">*   void showSearch(final String target)</span><br><span class="line">*       throws InterruptedException &#123;</span><br><span class="line">*     Future&lt;String&gt; future</span><br><span class="line">*       = executor.submit(new Callable&lt;String&gt;() &#123;</span><br><span class="line">*         public String call() &#123;</span><br><span class="line">*             return searcher.search(target);</span><br><span class="line">*         &#125;&#125;);</span><br><span class="line">*     displayOtherThings(); // do other things while searching</span><br><span class="line">*     try &#123;</span><br><span class="line">*       displayText(future.get()); // use future</span><br><span class="line">*     &#125; catch (ExecutionException ex) &#123; cleanup(); return; &#125;</span><br><span class="line">*   &#125;</span><br><span class="line">* &#125;&#125;&lt;/pre&gt;</span><br></pre></td></tr></table></figure></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">The &#123;@link FutureTask&#125; class is an implementation of &#123;@code Future&#125; that</span><br><span class="line"> * implements &#123;@code Runnable&#125;, and so may be executed by an &#123;@code Executor&#125;.</span><br><span class="line"> * For example, the above construction with &#123;@code submit&#125; could be replaced by:</span><br><span class="line"> *  &lt;pre&gt; &#123;@code</span><br><span class="line"> * FutureTask&lt;String&gt; future =</span><br><span class="line"> *   new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() &#123;</span><br><span class="line"> *     public String call() &#123;</span><br><span class="line"> *       return searcher.search(target);</span><br><span class="line"> *   &#125;&#125;);</span><br><span class="line"> * executor.execute(future);&#125;&lt;/pre&gt;</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;Memory consistency effects: Actions taken by the asynchronous computation</span><br><span class="line"> * &lt;a href=&quot;package-summary.html#MemoryVisibility&quot;&gt; &lt;i&gt;happen-before&lt;/i&gt;&lt;/a&gt;</span><br><span class="line"> * actions following the corresponding &#123;@code Future.get()&#125; in another thread.</span><br></pre></td></tr></table></figure></p><h1><span id="httpswwwjournaldevcom1016java-thread-example">https://www.journaldev.com/1016/java-thread-example</span></h1><p>Multithreading refers to two or more threads executing concurrently in a single program. A computer single core processor can execute only one thread at a time and time slicing is the OS feature to share processor time between different processes and threads.</p><p>Runnable vs Threadextend Thread if u just want to run itimplements Runnable if u want to add more funtionality</p><p>start vs runThread.start() is required to actually create a new thread so that the runnable's run method is executed in parallel. The difference is that Thread.start() starts a thread that calls the run() method, while Runnable.run() just calls the run() method on the current thread.</p><p><strong>Thread implements Runnable</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;java-concurrent-api-2&quot;&gt;JAVA concurrent API 2&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;futuretask&quot;&gt;FutureTask&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Futu
      
    
    </summary>
    
    
      <category term="concurrency" scheme="http://www.yifanguo.top/tags/concurrency/"/>
    
  </entry>
  
  <entry>
    <title>aqs</title>
    <link href="http://www.yifanguo.top/2018/07/31/aqs/"/>
    <id>http://www.yifanguo.top/2018/07/31/aqs/</id>
    <published>2018-08-01T04:43:17.000Z</published>
    <updated>2018-08-01T06:31:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="aqs-abstractqueuedsynchronizer-队列同步器">AQS  AbstractQueuedSynchronizer 队列同步器</span></h1><p>AQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前线程获取同步状态失败（锁）时，AQS则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。</p><p>AQS主要提供了如下一些方法：</p><p>getState()：返回同步状态的当前值；setState(int newState)：设置当前同步状态；compareAndSetState(int expect, int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性；tryAcquire(int arg)：独占式获取同步状态，获取同步状态成功后，其他线程需要等待该线程释放同步状态才能获取同步状态；tryRelease(int arg)：独占式释放同步状态；tryAcquireShared(int arg)：共享式获取同步状态，返回值大于等于0则表示获取成功，否则获取失败；tryReleaseShared(int arg)：共享式释放同步状态；isHeldExclusively()：当前同步器是否在独占式模式下被线程占用，一般该方法表示是否被当前线程所独占；acquire(int arg)：独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进入同步队列等待，该方法将会调用可重写的tryAcquire(int arg)方法；acquireInterruptibly(int arg)：与acquire(int arg)相同，但是该方法响应中断，当前线程为获取到同步状态而进入到同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException异常并返回；tryAcquireNanos(int arg,long nanos)：超时获取同步状态，如果当前线程在nanos时间内没有获取到同步状态，那么将会返回false，已经获取则返回true；acquireShared(int arg)：共享式获取同步状态，如果当前线程未获取到同步状态，将会进入同步队列等待，与独占式的主要区别是在同一时刻可以有多个线程获取到同步状态；acquireSharedInterruptibly(int arg)：共享式获取同步状态，响应中断；tryAcquireSharedNanos(int arg, long nanosTimeout)：共享式获取同步状态，增加超时限制；release(int arg)：独占式释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒；releaseShared(int arg)：共享式释放同步状态；</p><h1><span id="clh-同步队列">CLH 同步队列</span></h1><p>CLH同步队列是一个FIFO双向队列，AQS依赖它来完成同步状态的管理，当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点唤醒（公平锁），使其再次尝试获取同步状态。</p><h1><span id="locksupport">LockSupport</span></h1><p>当需要阻塞或者唤起一个线程时 aqs都是调用lockSupport来执行底层是通过unsafe来实现的</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">public native void park(boolean var1, long var2);</span><br><span class="line">public native void unpark(Object var1);</span><br></pre></td></tr></table></figure></p><p>unpark函数为线程提供“许可(permit)”，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不能叠加的，“许可”是一次性的。</p><p>比如线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态。</p><p>注意，unpark函数可以先于park调用。比如线程B调用unpark函数，给线程A发了一个“许可”，那么当线程A调用park时，它发现已经有“许可”了，那么它会马上再继续运行。</p><p>实际上，park函数即使没有“许可”，有时也会无理由地返回，这点等下再解析。</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Parker : public os::PlatformParker &#123;</span><br><span class="line">private:</span><br><span class="line">  volatile int _counter ;</span><br><span class="line">  ...</span><br><span class="line">public:</span><br><span class="line">  void park(bool isAbsolute, jlong time);</span><br><span class="line">  void unpark();</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">class PlatformParker : public CHeapObj&lt;mtInternal&gt; &#123;</span><br><span class="line">  protected:</span><br><span class="line">    pthread_mutex_t _mutex [1] ;</span><br><span class="line">    pthread_cond_t  _cond  [1] ;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到Parker类实际上用Posix的mutex，condition来实现的。在Parker类里的_counter字段，就是用来记录所谓的“许可”的。</p><p>当调用park时，先尝试直接能否直接拿到“许可”，即_counter&gt;0时，如果成功，则把_counter设置为0,并返回：</p><h1><span id="parker类实际上用posix的mutexcondition来实现的">Parker类实际上用Posix的mutex，condition来实现的</span></h1><h1><span id="posix">Posix</span></h1><p>POSIX表示可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;aqs-abstractqueuedsynchronizer-队列同步器&quot;&gt;AQS  AbstractQueuedSynchronizer 队列同步器&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;AQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前
      
    
    </summary>
    
    
      <category term="concurrency" scheme="http://www.yifanguo.top/tags/concurrency/"/>
    
  </entry>
  
  <entry>
    <title>Atomic</title>
    <link href="http://www.yifanguo.top/2018/07/30/Atomic/"/>
    <id>http://www.yifanguo.top/2018/07/30/Atomic/</id>
    <published>2018-07-31T05:04:50.000Z</published>
    <updated>2018-07-31T05:11:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="atomicity-optimizations">Atomicity Optimizations</span></h1><p>If multiple threads modify the same memory location concurrently, processors do not guarantee any specific result.</p><h1><span id="lock">Lock</span></h1><p>Load Lock/Store Conditional (LL/SC)41 The LL/SC operations work as a pair where the special load instruction is used to start an transaction and the final store will only succeed if the location has not been modified in the meantime. The store oper- ation indicates success or failure, so the program can repeat its efforts if necessary.</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int curval;int newval;do &#123;  curval = LL(var);  newval = curval + addend;&#125; while (SC(var, newval));</span><br></pre></td></tr></table></figure></p><p>#CAS</p><p>Compare-and-Swap (CAS) This is a ternary operation which writes a value provided as a parameter into an address (the second parameter) only if the cur- rent value is the same as the third parameter value;</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int curval;</span><br><span class="line">int newval;</span><br><span class="line">do &#123;</span><br><span class="line">curval = var;</span><br><span class="line">  newval = curval + addend;</span><br><span class="line">&#125; while (CAS(&amp;var, curval, newval));</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;atomicity-optimizations&quot;&gt;Atomicity Optimizations&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;If multiple threads modify the same memory location concurrent
      
    
    </summary>
    
    
      <category term="concurrency" scheme="http://www.yifanguo.top/tags/concurrency/"/>
    
  </entry>
  
  <entry>
    <title>WhatEveryProgrammerShouldKnowAboutMemory</title>
    <link href="http://www.yifanguo.top/2018/07/30/WhatEveryProgrammerShouldKnowAboutMemory/"/>
    <id>http://www.yifanguo.top/2018/07/30/WhatEveryProgrammerShouldKnowAboutMemory/</id>
    <published>2018-07-30T12:25:51.000Z</published>
    <updated>2018-07-31T04:50:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="超线程">超线程</span></h1><p>refer: https://www.cnblogs.com/Amaranthus/archive/2013/07/09/3180036.htmlHyper-threading enables a single processor core to be used for two or more concurrent executions with just a little extra hardware.</p><h1><span id="现代计算机的架构">现代计算机的架构</span></h1><p>主要有两个部分组成，南北桥<img src="nsbridge.png" alt=""></p><p>All CPUs (two in the previous example, but there can be more) are connected via a common bus (the Front Side Bus, FSB) to the Northbridge.</p><p>所有的cpu都通过fsb连接到北桥 <strong>fsb已经被qpi淘汰</strong></p><h2><span id="北桥">北桥</span></h2><p>The Northbridge contains, among other things, the memory controller, and its im- plementation determines the type of RAM chips used for the computer. Different types of RAM, such as DRAM, Rambus, and SDRAM, require different memory con- trollers.</p><p>北桥包含了内存控制器，决定了RAM(random access memory)的类型</p><p>To reach all other system devices, the Northbridge must communicate with the Southbridge.为了接触到其他的devices, 北桥必须和南桥通信</p><h2><span id="南桥">南桥</span></h2><p>南桥又被称为  I/O bridge 通过一系列的bus和其他devices通信</p><p>the PCI, PCI Express, SATA, and USB buses are of most importance, but PATA, IEEE 1394, serial, and par- allel ports are also supported by the Southbridge.</p><p>However, today the PCI-E slots are all connected to the Southbridge.</p><p>这样的结构造成了以下的结果</p><p>##所有的data communication 从一个cpu到另一个cpu必须 travel over the same bus used to communicate with the Northbridge.<strong>这个已经有所改变，intel最新的多核处理器是通过qpi进行通信的</strong>qpi: quick path iterconnecthttps://www.intel.com/content/www/us/en/io/quickpath-technology/quick-path-interconnect-introduction-paper.html</p><p>The Intel QuickPath Interconnect (QPI) is a point-to-point processor interconnect developed by Intel which replaced the front-side bus (FSB) in Xeon, Itanium, and certain desktop platforms starting in 2008.  Prior to the name's announcement, Intel referred to it as Common System Interface (CSI).</p><p>... 2008年推出的技术，结果这篇文章是2007年的</p><p>QPI will be replaced by Intel UltraPath Interconnect (UPI) in future Skylake EX/EP Xeon processors based on LGA 3647 socket.[5]</p><p>QPI也要被淘汰...</p><p>the QuickPath Architecture assumes that the processors will have integrated memory controllers, and enables a non-uniform memory access (NUMA) architecture.</p><h2><span id="all-communication-with-ram-must-pass-through-the-northbridge">All communication with RAM must pass through the Northbridge.</span></h2><h2><span id="the-ram-has-only-a-single-port">The RAM has only a single port</span></h2><h2><span id="communication-between-a-cpu-and-a-device-at-tached-to-the-southbridge-is-routed-through-the-northbridge">Communication between a CPU and a device at- tached to the Southbridge is routed through the Northbridge.</span></h2><h1><span id="dma-direct-memory-access">DMA direct memory access</span></h1><p>DMA allows devices, with the help of the Northbridge, to store and receive data in RAM directly without the intervention of the CPU (and its inherent performance cost).</p><p>it also creates contention for the bandwidth of the Northbridge as DMA requests compete with RAM access from the CPUs.</p><ol><li>DMA允许设备直接和RAM交互</li><li>DMA会和CPU抢夺北桥带宽</li></ol><h1><span id="第二个bottleneck">第二个bottleneck</span></h1><p>recent RAM types require two sep- arate buses (or channels as they are called for DDR2, see page 8) which doubles the available bandwidth.</p><p>北桥和RAM之间的总线所以出现了双通道（可以实现带宽加倍，内存访问在两个通道上交错分配）</p><p>北桥自身不带内存控制器，而是连接到外部多个内存控制器上，好处是支持更多的内存，可以同时访问不同的内存区，降低了延迟，但是对北桥的内部带宽要求巨大。使用外部内存控制器并不是唯一的办法，比较流行的还有一种是把控制器集成到cpu内部，将内存直接连接到CPU<img src="nbridge.png" alt="">The advantage of this architecture is that more than one memory bus exists and therefore total available band- width increases</p><p>这样的架构，系统里有几个cpu就可以有几个内存库（memory bank），不需要强大的北桥就可以实现4倍的内存带宽。但是缺点也是很明显：1.导致内存不再是统一的资源（NUMA的得名），2.cpu可以正常的访问本地内存，但是访问其他内存时需要和其他cpu互通。在讨论访问远端内存的代价时，我们用「NUMA因子」这个词。比如说IBM的x445和SGI的Altix系列。CPU被归入节点，节点内的内存访问时间是一致的，或者只有很小的NUMA因子。而在节点之间的连接代价很大，而且有巨大的NUMA因子。</p><p>#CSIIntel will have support for the Common System Interface (CSI) starting with the Nehalem processors; this is basically the same approach: an integrated memory controller with the possibility of local memory for each processor.</p><p>cpu集成RAM</p><p><img src="imc.png" alt=""></p><p>优点：不需要北桥庞大的带宽缺点：memory is not uniform ( numa- non uniform memroy architecture)</p><h1><span id="ram-types">RAM types</span></h1><p>RAM主要分为2类静态RAM，动态RAM，前者速度快，代价搞，后者速度慢代价低</p><p>SRAM 比DRAM 更贵</p><h1><span id="static-ram">static RAM</span></h1><p><img src="SRAM.png" alt=""></p><p>6个二极管组成的static dram</p><p>They have two stable states, representing 0 and 1 respectively. The state is stable as long as power on Vdd is available.</p><p><strong>这张图就充分说明了为什么断电RAM中的内容会消失</strong></p><p>主要有6个晶体管组成，核心是4个晶体管M1-M4,他们有2个稳定状态分别代表0和1</p><p>If access to the state of the cell is needed the word access line WL is raised. This makes the state of the cell imme- diately available for reading on BL and BL. If the cell state must be overwritten the BL and BL lines are first set to the desired values and then WL is raised. Since the outside drivers are stronger than the four transistors (M1 through M4) this allows the old state to be overwritten.</p><h2><span id="sram的特点">SRAM的特点</span></h2><p>• one cell requires six transistors. There are variants with four transistors but they have disadvantages.• maintaining the state of the cell requires constant power.• the cell state is available for reading almost im- mediately once the word access line WL is raised. The signal is as rectangular (changing quickly be- tween the two binary states) as other transistor- controlled signals.• the cell state is stable, no refresh cycles are needed.</p><h1><span id="dynamic-ram">Dynamic RAM</span></h1><p><img src="dram.png" alt=""></p><p>All it consists of is one transistor and one capacitor动态RAM只有一个晶体管和一个电容</p><ol><li>A dynamic RAM cell keeps its state in the capacitor C.</li><li>The transistor M is used to guard the access to the state.</li><li>To read the state of the cell the access line AL is raised;</li><li>this either causes a current to flow on the data line DL or not, depending on the charge in the capacitor.</li><li>To write to the cell the data line DL is appropriately set and then AL is raised for a time long enough to charge or drain the capacitor.</li></ol><p>disadvantages:</p><h2><span id="readiing-the-cell-discharges-the-capacitor">readiing the cell discharges the capacitor</span></h2><p>动态RAM优点是简单，但是缺点是由于读取状态时需要对电容器放电，所以这一过程不能无限重复，不得不在某个点上对它重新充电。更糟糕的是，为了容纳大量单元(现在一般在单个芯片上容纳10的9次方以上的RAM单元)，电容器的容量必须很小(0.000000000000001法拉以下)。这样，完整充电后大约持有几万个电子。即使电容器的电阻很大(若干兆欧姆)，仍然只需很短的时间就会耗光电荷，称为「泄漏」。</p><p><strong>这种泄露就是现在的大部分DRAM芯片每隔64ms就必须进行一次刷新的原因。（附A关于三极管的输入输出特性</strong></p><p>During the refresh cycle no access to the memory is possible since a refresh is simply a memory read operation where the result is discarded.</p><p>For some workloads this overhead might stall up to 50% of the memory accesses</p><h2><span id="a-second-problem-resulting-from-the-tiny-charge-is-that-the-information-read-from-the-cell-is-not-directly-usable">A second problem resulting from the tiny charge is that the information read from the cell is not directly usable.</span></h2><p>The data line must be connected to a sense amplifier which can distinguish between a stored 0 or 1 over the whole range of charges which still have to count as 1.</p><h2><span id="a-third-problem-is-that-reading-a-cell-causes-the-charge-of-the-capacitor-to-be-depleted">A third problem is that reading a cell causes the charge of the capacitor to be depleted.</span></h2><p>This means every read operation must be followed by an operation to recharge the capacitor.</p><h2><span id="高能预警why-sram-is-faster-than-dram">高能预警，why sram is faster than dram</span></h2><p>Unlike the static RAM case where the output is immediately available when the word access line is raised, it will always take a bit of time until the capacitor discharges sufficiently. This delay severely limits how fast DRAM can be.</p><p>因为DRAM把01状态保存在电容里，导致每次读都需要电容放电</p><h2><span id="dram-优势-size">DRAM 优势 --size</span></h2><p>The SRAM cells also need individual power for the transistors maintaining the state.</p><h1><span id="dram-access">DRAM access</span></h1><p>A program selects a memory location using a virtual address</p><p>The processor translates this into a physical address and finally the memory controller selects the RAM chip corresponding to that address.</p><p>Dynamic RAM Schematic</p><p><img src="data.png" alt=""></p><p>de-multiplexier<img src="demultiplexer" alt=""></p><p>The memory controller must be able to address each RAM module (collection of RAM chips).</p><h1><span id="sram-vs-dram">SRAM vs DRAM</span></h1><p>SRAM is currently used in CPU caches and on-die where the connections are small and fully under control of the CPU designer.</p><h1><span id="dram-access-technical-details">DRAM Access Technical Details</span></h1><ol><li>In the section introducing DRAM we saw that DRAM chips multiplex the addresses in order to save resources int the form of address pins.</li><li>We also saw that access- ing DRAM cells takes time since the capacitors in those cells do not discharge instantaneously to produce a stable signal</li><li>we also saw that DRAM cells must be refreshed.</li></ol><h1><span id="dram-sdram-and-its-successors-double-data-rate-dram-ddr">DRAM (SDRAM) and its successors Double Data Rate DRAM (DDR).</span></h1><h1><span id="sdram-synchronous-dram">SDRAM - Synchronous DRAM</span></h1><p>同步DRAM，顾名思义，是参照一个时间源工作的。由内存控制器提供一个时钟，时钟的频率决定了前端总线(FSB)的速度。以今天的SDRAM为例，每次数据传输包含64位，即8字节。所以FSB的传输速率应该是有效总线频率乘于8字节(对于4倍传输200MHz总线而言，传输速率为6.4GB/s)。听起来很高，但要知道这只是峰值速率，实际上无法达到的最高速率。我们将会看到，与RAM模块交流的协议有大量时间是处于非工作状态，不进行数据传输。我们必须对这些非工作时间有所了解，并尽量缩短它们，才能获得最佳的性能。</p><h1><span id="221读访问协议">2.2.1读访问协议</span></h1><p>这里忽略了许多细节，我们只关注时钟频率、RAS与CAS信号、地址总线和数据总线。首先，内存控制器将行地址放在地址总线上，并降低RAS信号，读周期开始。所有信号都在时钟(CLK)的上升沿读取，因此，只要信号在读取的时间点上保持稳定，就算不是标准的方波也没有关系。设置行地址会促使RAM芯片锁住指定的行。</p><p>CAS信号在tRCD(RAS到CAS时延)个时钟周期后发出。内存控制器将列地址放在地址总线上，降低CAS线。这里我们可以看到，地址的两个组成部分是怎么通过同一条总线传输的。</p><p>既然数据的传输需要这么多的准备工作，仅仅传输一个字显然是太浪费了。因此，DRAM模块允许内存控制指定本次传输多少数据。可以是2、4或8个字。这样，就可以一次填满高速缓存的整条线，而不需要额外的RAS/CAS序列。另外，内存控制器还可以在不重置行选择的前提下发送新的CAS信号。这样，读取或写入连续的地址就可以变得非常快，因为不需要发送RAS信号，也不需要把行置为非激活状态(见下文)。</p><p>在上图中，SDRAM的每个周期输出一个字的数据。这是第一代的SDRAM。而DDR可以在一个周期中输出两个字。这种做法可以减少传输时间，但无法降低时延。</p><p><img src="address.png" alt=""></p><h1><span id="222预充电和激活">2.2.2预充电和激活</span></h1><p>2.2.1中的图只是读取数据的一部分，还有以下部分：</p><p>显示的是两次CAS信号的时序图。第一次的数据在CL周期后准备就绪。图中的例子里，是在SDRAM上，用两个周期传输了两个字的数据。如果换成DDR的话，则可以传输4个字。即使是在一个命令速率为1的DRAM模块上，也无法立即发出预充电命令，而要等数据传输完成。在上图中，即为两个周期。刚好与CL相同，但只是巧合而已。预充电信号并没有专用线，某些实现是用同时降低写使能(WE)线和RAS线的方式来触发。</p><p>发出预充电信命令后，还需等待tRP(行预充电时间)个周期之后才能使行被选中。在图2.9中，这个时间(紫色部分)大部分与内存传输的时间(淡蓝色部分)重合。不错。但tRP大于传输时间，因此下一个RAS信号只能等待一个周期。</p><p>数据总线的7个周期中只有2个周期才是真正在用的。再用它乘于FSB速度，结果就是，800MHz总线的理论速率6.4GB/s降到了1.8GB/s</p><p>我们会看到预充电指令被数据传输时间限制（途中为COL Addr的传输）除此之外，SDRAM模块在RAS信号之后，需要经过一段时间，才能进行预充电(记为tRAS)（minimum active to precharge time（也就是RAS信号之后到充电的最小时间间隔））它的值很大，一般达到tRP的2到3倍。如果在某个RAS信号之后，只有一个CAS信号，而且数据只传输很少几个周期，那么就有问题了。假设在图2.9中，第一个CAS信号是直接跟在一个RAS信号后免的，而tRAS为8个周期。那么预充电命令还需要被推迟一个周期，因为tRCD、CL和tRP加起来才7个周期。</p><p>DDR模块往往用w-z-y-z-T来表示。例如，2-3-2-8-T1，意思是：</p><p>w 2 CAS时延(CL)x 3 RAS-to-CAS时延(t RCD)y 2 RAS预充电时间(t RP)z 8 激活到预充电时间(t RAS)T T1 命令速率</p><h1><span id="223重充电">2.2.3重充电</span></h1><p>充电对内存是性能最大的影响，根据JEDEC规范，DRAM单元必须保持每64ms刷新一次我们在解读性能参数时有必要知道，它也是DRAM生命周期的一个部分。如果系统需要读取某个重要的字，而刚好它所在的行正在刷新，那么处理器将会被延迟很长一段时间。刷新的具体耗时取决于DRAM模块本身。</p><h1><span id="225-结论">2.2.5 结论</span></h1><p>通过本节，大家应该了解到访问DRAM的过程并不是一个快速的过程。至少与处理器的速度相比，或与处理器访问寄存器及缓存的速度相比，DRAM的访问不算快。大家还需要记住CPU和内存的频率是不同的。Intel Core 2处理器运行在2.933GHz，而1.066GHz FSB有11:1的时钟比率(注: 1.066GHz的总线为四泵总线)。那么，内存总线上延迟一个周期意味着处理器延迟11个周期。绝大多数机器使用的DRAM更慢，因此延迟更大。前文中读命令的时序图表明，DRAM模块可以支持高速数据传输。每个完整行可以被毫无延迟地传输。数据总线可以100%被占。对DDR而言，意味着每个周期传输2个64位字。对于DDR2-800模块和双通道而言，意味着12.8GB/s的速率。</p><p>但是，除非是特殊设计，DRAM的访问并不总是串行的。访问不连续的内存区意味着需要预充电和RAS信号。于是，各种速度开始慢下来，DRAM模块急需帮助。预充电的时间越短，数据传输所受的惩罚越小。</p><p>硬件和软件的预取(参见第6.3节)可以在时序中制造更多的重叠区，降低延迟。预取还可以转移内存操作的时间，从而减少争用。我们常常遇到的问题是，在这一轮中生成的数据需要被存储，而下一轮的数据需要被读出来。通过转移读取的时间，读和写就不需要同时发出了</p><p>2.3主存的其他用户除了CPU外，系统中还有其它一些组件也可以访问主存。高性能网卡或大规模存储控制器是无法承受通过CPU来传输数据的，它们一般直接对内存进行读写(直接内存访问，DMA)。在图2.1中可以看到，它们可以通过南桥和北桥直接访问内存。另外，其它总线，比如USB等也需要FSB带宽，即使它们并不使用DMA，但南桥仍要通过FSB连接到北桥。</p><p>DMA当然有很大的优点，但也意味着FSB带宽会有更多的竞争。在有大量DMA流量的情况下，CPU在访问内存时必然会有更大的延迟。我们可以用一些硬件来解决这个问题。例如，通过图2.3中的架构，我们可以挑选不受DMA影响的节点，让它们的内存为我们的计算服务。还可以在每个节点上连接一个南桥，将FSB的负荷均匀地分担到每个节点上。</p><h1><span id="what-programmer-can-do">what programmer can do</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;超线程&quot;&gt;超线程&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;refer: https://www.cnblogs.com/Amaranthus/archive/2013/07/09/3180036.html
Hyper-threading enables a si
      
    
    </summary>
    
    
      <category term="core" scheme="http://www.yifanguo.top/tags/core/"/>
    
  </entry>
  
  <entry>
    <title>lock</title>
    <link href="http://www.yifanguo.top/2018/07/30/lock/"/>
    <id>http://www.yifanguo.top/2018/07/30/lock/</id>
    <published>2018-07-30T11:46:26.000Z</published>
    <updated>2018-07-30T12:09:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="深入理解锁机制的实现">深入理解锁机制的实现</span></h1><h1><span id="cas">CAS</span></h1><p>Unsafe中有一个method compareAndSwapInt 实现的是无锁同步的机制我们看下它是如何实现的</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/***</span><br><span class="line">         * Compares the value of the integer field at the specified offset</span><br><span class="line">         * in the supplied object with the given expected value, and updates</span><br><span class="line">         * it if they match.  The operation of this method should be atomic,</span><br><span class="line">         * thus providing an uninterruptible way of updating an integer field.</span><br><span class="line">         * 在obj的offset位置比较integer field和期望的值，如果相同则更新。这个方法</span><br><span class="line">         * 的操作应该是原子的，因此提供了一种不可中断的方式更新integer field。</span><br><span class="line">         *</span><br><span class="line">         * @param obj the object containing the field to modify.</span><br><span class="line">         *            包含要修改field的对象</span><br><span class="line">         * @param offset the offset of the integer field within &lt;code&gt;obj&lt;/code&gt;.</span><br><span class="line">         *               &lt;code&gt;obj&lt;/code&gt;中整型field的偏移量</span><br><span class="line">         * @param expect the expected value of the field.</span><br><span class="line">         *               希望field中存在的值</span><br><span class="line">         * @param update the new value of the field if it equals &lt;code&gt;expect&lt;/code&gt;.</span><br><span class="line">         *           如果期望值expect与field的当前值相同，设置filed的值为这个新值</span><br><span class="line">         * @return true if the field was changed.</span><br><span class="line">         *                             如果field的值被更改</span><br><span class="line">         */</span><br><span class="line">         </span><br><span class="line">public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);</span><br></pre></td></tr></table></figure></p><p>调用了JNI，也就是说有对应的unsafe.cpp的接口 如下：</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))</span><br><span class="line">  UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;);</span><br><span class="line">  oop p = JNIHandles::resolve(obj);</span><br><span class="line">  //获取对象的变量的地址</span><br><span class="line">  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);</span><br><span class="line">  //调用Atomic操作</span><br><span class="line">  //进入atomic.hpp,大意就是先去获取一次结果，如果结果和现在不同，就直接返回，因为有其他人修改了；否则会一直尝试去修改。直到成功。</span><br><span class="line">  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;</span><br><span class="line">UNSAFE_END</span><br></pre></td></tr></table></figure></p><p>再来看atomic::cmpxchg这个方法实现，这是一个c++的库</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">jbyte Atomic::cmpxchg(jbyte exchange_value, volatile jbyte* dest, jbyte compare_value) &#123;</span><br><span class="line">  assert(sizeof(jbyte) == 1, &quot;assumption.&quot;);</span><br><span class="line">  uintptr_t dest_addr = (uintptr_t)dest;</span><br><span class="line">  uintptr_t offset = dest_addr % sizeof(jint);</span><br><span class="line">  volatile jint* dest_int = (volatile jint*)(dest_addr - offset);</span><br><span class="line">  jint cur = *dest_int;</span><br><span class="line">  jbyte* cur_as_bytes = (jbyte*)(&amp;cur);</span><br><span class="line">  jint new_val = cur;</span><br><span class="line">  jbyte* new_val_as_bytes = (jbyte*)(&amp;new_val);</span><br><span class="line">  new_val_as_bytes[offset] = exchange_value;</span><br><span class="line">  while (cur_as_bytes[offset] == compare_value) &#123;</span><br><span class="line">    jint res = cmpxchg(new_val, dest_int, cur);</span><br><span class="line">    if (res == cur) break;</span><br><span class="line">    cur = res;</span><br><span class="line">    new_val = cur;</span><br><span class="line">    new_val_as_bytes[offset] = exchange_value;</span><br><span class="line">  &#125;</span><br><span class="line">  return cur_as_bytes[offset];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>jint* dest_int 做了volatile，意味着值不会从cpu cache中获取，会从主内存中获取</p><p>CAS是Compare And Set的缩写。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。</p><h1><span id="x86">x86</span></h1><p>CAS保证了原子性，原子性定义Atomic Variables. The java.util.concurrent.atomic package defines classes that support atomic operations on single variables. All classes have get and set methods that work like reads and writes on volatile variables. That is, a set has a happens-before relationship with any subsequent get on the same variable.</p><p>简单来说就是原子变量一旦开始操作就不会做context switch（切换到另一个线程），直到运行结束。</p><h2><span id="什么情况下适合用atomic类">什么情况下适合用atomic类</span></h2><p>Atomic classes are designed primarily as building blocks for implementing non-blocking data structures and related infrastructure classes. The compareAndSet method is not a general replacement for locking. It applies only when critical updates for an object are confined to a single variable.</p><p>那么在x86架构中是如何实现的</p><h1><span id="m-threads-同时-sharedcounter">M threads 同时++ sharedCounter</span></h1><p>non-volatile version:add    $0x10,%ecx</p><p>volatile version:mov    0xc(%r10),%r8d ; Loadinc    %r8d           ; Incrementmov    %r8d,0xc(%r10) ; Storelock addl $0x0,(%rsp) ; StoreLoad Barrier</p><p>makes every store before the lock addl visible to other processors, and ensures that every load after the lock addl gets at least the version visible at the time it is executed. In this case, volatile gives visibility, in that each of the processors immediately gets the version from the other processors after each increment.</p><p>AtomicInteger version:</p><p>mov    0xc(%r11),%eax       ; Loadmov    %eax,%r8d<br>inc    %r8d                 ; Incrementlock cmpxchg %r8d,0xc(%r11) ; Compare and exchange</p><p>cmpxchg:Compares the value in the EAX register with the destination operand. If the two values are equal, the source operand is loaded into the destination operand. Otherwise, the destination operand is loaded into the EAX register.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;深入理解锁机制的实现&quot;&gt;深入理解锁机制的实现&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;cas&quot;&gt;CAS&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;Unsafe中有一个method compareAndSwapInt 实现的是无
      
    
    </summary>
    
    
      <category term="lock" scheme="http://www.yifanguo.top/tags/lock/"/>
    
  </entry>
  
  <entry>
    <title>unix network programming</title>
    <link href="http://www.yifanguo.top/2018/07/30/unix/"/>
    <id>http://www.yifanguo.top/2018/07/30/unix/</id>
    <published>2018-07-30T08:53:18.000Z</published>
    <updated>2018-07-30T09:07:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="unix-network-programming-learning-notes">unix network programming learning notes</span></h1><p>daemon: 后台程序</p><p>a Web server is typically thought of as a long-running program (or daemon) that sends network messages only in response to requests coming in from the network. The other side of the protocol is a Web client, such as a browser, which always initiates communication with the server.</p><p>Web clients and servers communicate using the Transmission Control Protocol, or TCP. TCP, in turn, uses the Internet Protocol, or IP, and IP communicates with a datalink layer of some form.</p><p><img src="tcp.png" alt=""></p><p>Even though the client and server communicate using an application protocol, the transport layers communicate using TCP</p><p>he client and server need not be attached to the same local area network (LAN) as we show in Figure 1.3. For instance, in Figure 1.4, we show the client and server on different LANs, with both LANs connected to a wide area network (WAN) using routers.</p><p><img src="wan.png" alt=""></p><p>The largest WAN today is the Internet.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;unix-network-programming-learning-notes&quot;&gt;unix network programming learning notes&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;daemon: 后台程序&lt;/p&gt;
&lt;p&gt;a Web serv
      
    
    </summary>
    
    
      <category term="unix" scheme="http://www.yifanguo.top/tags/unix/"/>
    
  </entry>
  
  <entry>
    <title>linux_sychronization</title>
    <link href="http://www.yifanguo.top/2018/07/30/linux-sychronization/"/>
    <id>http://www.yifanguo.top/2018/07/30/linux-sychronization/</id>
    <published>2018-07-30T08:41:38.000Z</published>
    <updated>2018-07-30T08:47:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="linux中常见同步机制设计原理">Linux中常见同步机制设计原理</span></h1><p>-谈谈linux中常见并发访问的保护机制设计原理</p><h1><span id="自旋锁spin-lock">自旋锁（spin lock）</span></h1><p>自旋锁是linux中使用非常频繁的锁，原理简单。当进程A申请锁成功后，进程B申请锁就会失败，但是不会调度，原地自旋。就在原地转到天昏地暗只为等到进程A释放锁。由于不会睡眠和调度的特性，在中断上下文中，数据的保护一般都是选择自旋锁。如果有多个进程去申请锁。当第一个申请锁成功的线程在释放的时候，其他进程是竞争的关系。因此是一种不公平。所以现在的linux采用的是排队机制。先到先得。谁先申请，谁就先得到锁</p><h2><span id="next-and-owner">next and owner</span></h2><p>linux中针对每一个spin lock会有两个计数。分别是next和owner（初始值为0）。进程A申请锁时，会判断next和owner的值是否相等。如果相等就代表锁可以申请成功，否则原地自旋。直到owner和next的值相等才会退出自旋。假设进程A申请锁成功，然后会next加1。此时owner值为0，next值为1。进程B也申请锁，保存next得值到局部变量tmp（tmp = 1）中。由于next和owner值不相等，因此原地自旋读取owner的值，判断owner和tmp是否相等，直到相等退出自旋状态。当然next的值还是加1，变成2。进程A释放锁，此时会将owner的值加1，那么此时B进程的owner和tmp的值都是1，因此B进程获得锁。当B进程释放锁后，同样会将owner的值加1。最后owner和next都等于2，代表没有进程持有锁。next就是一个记录申请锁的次数，而owner是持有锁进程的计数值。</p><h1><span id="信号量semaphore">信号量（semaphore）</span></h1><p>信号量（semaphore）是进程间通信处理同步互斥的机制。是在多线程环境下使用的一种措施，它负责协调各个进程，以保证他们能够正确、合理的使用公共资源。 它和spin lock最大的不同之处就是：无法获取信号量的进程可以睡眠，因此会导致系统调度。</p><h2><span id="原理">原理</span></h2><p>信号量一般可以用来标记可用资源的个数。老规矩，还是举个例子。假设图书馆有2本《C语言从入门到放弃》书籍。A同学想学C语言，于是发现这本书特别的好。于是就去学校的图书馆借书，A同学成功的从图书馆借走一本。这时，A同学室友B同学发现A同学竟然在偷偷的学习武功秘籍（C语言）。于是，B同学也去借一本。此时，图书馆已经没有书了。C同学也想借这本书，可能是这本书太火了。图书馆管理员告诉C同学，图书馆这本书都被借走了。如果有同学换回来，会第一时间通知你。于是，管理员就把C同学的信息登记先来，以备后续通知C同学来借书。所以，C同学只能悲伤的走了（如果是自旋锁的原理的话，那么C同学将会端个小板凳坐在图书馆，一直要等到A同学或者B同学还书并借走）。</p><h1><span id="读写锁read-write-lock">读写锁（read-write lock）</span></h1><p>不管是自旋锁还是信号量在同一时间只能有一个进程进入临界区。对于有些情况，我们是可以区分读写操作的。因此，我们希望对于读操作的进程可以并发进行。对于写操作只限于一个进程进入临界区。而这种同步机制就是读写锁。读写锁一般具有以下几种性质。同一时间有且仅有一个写进程进入临界区。在没有写进程进入临界区的时候，同时可以有多个读进程进入临界区。读进程和写进程不可以同时进入临界区。读写锁有两种，一种是信号量类型，另一种是spin lock类型。下面以spin lock类型讲解。</p><p>##原理老规矩，还是举个例子理解读写锁。我绞尽脑汁才想到一个比较贴切的例子。这个例子来源于生活。我发现公司一般都会有保洁阿姨打扫厕所。如果以男厕所为例的话，我觉得男士进入厕所就相当于读者进入临界区。因为可以有多个男士进厕所。而保洁阿姨进入男士厕所就相当于写者进入临界区。假设A男士发现保洁阿姨不在打扫厕所，就进入厕所。随后B和C同时也进入厕所。然后保洁阿姨准备打扫厕所，发现有男士在厕所里面，因此只能在门口等待。ABC都离开了厕所。保洁阿姨迅速进入厕所打扫。然后D男士去上厕所，发现保洁阿姨在里面。灰溜溜的出来了在门口等着。现在体会到了写者（保洁阿姨）具有排他性，读者（男士）可以并发进入临界区了吧。</p><p>既然我们允许多个读者进入临界区，因此我们需要一个计数统计读者的个数。同时，由于写者永远只存在一个进入临界区，因此只需要一个bit标记是否有写进程进入临界区。所以，我们可以将两个计数合二为一。只需要1个unsigned int类型即可。最高位（bit31）代表是否有写者进入临界区，低31位（0~30bit）统计读者个数。</p><h1><span id="互斥量mutex">互斥量（mutex）</span></h1><p>前文提到的semaphore在初始化count计数的时候，可以分为计数信号量和互斥信号量（二值信号量）。mutex和初始化计数为1的二值信号量有很大的相似之处。他们都可以用做资源互斥。但是mutex却有一个特殊的地方：只有持锁者才能解锁。但是，二值信号量却可以在一个进程中获取信号量，在另一个进程中释放信号量。如果是应用在嵌入式应用的RTOS，针对mutex的实现还会考虑优先级反转问题。</p><p>原理既然mutex是一种二值信号量，因此就不需要像semaphore那样需要一个count计数。由于mutex具有“持锁者才能解锁”的特点，所以我们需要一个变量owner记录持锁进程。释放锁的时候必须是同一个进程才能释放。当然也需要一个链表头，主要用来便利睡眠等待的进程。原理和semaphore及其相似，因此在代码上也有体现。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;linux中常见同步机制设计原理&quot;&gt;Linux中常见同步机制设计原理&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;-谈谈linux中常见并发访问的保护机制设计原理&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;自旋锁spin-lock&quot;&gt;自旋锁（spin lock）&lt;/spa
      
    
    </summary>
    
    
      <category term="linux" scheme="http://www.yifanguo.top/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux_kernel</title>
    <link href="http://www.yifanguo.top/2018/07/30/linux-kernel/"/>
    <id>http://www.yifanguo.top/2018/07/30/linux-kernel/</id>
    <published>2018-07-30T08:21:17.000Z</published>
    <updated>2018-07-30T08:41:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="linux-kernel">linux kernel</span></h1><ol><li><p>Process Scheduler，也称作进程管理、进程调度。负责管理CPU资源，以便让各个进程可以以尽量公平的方式访问CPU。</p></li><li><p>Memory Manager，内存管理。负责管理Memory（内存）资源，以便让各个进程可以安全地共享机器的内存资源。另外，内存管理会提供虚拟内存的机制，该机制可以让进程使用多于系统可用Memory的内存，不用的内存会通过文件系统保存在外部非易失存储器中，需要使用的时候，再取回到内存中。</p></li><li><p>VFS（Virtual File System），虚拟文件系统。Linux内核将不同功能的外部设备，例如Disk设备（硬盘、磁盘、NAND Flash、Nor Flash等）、输入输出设备、显示设备等等，抽象为可以通过统一的文件操作接口（open、close、read、write等）来访问。这就是Linux系统“一切皆是文件”的体现（其实Linux做的并不彻底，因为CPU、内存、网络等还不是文件，如果真的需要一切皆是文件，还得看贝尔实验室正在开发的&quot;Plan 9”的）。</p></li><li><p>Network，网络子系统。负责管理系统的网络设备，并实现多种多样的网络标准。</p></li><li><p>IPC（Inter-Process Communication），进程间通信。IPC不管理任何的硬件，它主要负责Linux系统中进程之间的通信。</p></li></ol><h1><span id="process-scheduler">Process Scheduler</span></h1><p>进程调度是Linux内核中最重要的子系统，它主要提供对CPU的访问控制。因为在计算机中，CPU资源是有限的，而众多的应用程序都要使用CPU资源，所以需要“进程调度子系统”对CPU进行调度管理。</p><p><img src="linux.png" alt=""></p><ol><li><p>Scheduling Policy，实现进程调度的策略，它决定哪个（或哪几个）进程将拥有CPU。</p></li><li><p>Architecture-specific Schedulers，体系结构相关的部分，用于将对不同CPU的控制，抽象为统一的接口。这些控制主要在suspend和resume进程时使用，牵涉到CPU的寄存器访问、汇编指令操作等。</p></li><li><p>Architecture-independent Scheduler，体系结构无关的部分。它会和“Scheduling Policy模块”沟通，决定接下来要执行哪个进程，然后通过“Architecture-specific Schedulers模块”resume指定的进程。</p></li><li><p>System Call Interface，系统调用接口。进程调度子系统通过系统调用接口，将需要提供给用户空间的接口开放出去，同时屏蔽掉不需要用户空间程序关心的细节。</p></li></ol><h1><span id="memory-manager">Memory Manager</span></h1><p><img src="mm.png" alt=""></p><ol><li><p>Architecture Specific Managers，体系结构相关部分。提供用于访问硬件Memory的虚拟接口。</p></li><li><p>Architecture Independent Manager，体系结构无关部分。提供所有的内存管理机制，包括：以进程为单位的memory mapping；虚拟内存的Swapping。</p></li><li><p>System Call Interface，系统调用接口。通过该接口，向用户空间程序应用程序提供内存的分配、释放，文件的map等功能。</p></li></ol><h1><span id="虚拟文件系统virtual-filesystem-vfs">虚拟文件系统（Virtual Filesystem, VFS）</span></h1><p><img src="vfs.png" alt=""></p><ol><li><p>Device Drivers，设备驱动，用于控制所有的外部设备及控制器。由于存在大量不能相互兼容的硬件设备（特别是嵌入式产品），所以也有非常多的设备驱动。因此，Linux内核中将近一半的Source Code都是设备驱动，大多数的Linux底层工程师（特别是国内的企业）都是在编写或者维护设备驱动，而无暇估计其它内容（它们恰恰是Linux内核的精髓所在）。</p></li><li><p>Device Independent Interface， 该模块定义了描述硬件设备的统一方式（统一设备模型），所有的设备驱动都遵守这个定义，可以降低开发的难度。同时可以用一致的形势向上提供接口。</p></li><li><p>Logical Systems，每一种文件系统，都会对应一个Logical System（逻辑文件系统），它会实现具体的文件系统逻辑。</p></li><li><p>System Independent Interface，该模块负责以统一的接口（快设备和字符设备）表示硬件设备和逻辑文件系统，这样上层软件就不再关心具体的硬件形态了。</p></li><li><p>System Call Interface，系统调用接口，向用户空间提供访问文件系统和硬件设备的统一的接口。</p></li></ol><h1><span id="网络子系统net">网络子系统（Net）</span></h1><p><img src="net.png" alt=""></p><ol><li><p>Network Device Drivers，网络设备的驱动，和VFS子系统中的设备驱动是一样的。</p></li><li><p>Device Independent Interface，和VFS子系统中的是一样的。</p></li><li><p>Network Protocols，实现各种网络传输协议，例如IP, TCP, UDP等等。</p></li><li><p>Protocol Independent Interface，屏蔽不同的硬件设备和网络协议，以相同的格式提供接口（socket)。</p></li><li><p>System Call interface，系统调用接口，向用户空间提供访问网络设备的统一的接口。</p></li></ol><h1><span id="linux内核源代码的目录结构">Linux内核源代码的目录结构</span></h1><ol><li><p>内核核心代码，包括第3章所描述的各个子系统和子模块，以及其它的支撑子系统，例如电源管理、Linux初始化等</p></li><li><p>其它非核心代码，例如库文件（因为Linux内核是一个自包含的内核，即内核不依赖其它的任何软件，自己就可以编译通过）、固件集合、KVM（虚拟机技术）等</p></li><li><p>编译脚本、配置文件、帮助文档、版权说明等辅助性文件</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;linux-kernel&quot;&gt;linux kernel&lt;/span&gt;&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Process Scheduler，也称作进程管理、进程调度。负责管理CPU资源，以便让各个进程可以以尽量公平的方式访问C
      
    
    </summary>
    
    
      <category term="linux" scheme="http://www.yifanguo.top/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>dubboRpc</title>
    <link href="http://www.yifanguo.top/2018/07/29/dubboRpc/"/>
    <id>http://www.yifanguo.top/2018/07/29/dubboRpc/</id>
    <published>2018-07-30T04:51:28.000Z</published>
    <updated>2018-07-30T04:51:49.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="rpc" scheme="http://www.yifanguo.top/tags/rpc/"/>
    
  </entry>
  
  <entry>
    <title>rxjava</title>
    <link href="http://www.yifanguo.top/2018/07/29/rxjava/"/>
    <id>http://www.yifanguo.top/2018/07/29/rxjava/</id>
    <published>2018-07-30T03:56:42.000Z</published>
    <updated>2018-07-30T04:23:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="backpressure">backpressure</span></h1><p>背压是指在异步场景中，被观察者发送事件速度远快于观察者的处理速度的情况下，一种告诉上游的被观察者降低发送速度的策略。</p><h1><span id="observer-pattern">Observer pattern</span></h1><p>RxJava 以观察者模式为骨架Observable ( 被观察者 ) / Observer ( 观察者 )Flowable （被观察者）/ Subscriber （观察者）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;backpressure&quot;&gt;backpressure&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;背压是指在异步场景中，被观察者发送事件速度远快于观察者的处理速度的情况下，一种告诉上游的被观察者降低发送速度的策略。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;observe
      
    
    </summary>
    
    
      <category term="reactive" scheme="http://www.yifanguo.top/tags/reactive/"/>
    
  </entry>
  
  <entry>
    <title>vertxDemos</title>
    <link href="http://www.yifanguo.top/2018/07/29/vertxDemos/"/>
    <id>http://www.yifanguo.top/2018/07/29/vertxDemos/</id>
    <published>2018-07-30T02:53:32.000Z</published>
    <updated>2018-07-30T02:53:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="几个vertx搭建的demo">几个vertx搭建的demo</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;几个vertx搭建的demo&quot;&gt;几个vertx搭建的demo&lt;/span&gt;&lt;/h1&gt;

      
    
    </summary>
    
    
      <category term="reactive" scheme="http://www.yifanguo.top/tags/reactive/"/>
    
  </entry>
  
</feed>
