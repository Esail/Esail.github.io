<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yifan Guo Personal Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.yifanguo.top/"/>
  <updated>2018-12-26T11:29:04.000Z</updated>
  <id>http://www.yifanguo.top/</id>
  
  <author>
    <name>Yifan Guo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>美团机器学习实践阅读笔记</title>
    <link href="http://www.yifanguo.top/2018/12/26/%E7%BE%8E%E5%9B%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.yifanguo.top/2018/12/26/美团机器学习实践阅读笔记/</id>
    <published>2018-12-26T08:56:04.000Z</published>
    <updated>2018-12-26T11:29:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="第16章-分布式机器学习">第16章 分布式机器学习</span></h1><p>分布式机器学习需要解决如下三个问题：</p><ol><li>如何更好切分成多个任务</li><li>如何调度子任务</li><li>均衡各节点负载</li></ol><h2><span id="参数服务器">参数服务器</span></h2><ul><li>参数的获取与提交：计算节点从参数服务节点上获取当前的梯度，然后根据本地分配的训练样本进行梯度计算，通过几轮迭代后将更新后的梯度推送给参数服务器节点。参数在参数服务器需要高效地进行分布式存储，同时计算节点和参数服务节点之间的通信要足够高效</li><li>参数值的同步问题：根据参数服务器的设计和运行原理，我们可以得知在每一个时刻计算节点的梯度和当前参数服务节点上储存的梯度可能是不一致的。</li></ul><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E7%BE%8E%E5%9B%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/ps.png" alt="ps"></p><p>什么时候计算节点与参数服务器节点更新同步一次参数呢？</p><p>这个更新同步过程对每个计算节点来说都是相互独立的。一般来说，一个比较简单而且常用的方式是，我们可以采用固定的迭代轮数，每个计算节点迭代这个轮数后和参数服务节点做一次同步</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E7%BE%8E%E5%9B%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E9%9D%9E%E5%87%B8%E9%97%AE%E9%A2%98.png" alt="非凸问题"></p><h2><span id="梯度如何更新">梯度如何更新</span></h2><p>主要有参数平均法和基于更新方法两种</p><h3><span id="参数平均法">参数平均法</span></h3><p>参数平均法的核心思想是将每个计算节点获取的参数值求平均后作为全局参数值，可以证明参数平均法的结果在数学意义上等同于用单个机器进行训练</p><h3><span id="异步梯度下降更新">异步梯度下降更新</span></h3><p>相对于在工作节点与参数服务器之间传递参数，我们只传递梯度更新信息。</p><h3><span id="比较">比较</span></h3><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E7%BE%8E%E5%9B%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E6%AF%94%E8%BE%83.png" alt="比较"></p><h2><span id="xgboost">XGBoost</span></h2><p>使用rabit,rabit在MPI的allReduce和broadcast操作原语这个基础上提供了更好的容错处理功能，弥补了MPI的不足</p><p>xgboost优化了rabit的MR流程</p><ol><li>每一轮迭代结束后，计算结果不用放入储存系统。保留在内存里</li><li>每一轮迭代后没有数据重新分发的过程(no shuffle)</li></ol><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E7%BE%8E%E5%9B%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/rabit.png" alt="rabit"></p><h3><span id="xgboost容错">xgboost容错</span></h3><p>rabit在一轮AllReduce后，会把在各个节点内存中将模型结果缓存为checkpoint,并加版本号</p><p>同步结束后，各个节点会继续计算到下一次AllReduce通信同步。</p><p>如果有节点发生故障，该故障节点会从集群中找到最近的节点，拿到上一轮的模型文件，然后重新开始计算，其他无故障的节点等待故障节点计算完成后再AllReduce</p><h2><span id="pslite">PSlite</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;第16章-分布式机器学习&quot;&gt;第16章 分布式机器学习&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;分布式机器学习需要解决如下三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何更好切分成多个任务&lt;/li&gt;
&lt;li&gt;如何调度子任务&lt;/li&gt;
&lt;li&gt;均
      
    
    </summary>
    
    
      <category term="ML" scheme="http://www.yifanguo.top/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>ctr那些事儿</title>
    <link href="http://www.yifanguo.top/2018/12/26/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/"/>
    <id>http://www.yifanguo.top/2018/12/26/ctr那些事儿/</id>
    <published>2018-12-26T08:13:39.000Z</published>
    <updated>2018-12-26T08:40:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="ctr概述">CTR概述</span></h1><p>转自【https://zhuanlan.zhihu.com/p/31499375】</p><p>click through rate 是用来估计一个用户（缩写为u）是否会点击一个广告或其它item（缩写为a）的技术</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-e5998fc5f766e99bbe92be20711a7206_hd.jpg" alt="v2-e5998fc5f766e99bbe92be20711a7206_hd"></p><p>问题的核心在于建模，即：<strong>寻找一个函数</strong> <img src="https://www.zhihu.com/equation?tex=f" alt="f"> <strong>可以学习出数据中</strong> <img src="https://www.zhihu.com/equation?tex=f%3A+X+%5Cto+y" alt="f: X \to y"> <strong>的映射，即尽可能用数据</strong> <img src="https://www.zhihu.com/equation?tex=%28X%2Cy%29" alt="(X,y)"> <strong>拟合</strong> <img src="https://www.zhihu.com/equation?tex=f" alt="f"> 。这可以简化地理解为一个分类（Classification）问题</p><p>作为一种预估问题，CTR预估潜在地包含了假设：<strong>过去的规律在未来依然有效。</strong></p><p>我们会自然地想到，从历史估计未来，最简单的方式就是对历史数据做统计。那么是否用统计值来预估就可以了？</p><p>不然。</p><p>首先，统计量本身有<strong>置信度</strong>的概念，数据中很难保证每个特征都有充足的数据支持每个特征的置信度。比如，张三看了1kw的广告、点击了1k次，或许可以说张三的点击率是0.01%；但如果李四只看了1次广告、没有点击，却不能简单地认为李四的点击率一定为0%。其次，历史上一定有<strong>未被观察</strong>（unseen）的事件。比如“张三看宝马会点击”是一个事件，但张三不可能看过所有的广告；张三在历史上没有看过奔驰广告，统计也就无法得知他是否会点击奔驰广告。</p><p>从另一个角度讲，传统的Machine Learning问题为便于建模，一般会隐含<strong>数据服从Gaussian分布</strong>的假设；但在互联网主要的展示（impression）、点击（click）、关注（follow）、转发（re-twitter）、交易（order）等数据中，由于强烈的“头部效应”，整体数据是呈现<strong>幂指数分布</strong>的——由于长尾的存在，对于部分特征来讲数据一定是不充分的。</p><p>于是我们总结出CTR预估第一个问题：<strong>CTR预估是在不完善信息下做出的决策</strong>。换句话说就是：<strong>总有统计上不充分的情况出现，无论是unseen事件，还是seen但事件重复次数较少的情况。</strong></p><p>回到“过去的规律在未来依然有效”这个假设。在实际应用中，这个假设是双刃剑：</p><ul><li>好的方面：过去的规律意味着可以利用历史信息，也就意味着利用更大量的<strong>样本</strong>（instance）、构造大量的<strong>特征</strong>（feature）、使用复杂的<strong>模型</strong>（model）的可能性。这也是CTR预估算法从2007年使用LR建模之后十多年不断发展和分化的基础。</li><li>坏的方面：这个假设在现实中并不完全成立——数据的分布在并不被模型预知的情况下变动着。用户行为影响ranking，ranking反过来也会影响用户行为；再加上用户分布变化对数据分布的扰动、运营手段对数据分布的扰动等等复杂因素，经常会导致模型刚上线效果最好，然后可能渐渐地就不好用了。</li></ul><p>这就是CTR预估第二个问题：**CTR预估是在变化的分布上做出的估计。**换句话说就是：<strong>总有从历史上得不到的规律。</strong></p><p>对于这两个问题，常见的解决思路有：</p><ul><li><p>针对在不完善信息下做出决策的问题：</p></li><li><ul><li>试：引入E&amp;E机制快速试错；</li><li>泛：引入更通用、更泛化的特征，在无法精细估计的情况下给出一个更通用的估计。</li></ul></li><li><p>针对在变化的分布上做出估计的问题：</p></li><li><ul><li>快：更快的模型迭代更新速度、在线学习；</li><li>猜：引入博弈论，强化学习，对用户-系统交互行为进行建模。</li></ul></li></ul><h2><span id="一个例子">一个例子</span></h2><p>考虑一个简单的CTR预估场景的例子。这里有两个特征（position_id、ad）。为了方便，我们把相同特征下的曝光和点击进行计数，聚合在一起。</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-e366cc1eea72ef722c49a8933e1e46e0_hd.jpg" alt="v2-e366cc1eea72ef722c49a8933e1e46e0_hd"></p><blockquote><p>以第一行数据为例：“ad=宝马”在“position_id=1”的位置曝光了10次，有6次点击。</p></blockquote><p>我们把每个特征进行one-hot encoding：</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-0d6a9486da21453f893c09ce72dfa7c5_hd.jpg" alt="v2-0d6a9486da21453f893c09ce72dfa7c5_hd"></p><p>下面我们入手开始CTR预估建模。对于CTR预估问题，工业界解决的起点其实和大部分机器学习的通用思路是一致的：**先给出并使用一个较粗糙的解，然后把求解问题转化成一个优化问题。**毕竟，“随机猜”（random）也是一种模型，只是效果比较差而已。我们要优化出比random更好的解，也就是从test AUC = 0.5开始进行优化。</p><p>CTR系统核心建模是针对展示（pv）和点击（click）的关系进行建模的：</p><p><img src="https://www.zhihu.com/equation?tex=%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7Ey_%7Bclick%7D+%3D+Bernoulli%28p_%7Bctr%7D%29" alt="~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~y_{click} = Bernoulli(p_{ctr})"></p><p>这一点是众多CTR预估算法的共同基础。而针对 <img src="https://www.zhihu.com/equation?tex=p_%7Bctr%7D" alt="p_{ctr}"> 建模主要有两大类途径：</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-97bfe6be9ef47f6544fb5aa78a225d59_hd.jpg" alt="v2-97bfe6be9ef47f6544fb5aa78a225d59_hd"></p><p>以线性模型LR为例，核心建模为：<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7E%7Ep_%7Bctr%7D+%26%3D+f%28%5Cphi%28x%29%29+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cphi%28x%29%7D%7D%5C%5C+%5Cphi%28x%29+%26%3D+w%5ETx+%5Cend%7Bsplit%7D" alt="\begin{split} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~p_{ctr} &amp;amp;= f(\phi(x)) \ &amp;amp;= \frac{1}{1+e^{-\phi(x)}}\ \phi(x) &amp;amp;= w^Tx \end{split}">在上图的例子中， <img src="https://www.zhihu.com/equation?tex=x" alt="x"> 为四维one-hot特征的取值，如对于上例的第一行数据：<img src="https://www.zhihu.com/equation?tex=x_1%3D1%2C+x_2%3D0%2C+x_3%3D1%2C+x_4%3D0." alt="x_1=1, x_2=0, x_3=1, x_4=0.">对应地，我们估计出的 <img src="https://www.zhihu.com/equation?tex=w" alt="w"> 也是一个四维向量，分别代表特征“psid=1、psid=2、ad=宝马、ad=奔驰”的权重。由这些权重，我们就可以估计出各种 <img src="https://www.zhihu.com/equation?tex=x" alt="x"> 取值下的点击率。</p><p>可以看到，线性模型假设模型 <img src="https://www.zhihu.com/equation?tex=f%28%C2%B7%29" alt="f(·)"> 是<strong>线性可分</strong>的。当然，这并不意味着线性模型无法表示非线性：我们可以在feature <img src="https://www.zhihu.com/equation?tex=X" alt="X"> 中增加非线性特征来提供非线性。与此对应的是，<strong>非线性模型在模型假设中直接具有非线性</strong>。</p><p>线性模型中，一般特征的规模都会特别大。这是因为线性模型如果要达到与非线性模型相似的模型效果（或者说表达能力），需要在特征侧做大量的工作：比如把原本非线性表达的特征离散化成局部线性的特征、把单一实体变换为高维度的one-hot encoding特征、以及由于上述的操作大量分割了实体之间的关系而需要添加大量组合（crossing）特征等等。这些变换都会大幅增加稀疏特征的维度。</p><p>如果我们把线性模型和非线性模型的计算链路展开，会发现线性模型的特征维度高但计算深度少，模型相对很“宽（wide）”；而非线性模型则相对更“深（deep）”，模型计算更为复杂。相对应地，有些模型更倾向于在<strong>特征侧</strong>进行优化，而有的模型更针对于<strong>模型侧</strong>的调优。</p><h2><span id="模型侧和特征侧优化">模型侧和特征侧优化</span></h2><p>CTR预估中，模型侧的优化主要集中在各类<strong>非线性模型</strong>上，如基于Kernel的模型、NN、Boosting等。在实际的CTR预估系统中，NN和Boosting较为常用，而kernel的身影比较少见。这是因为基于kernel的模型中特征维度通常很高，且 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="O(N^2)"> 的时间复杂度太高难以满足工业要求。</p><p>在实际工程中，对模型侧的优化主要体现在：<strong>观察数据找规律，建模调参线上试</strong>。大致的步骤包括：</p><ol><li>观察数据；</li><li>找到规律；</li><li>根据规律做模型的假设；</li><li>对模型假设中的参数用数据进行拟合；</li><li>把拟合的结果用到线上，看看效果怎么样。</li></ol><p>举个例子：在某业务中，我们通过观察数据，认为图像特征是主要的影响CTR预估效果的因素；则我们在建模中引入CNN假设进行joint training，然后调参、离线验证，验证ok进行线上实验，完成一轮优化。其中，掌握模型的理论本质、适用范围和复杂度，针对需求对模型进行选择和业务适配，是模型侧优化的主要工作。</p><p><strong>特征侧优化</strong></p><p>特征侧有相对有迹可循的优化方法。常用的是<strong>层次化特征：保证细粒度ID无法命中的时候，层次化“上位”更粗粒度特征可以生效。</strong></p><p>如某个场景中有如下的特征层次关系，其曝光量如色阶所示：</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-2215e475e08325a0139828d2d00d8623_hd.jpg" alt="2-2215e475e08325a0139828d2d00d8623_hd"></p><ul><li>1阶特征中，“小吃套餐”特征曝光太少，特征置信度低，则至少上位特征“某的基”可以命中生效。这是一个从最细粒度到更粗粒度的扩展过程；</li><li>2阶组合特征中，最细粒度的“小吃素材&amp;顶部通栏2号位”曝光很少很难命中优化，可以取其中某一个的上位，形成“某的基&amp;顶部通栏2号位”；或者如果还不够，则扩充更多的维度，如“某的基&amp;通栏” 。越宏观的特征表达出的个性化信息越少，但是在数据不足时，能表达出特性的概率越大。</li></ul><p>一图以蔽之，模型侧和特征侧优化方法可以比较总结如下：</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/ctr%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/v2-ddeb06abfa253f77304644badb7bbb61_hd.jpg" alt="v2-ddeb06abfa253f77304644badb7bbb61_hd"></p><h2><span id="逻辑回归">逻辑回归</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;ctr概述&quot;&gt;CTR概述&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;转自【https://zhuanlan.zhihu.com/p/31499375】&lt;/p&gt;
&lt;p&gt;click through rate 是用来估计一个用户（缩写为u）是否
      
    
    </summary>
    
    
      <category term="ctr" scheme="http://www.yifanguo.top/tags/ctr/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统遇上深度学习</title>
    <link href="http://www.yifanguo.top/2018/12/26/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E9%81%87%E4%B8%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://www.yifanguo.top/2018/12/26/推荐系统遇上深度学习/</id>
    <published>2018-12-26T08:02:31.000Z</published>
    <updated>2018-12-26T08:11:07.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="mlr">MLR</span></h1><p>业界常用的CTR预估算法的不足如下表所示：</p><table><thead><tr><th>方法</th><th>简介</th><th>不足</th></tr></thead><tbody><tr><td>逻辑回归</td><td>使用了Sigmoid函数将函数值映射到0~1区间作为CTR的预估值。LR这种线性模型很容易并行化，处理上亿条训练样本不是问题。</td><td>线性模型的学习能力有限，需要引入大量的领域知识来人工设计特征以及特征之间的交叉组合来间接补充算法的非线性学习能力，非常消耗人力和机器资源，迁移性不够友好。</td></tr><tr><td>Kernel方法</td><td>将低维特征映射到高维特征空间</td><td>复杂度太高而不易实现</td></tr><tr><td>树模型</td><td>如Facebook的GBDT+LR算法，有效地解决了LR模型的特征组合问题</td><td>是对历史行为的记忆，缺乏推广性，树模型只能学习到历史数据中的特定规则，对于新规则缺乏推广性</td></tr><tr><td>FM模型</td><td>自动学习高阶属性的权值，不用通过人工的方式选取特征来做交叉</td><td>FM模型只能拟合特定的非线性模式，常用的就是二阶FM</td></tr><tr><td>深度神经网络</td><td>使用神经网络拟合数据之间的高阶非线性关系，非线性拟合能力足够强</td><td>适合数据规律的、具备推广性的网络结构业界依然在探索中，尤其是要做到端到端规模化上线，这里面的技术挑战依然很大</td></tr></tbody></table><p><strong>那么挑战来了，如何设计算法从大规模数据中挖掘出具有推广性的非线性模式？</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;mlr&quot;&gt;MLR&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;业界常用的CTR预估算法的不足如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;简介&lt;/th&gt;
&lt;th&gt;不足&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbo
      
    
    </summary>
    
    
      <category term="rs" scheme="http://www.yifanguo.top/tags/rs/"/>
    
  </entry>
  
  <entry>
    <title>阿里妈妈ctr演讲</title>
    <link href="http://www.yifanguo.top/2018/12/26/%E9%98%BF%E9%87%8C%E5%A6%88%E5%A6%88ctr%E6%BC%94%E8%AE%B2/"/>
    <id>http://www.yifanguo.top/2018/12/26/阿里妈妈ctr演讲/</id>
    <published>2018-12-26T07:03:08.000Z</published>
    <updated>2018-12-26T07:53:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="互联网数据和经典模型">互联网数据和经典模型</span></h1><p>文章地址： https://mp.weixin.qq.com/s/UzukJHlYvRKtYBeuLoApqg</p><p>CTR经典三种做法</p><ol><li>简单线性模型LR</li><li>稀疏正则L1-Norm特征筛选</li><li>处理非线性：人工特征工程</li></ol><h2><span id="经典方法1id特征">经典方法1:ID特征</span></h2><p>ID特征，这里指的是稀疏鉴别式特征。举个例子，假如有1亿个用户，可以把1亿个用户表示为1亿维的01向量，01向量的第一个用户就命中第一维，第二个用户就命中为第二维，所以一种特征可以用这种ID类表示展现成一个非常长的01稀疏向量。如果有很多组特征，就可以把这些向量拼起来，形成一个更长的向量。</p><p>就原始特征而言，一般用户量大的公司可能是上亿级，而大的互联网公司，是上亿、上十亿甚至上百亿级的。所以原始ID特征在表示上，可以轻松将其表示成十几亿或者几十亿级。此外，我们还可以做特征的交叉组合，只要工程能力够，可以轻松上千亿，这个特征维度很大。</p><h2><span id="逻辑回归">逻辑回归</span></h2><p>逻辑回归是线性模型加上非线性的变换，变成一个概率形式。逻辑回归在工业界使用的方式很不一样。第一，它能处理非常大规模的数据，所以其模型和数据都必须是并行处理的，这对工程和算法上的要求都特别高。第二，对于特别大的特征来讲，通常我们会用稀疏正则L1-Norm特征筛选的方法。</p><p>##经典方法三：人工特征工程</p><p>如果想用这个经典方法将更多有用的信息尤其是非线性的压榨出来，还需要用到人工特征工程的方法。比如刚才说的两个特征，如果两个特征的交互对目标影响很大，那么拼起来的线性模型可能不够，我们就要做交叉等很多特征。</p><h2><span id="问题">问题</span></h2><ol><li>人工能力有限，很难对非线性模式完全挖掘充分</li><li>依赖人力和领域经验，方法推广到其他的问题代价太大</li></ol><p><strong>有多少人工就有多少智能</strong></p><h2><span id="其他方法">其他方法</span></h2><h3><span id="kernel">kernel</span></h3><p>不适合工业界</p><h3><span id="tree-based">Tree based</span></h3><p>在ID特征上表现不够好</p><p>Tree based方法在一些低维的强特征上效果特别好，但在ID特征上反而作用不太好。</p><p>这里举一个例子：在推荐场景中，需要预估一个用户和一个宝贝的点击率，先不取历史行为就用用户ID和宝贝ID两种特征。有这两个特征，对于协同过滤的方法就已经够了。但是，如果用Tree based方法，要建树就会带来很多麻烦，树根到树叶的路径等价于是否是某个用户和是否是某个宝贝的联合判断。在这种情况下，它已经变成了一个历史记忆。这就是为什么Tree based的方法在稀疏大规模ID数据上表现不行的原因。</p><p>Facebook也做了一个方法，就是在强特征上用Tree based方法做数据筛选，再用一些LR聚合类的方法利用弱特征。</p><p>( GBDT + LR)</p><h3><span id="矩阵分解和分解机器模型无法处理高阶关系">矩阵分解和分解机器模型：无法处理高阶关系</span></h3><p>矩阵分解和分解机器模型，这两类模型其实有点共通。以分解机器模型为例，它主要处理的是有限次关系，经典的方法是二次关系。对于一些高阶关系是没法处理的。</p><h1><span id="分片线性模型和学习算法mlr模型">分片线性模型和学习算法MLR模型</span></h1><p>分片线性模型MLR是2011年我在阿里提出的方法。该模型的优点在于，可将整个数据分成不同的区域，在每个不同区域都用一个简单的模型预测，再将全部信息聚合起来，得到可以比较复杂的分片线性模型。如此一来，就能平衡欠拟合和过拟合的问题，从而在大规模数据中挖掘出推广性好的非线性信息。而其一个基本原则，就在于要使每分片对应足够量的样本。</p><p>特点：</p><p>分而治之；</p><p>分片数足够多时，有非常强的非线性能力；</p><p>模型复杂度可控：有较好泛化能力；</p><p>具有自动特征选择作用；</p><p>可以适用于大规模高维度数据；</p><p>#大规模ID特征+MLR实践</p><p>#深层用户兴趣分布网络</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;互联网数据和经典模型&quot;&gt;互联网数据和经典模型&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;文章地址： https://mp.weixin.qq.com/s/UzukJHlYvRKtYBeuLoApqg&lt;/p&gt;
&lt;p&gt;CTR经典三种做法&lt;/p
      
    
    </summary>
    
    
      <category term="ctr" scheme="http://www.yifanguo.top/tags/ctr/"/>
    
  </entry>
  
  <entry>
    <title>ctr</title>
    <link href="http://www.yifanguo.top/2018/12/26/ctr/"/>
    <id>http://www.yifanguo.top/2018/12/26/ctr/</id>
    <published>2018-12-26T06:37:16.000Z</published>
    <updated>2018-12-26T06:46:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="ctr-模型">ctr 模型</span></h1><h1><span id="有用的资料">有用的资料</span></h1><p>https://zhuanlan.zhihu.com/p/39439947 【阿里的DIN】</p><h1><span id="历史">历史</span></h1><p>CTR预估是一个比较窄的研究领域，但是模型性能一点点的提升，在实际应用中都非常关键，真金白银毫不含糊。随着深度学习在CV、NLP等领域取得突破性进展，一些研究也开始尝试将DNN应用于CTR预估，比如：Wide&amp;Deep, DeepFM等。</p><blockquote><p>这些做法一般分为两部分：</p><ol><li><p>在输入上面加一层embeding层，把最原始高维度、稀疏的数据转换为低维度的实值表示上(dense vector)。</p></li><li><p>增加多个全连接层，学习特征之间的非线性关系。Sparse Features -&gt; Embedding Vector -&gt; MLPs -&gt; Output</p></li></ol></blockquote><p>这些方法的<strong>优点</strong>在于：<strong>相比于原来的Logistic Regression方法，大大减少了人工特征工程的工作量。</strong></p><p>**缺点：<strong>在电子商务领域中，用户的历史行为数据(User Behavior Data)中包含大量的用户兴趣信息，之前的研究并没有针对Behavior data</strong>特殊的结构(Diversity + Local Activation)**进行建模</p><p>这就是DIN要改进的地方!** DIN同时对Diversity和Local Activation进行建模。</p><p><strong>针对Diversity：</strong>针对用户广泛的兴趣，DIN用<em>an interest distribution</em>去表示。</p><p><strong>针对Local Activation：</strong>DIN借鉴机器翻译中的Attention机制，设计了一种<em>attention-like network structure</em>， 针对当前候选Ad，去局部的激活(<em>Local Activate</em>)相关的历史兴趣信息。和当前候选Ad相关性越高的历史行为，会获得更高的<em>attention score</em>，从而会主导这一次预测。</p><h1><span id="阿里推荐系统工作流程">阿里推荐系统工作流程</span></h1><ol><li>检查用户历史行为数据</li><li>使用matching module产生候选ads</li><li>通过ranking module得到候选ads的点击概率，并根据概率排序得到推荐列表</li><li>记录下用户在当前展示广告下的反应(点击与否)</li></ol><h1><span id="特征工程">特征工程</span></h1><h2><span id="21-训练数据">2.1 训练数据</span></h2><p>前面提到，电子商务领域，充分利用User Behavior Data非常关键，而它又有着非常显著的特点：</p><ul><li>Diversity. 兴趣爱好非常广泛</li><li>Local Activation. 历史行为中部分数据主导是否会点击候选广告</li></ul><p>还有的特点，就是CTR中输入普遍存在的特点：</p><ul><li>高纬度</li><li>非常稀疏</li></ul><p>CTR中一旦涉及到用户行为数据，还有一个特点：</p><ul><li>特征往往都是<strong>multi-hot</strong>的稀疏ids。</li></ul><p>也就是：多值离散特征。比如：用户在YouTube上看的视频和搜索过的视频。无论是看过的还是搜索过的，都不止一个，但是相对于所有的视频来说，看过和搜索过的数量都太小了(非常稀疏)。在电子商务上的例子就是：用户购买过的good_id有多个，购买过的shop_id也有多个，而这也直接导致了每个用户的历史行为id长度是不同的。</p><p>为了得到一个固定长度的Embedding Vector表示，原来的做法是在<code>Embedding Layer</code>后面增加一个<code>Pooling Layer</code>。Pooling可以用sum或average。最终得到一个固定长度的<code>Embedding Vector</code>，是用户兴趣的一个抽象表示，常被称作<code>User Representation</code>。缺点是会损失一些信息。</p><p>DIN使用Attention机制来解决这个问题。<strong>Attention机制</strong>来源于<code>Neural Machine Translation(NMT)</code>。DIN使用Attention机制去更好的建模局部激活。在DIN场景中，针对不同的候选广告需要自适应地调整<code>User Representation</code>。也就是说：在<code>Embedding Layer -&gt; Pooling Layer</code>得到用户兴趣表示的时候，赋予不同的历史行为不同的权重，实现局部激活。从最终反向训练的角度来看，就是根据当前的候选广告，来反向的激活用户历史的兴趣爱好，赋予不同历史行为不同的权重。</p><h2><span id="22-特征处理">2.2 特征处理</span></h2><h1><span id="总结">总结</span></h1><ol><li>用户有多个兴趣爱好，访问了多个good_id，shop_id。为了降低纬度并使得商品店铺间的算术运算有意义，我们先对其进行Embedding嵌入。那么我们如何对用户多种多样的兴趣建模那？使用<strong>Pooling对Embedding Vector求和或者求平均</strong>。同时这也解决了不同用户输入长度不同的问题，得到了一个固定长度的向量。这个向量就是用户表示，是用户兴趣的代表。</li><li>但是，直接求sum或average损失了很多信息。所以稍加改进，针对不同的behavior id赋予不同的权重，这个权重是由当前behavior id和候选广告共同决定的。这就是Attention机制，实现了Local Activation。</li><li>DIN使用<em>activation unit</em>来捕获local activation的特征，使用<em>weighted sum pooling</em>来捕获diversity结构。</li><li>在模型学习优化上，DIN提出了<em>Dice激活函数</em>、<em>自适应正则</em> ，显著的提升了模型性能与收敛速度。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;ctr-模型&quot;&gt;ctr 模型&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;有用的资料&quot;&gt;有用的资料&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;https://zhuanlan.zhihu.com/p/39439947 【阿里的DI
      
    
    </summary>
    
    
      <category term="click through prediction" scheme="http://www.yifanguo.top/tags/click-through-prediction/"/>
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="http://www.yifanguo.top/2018/12/25/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>http://www.yifanguo.top/2018/12/25/决策树/</id>
    <published>2018-12-25T02:22:20.000Z</published>
    <updated>2018-12-26T05:17:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1><span id="决策树概述">决策树概述</span></h1><p>用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布</p><h1><span id="决策树场景">决策树场景</span></h1><p>决策树是通过不停缩小猜测的范围，最后得到答案</p><p>如下图：</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/dt.png" alt="dt"></p><h1><span id="决策树的定义">决策树的定义</span></h1><p>决策树由节点node和有向边(directed edge)组成</p><p>node有两类，内部节点和叶节点，内部节点表示一个特征(feature), 叶节点表示一个label</p><h1><span id="决策树的预测">决策树的预测</span></h1><p>当需要使用决策树对一个目标进行分类时，从根节点开始，对目标的某一特征开始进行测试，</p><p>根据测试结果将该目标分配到某一子节点。每一个子节点对应着该特征的一个取值。dfs到达叶节点</p><p>选择该叶节点作为预测label</p><h1><span id="决策树的术语">决策树的术语</span></h1><p>信息熵又名信息增益</p><p>熵： entropy 指的是体系的混乱程度</p><p>信息论：information theory 是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。例如：火柴有序放在火柴盒里，熵值很低，相反，熵值很高。</p><p>信息增益：information gain 在划分数据集前后信息发生的变化称为信息增益</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/entropy.png" alt="entropy"></p><h1><span id="决策树的种类">决策树的种类</span></h1><p>针对如何生成决策树一般有三类：</p><p>https://zhuanlan.zhihu.com/p/30059442</p><p>https://blog.csdn.net/xbinworld/article/details/44660339</p><h2><span id="id3">ID3</span></h2><p>会overfitting 因为id3会尝试将错误率通过分割非常细来达到0</p><h2><span id="c45">C4.5</span></h2><p>c4.5对ID3进行了改进，C4.5中，增加的熵要除以分割太细的代价，这个比值叫做信息增益率，显然分割太细分母增加，信息增益率会降低。除此之外，其他的原理和ID3相同</p><h2><span id="cart">CART</span></h2><p>分类回归树</p><p>CART只能将一个父节点分为2个子节点。CART用GINI指数来决定如何分裂</p><p>GINI指数：总体内包含的类别越杂乱，GINI指数就越大（跟熵的概念很相似）</p><p>选择GINI指数最小的开始分</p><p>CART还是一个回归树，回归解析用来决定分布是否终止。理想地说每一个叶节点里都只有一个类别时分类应该停止，但是很多数据并不容易完全划分，或者完全划分需要很多次分裂，必然造成很长的运行时间，所以CART可以对每个叶节点里的数据分析其均值方差，当方差小于一定值可以终止分裂，以换取计算成本的降低。</p><p>CART和ID3一样，存在偏向细小分割，即过度学习（过度拟合的问题），为了解决这一问题，对特别长的树进行剪枝处理，直接剪掉。</p><h1><span id="随机森林">随机森林</span></h1><h2><span id="概述">概述</span></h2><p>首先，从原始的数据集中采取有放回的抽样，构造子数据集，子数据集的数据量是和原始数据集相同的。不同子数据集的元素可以重复，同一个子数据集中的元素也可以重复。第二，利用子数据集来构建子决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。最后，如果有了新的数据需要通过随机森林得到分类结果，就可以通过对子决策树的判断结果的投票，得到随机森林的输出结果了。如下图，假设随机森林中有3棵子决策树，2棵子树的分类结果是A类，1棵子树的分类结果是B类，那么随机森林的分类结果就是A类。</p><h2><span id="例子">例子</span></h2><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf.png" alt="rf"></p><p>待选特征的随机选取：与数据集的随机选取类似，随机森林中的子树的每一个分裂过程并未用到所有的待选特征，而是从所有的待选特征中随机选取一定的特征，之后再在随机选取的特征中选取最优的特征。这样能够使得随机森林中的决策树都能够彼此不同，提升系统的多样性，从而提升分类性能。</p><p>下图中，蓝色的方块代表所有可以被选择的特征，也就是目前的待选特征。黄色的方块是分裂特征。左边是一棵决策树的特征选取过程，通过在待选特征中选取最优的分裂特征（别忘了前文提到的ID3算法，C4.5算法，CART算法等等），完成分裂。右边是一个随机森林中的子树的特征选取过程。</p><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/rf_2.png" alt="rf_2"></p><p>http://www.cnblogs.com/pinard/p/6131423.html</p><p>#Ensemble learning集成学习</p><h2><span id="集成学习概念">集成学习概念</span></h2><p>&lt;pre class=&quot;mermaid&quot;&gt;graph TD;个体学习器A1--&gt;强学习器B;个体学习器A2--&gt;强学习器B;个体学习器A3--&gt;强学习器B;个体学习器A4--&gt;强学习器B;&lt;/pre&gt;</p><p>集成学习是通过训练出若干个个体学习器，通过一定的结合策略，最终形成一个强学习器，达到<strong>博采众长</strong>的目的</p><h2><span id="集成学习需要解决的两个问题">集成学习需要解决的两个问题</span></h2><p>1.如何得到若干个个体学习器</p><p>2.如何选择一种结合策略，将这些个体学习器集成一个强学习器</p><h2><span id="个体学习器">个体学习器</span></h2><p>个体学习器强依赖关系，需要串行--boosting算法</p><p>个体学习器不存在强依赖关系，可以并行—bagging和rf</p><h2><span id="boosting">Boosting</span></h2><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/boosting.png" alt="boosting"></p><p>从图中可以看出，Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。</p><p>Boosting系列算法里最著名算法主要有AdaBoost算法和提升树(boosting tree)系列算法。提升树系列算法里面应用最广泛的是梯度提升树(Gradient Boosting Tree)</p><h2><span id="bagging">Bagging</span></h2><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/bagging.png" alt="bagging"></p><p>从上图可以看出，bagging的个体弱学习器的训练集是通过随机采样得到的。通过T次的随机采样，我们就可以得到T个采样集，对于这T个采样集，我们可以分别独立的训练出T个弱学习器，再对这T个弱学习器通过集合策略来得到最终的强学习器。</p><p>对于这里的随机采样有必要做进一步的介绍，这里一般采用的是自助采样法（Bootstap sampling）,即对于m个样本的原始训练集，我们每次先随机采集一个样本放入采样集，接着把该样本放回，也就是说下次采样时该样本仍有可能被采集到，这样采集m次，最终可以得到m个样本的采样集，由于是随机采样，这样每次的采样集是和原始训练集不同的，和其他采样集也是不同的，这样得到多个不同的弱学习器。</p><p>随机森林是bagging的一个特化进阶版，所谓的特化是因为随机森林的弱学习器都是决策树。所谓的进阶是随机森林在bagging的样本随机采样基础上，又加上了特征的随机选择，其基本思想没有脱离bagging的范畴。</p><h2><span id="结合策略">结合策略</span></h2><h3><span id="平均法">平均法</span></h3><p>最终的预测是各个弱学习器的平均值</p><p>如果弱学习器有权重，则是一个加权平均</p><h3><span id="投票法">投票法</span></h3><p>投票法可以有少数服从多数法，绝对票数，以及加权投票</p><h3><span id="学习法">学习法</span></h3><p>上两节的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，也就是说，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。</p><p>在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。</p><h2><span id="boosting算法需要解决的问题">boosting算法需要解决的问题</span></h2><ol><li>如何计算学习误差率e</li><li>如何得到弱学习器权重系数a</li><li>如何更新样本权重d</li><li>使用何种结合策略</li></ol><p>#Adaboosting</p><ul><li><p>样本权重</p><ul><li><p>没有先验知识的情况下，初始的分布为等概分布，即计算集如果有N个样本，每个样本的分布概率为1/N</p></li><li><p>m每次循环后提高误分样本的分布概率，误分样本在训练集中所占的权重增大，使得下一次循环的弱学习器能够集中力量对这些误分样本进行判断</p></li><li><p>准确率越高的弱学习机权重较高</p></li></ul></li></ul><h2><span id="m1算法">M1算法</span></h2><p><img src="/Users/yifanguo/Desktop/blog/source/_posts/%E5%86%B3%E7%AD%96%E6%A0%91/ada.png" alt="ada"></p><h2><span id="前向逐步递增">前向逐步递增</span></h2><h2><span id="优缺点">优缺点</span></h2><p>Adaboost的主要优点有：</p><p>1）Adaboost作为分类器时，分类精度很高</p><p>2）在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。</p><p>3）作为简单的二元分类器时，构造简单，结果可理解。</p><p>4）不容易发生过拟合</p><p>Adaboost的主要缺点有：</p><p>1）对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。</p><h1><span id="gbdtgradient-boosting-decision-tree">GBDT（Gradient Boosting Decision Tree)</span></h1><p>GBDT也是集成学习Boosting家族的成员，但是却和传统的Adaboost有很大的不同。回顾下Adaboost，我们是利用前一轮迭代弱学习器的误差率来更新训练集的权重，这样一轮轮的迭代下去。GBDT也是迭代，使用了前向分布算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。</p><p>在GBDT的迭代中，假设我们前一轮迭代得到的强学习器是ft−1(x)ft−1(x), 损失函数是L(y,ft−1(x))L(y,ft−1(x)), 我们本轮迭代的目标是找到一个CART回归树模型的弱学习器ht(x)ht(x)，让本轮的损失函数L(y,ft(x)=L(y,ft−1(x)+ht(x))L(y,ft(x)=L(y,ft−1(x)+ht(x))最小。也就是说，本轮迭代找到决策树，要让样本的损失尽量变得更小。</p><p>GBDT的思想可以用一个通俗的例子解释，假如有个人30岁，我们首先用20岁去拟合，发现损失有10岁，这时我们用6岁去拟合剩下的损失，发现差距还有4岁，第三轮我们用3岁拟合剩下的差距，差距就只有一岁了。如果我们的迭代轮数还没有完，可以继续迭代下面，每一轮迭代，拟合的岁数误差都会减小。</p><p>从上面的例子看这个思想还是蛮简单的，但是有个问题是这个损失的拟合不好度量，损失函数各种各样，怎么找到一种通用的拟合方法呢？</p><h2><span id="gbdt的负梯度拟合">GBDT的负梯度拟合</span></h2><h2><span id="gbdt回归算法">GBDT回归算法</span></h2><p>GBDT主要的优点有：</p><ol><li><p>可以灵活处理各种类型的数据，包括连续值和离散值。</p></li><li><p>在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。</p></li></ol><p>3）使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</p><p>GBDT的主要缺点有：</p><p>1)由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行</p><h2><span id="gradient-boosting">Gradient Boosting</span></h2><p>用一个弱学习器近似负梯度</p><h1><span id="xgboost">XGBoost</span></h1><h1><span id="有用的资料">有用的资料</span></h1><p>http://codewithzhangyi.com/2018/06/01/XGBOOST%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</p><p>https://zxth93.github.io/2017/09/29/XGBoost%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/index.html</p><p>https://www.bilibili.com/video/av26088803?from=search&amp;seid=4150235187907599632</p><p>https://www.bilibili.com/video/av24476653?from=search&amp;seid=11865982546931463007 （非常好的视频，不过适合有基础的看）</p><p>https://www.jiqizhixin.com/articles/2018-03-18-4 (非常好的讲xgboost的直方图和lgb的GOSS算法对比)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;决策树概述&quot;&gt;决策树概述&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;用于分类时，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;决策树场景&quot;&gt;决策树场景&lt;/sp
      
    
    </summary>
    
    
      <category term="决策树" scheme="http://www.yifanguo.top/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>ml_list</title>
    <link href="http://www.yifanguo.top/2018/12/24/ml-list/"/>
    <id>http://www.yifanguo.top/2018/12/24/ml-list/</id>
    <published>2018-12-24T02:27:53.000Z</published>
    <updated>2018-12-24T02:32:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="ml常见模型">ML常见模型</span></h1><h2><span id="logistic-regression">logistic regression</span></h2><h2><span id="knn">knn</span></h2><h2><span id="naive-bayes">naive bayes</span></h2><h2><span id="rf">rf</span></h2><h2><span id="gbdt">gbdt</span></h2><h2><span id="svm">svm</span></h2><h2><span id="pca">pca</span></h2><h2><span id="svd">svd</span></h2><h2><span id="lda">lda</span></h2><h2><span id="psi">psi</span></h2><h2><span id="kmeans">kmeans</span></h2><h2><span id="kmodes">kmodes</span></h2><h2><span id="crf">crf</span></h2><h2><span id="markov">markov</span></h2><h2><span id="lasso">lasso</span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;ml常见模型&quot;&gt;ML常见模型&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;span id=&quot;logistic-regression&quot;&gt;logistic regression&lt;/span&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;span id=&quot;knn&quot;&gt;knn&lt;/span&gt;&lt;/h
      
    
    </summary>
    
    
      <category term="interview" scheme="http://www.yifanguo.top/tags/interview/"/>
    
  </entry>
  
  <entry>
    <title>spark</title>
    <link href="http://www.yifanguo.top/2018/12/24/spark/"/>
    <id>http://www.yifanguo.top/2018/12/24/spark/</id>
    <published>2018-12-24T02:12:20.000Z</published>
    <updated>2018-12-24T02:12:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="spark内核设计的艺术架构设计与实现">Spark内核设计的艺术架构设计与实现</span></h1><h1><span id="spark-vs-mr">Spark vs MR</span></h1><p>spark是基于内存的MR需要使用磁盘</p><h1><span id="宽依赖和窄依赖">宽依赖和窄依赖</span></h1><p>https://www.jianshu.com/p/5c2301dfa360</p><p>窄依赖与窄依赖比较</p><p>宽依赖往往对应着shuffle操作，需要在运行的过程中将同一个RDD分区传入到不同的RDD分区中，中间可能涉及到多个节点之间数据的传输，而窄依赖的每个父RDD分区通常只会传入到另一个子RDD分区，通常在一个节点内完成。当RDD分区丢失时，对于窄依赖来说，由于父RDD的一个分区只对应一个子RDD分区，这样只需要重新计算与子RDD分区对应的父RDD分区就行。这个计算对数据的利用是100%的当RDD分区丢失时，对于宽依赖来说，重算的父RDD分区只有一部分数据是对应丢失的子RDD分区的，另一部分就造成了多余的计算。宽依赖中的子RDD分区通常来自多个父RDD分区，极端情况下，所有父RDD都有可能重新计算。如下图，par4丢失，则需要重新计算par1,par2,par3,产生了冗余数据par5</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">宽依赖，窄依赖函数</span><br><span class="line"></span><br><span class="line">窄依赖的函数有：</span><br><span class="line">map, filter, union, join(父RDD是hash-partitioned ), mapPartitions, mapValues</span><br><span class="line">宽依赖的函数有：</span><br><span class="line">groupByKey, join(父RDD不是hash-partitioned ), partitionBy</span><br></pre></td></tr></table></figure></p><h1><span id="rdd-resillient-distributed-dataset">RDD resillient distributed dataset</span></h1><p>只有spark action才会将RDD及其DAG（lineage) 提交到DAGScheduler</p><p>RDD 的祖先一定是一个跟数据源相关的RDD, 负责从数据源迭代读取数据</p><h1><span id="dag-directed-acycle-graph">DAG directed acycle graph</span></h1><p>DAG用来反映各RDD之间的依赖或血缘关系</p><h1><span id="partition">Partition</span></h1><p>一个RDD可以划分为多个分区，spark根据partition来确定task数量</p><h1><span id="narrowdependency-窄依赖">NarrowDependency 窄依赖</span></h1><p>子RDD依赖于父RDD中固定的partition</p><h1><span id="shuffledependency-宽依赖">ShuffleDependency 宽依赖</span></h1><p>子RDD对父RDD中所有的partition都可能产生依赖子RDD对父RDD各个partition的依赖将取决于分区计算器 partitioner的算法</p><h1><span id="job-用户提交的作业">Job 用户提交的作业</span></h1><p>当RDD及其DAG被提交给DAGScheduler调度后，DAGScheduler会将所有RDD中的转换及动作看出一个job. 一个job由1到多个Task组成</p><h1><span id="stage-job的执行阶段">Stage job的执行阶段</span></h1><p>DAGScheduler按照shuffleDependency作为Stage的划分节点对RDD的DAG进行Stage划分上游的Stage为shuffleMapStage. 因此一个job可能被划分为一到多个Stage.</p><p>Stage分为shuffleMapStage 和ResultStage</p><h1><span id="task">Task</span></h1><p>ShuffleMapTask, ResultTask</p><h1><span id="shuffle">Shuffle</span></h1><p>shuffle用于打通map任务的输出和reduce任务的输入</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;spark内核设计的艺术架构设计与实现&quot;&gt;Spark内核设计的艺术架构设计与实现&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;spark-vs-mr&quot;&gt;Spark vs MR&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;spark是
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TonY</title>
    <link href="http://www.yifanguo.top/2018/12/21/TonY/"/>
    <id>http://www.yifanguo.top/2018/12/21/TonY/</id>
    <published>2018-12-21T08:11:50.000Z</published>
    <updated>2018-12-21T12:04:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="tensorflow-on-yarn源码详解">TensorFlow On Yarn源码详解</span></h1><p><img src="./TonY/tony.png" alt=""><img src="tony.png" alt=""></p><p>首先来看代码目录构成</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">events: eventHandler和event类，event由avro编写</span><br><span class="line">io: HdfsAvroFileSplitReader 主要是读取Avro File</span><br><span class="line">mini: hadoop minicluster, 主要是测试用</span><br><span class="line">models: Job信息</span><br><span class="line">rpc: grpc通信操作类</span><br><span class="line">tensorflow: 包含一些和tf相关的操作</span><br><span class="line">util: utils类包</span><br><span class="line"></span><br><span class="line">Constants: 常量类</span><br><span class="line">TaskExecutor: 运行task的executor</span><br><span class="line">TFConfig: TFConfig 存TFClusterSpec</span><br><span class="line">TFPolicyProvider：</span><br><span class="line">TonyApplicationMaster: AMContainer运行的类，主要class</span><br><span class="line">TonyClient：提交application的client</span><br><span class="line">TonyConfigurationKeys: Tony的配置类</span><br><span class="line">TonyJobMetadata：Tony job的元数据</span><br></pre></td></tr></table></figure></p><h1><span id="源码分析">源码分析</span></h1><p><img src="./TonY/tf_ps.png" alt=""><img src="tf_ps.png" alt=""></p><p>先感受下最原始的tensorflow分布式如何运行</p><h2><span id="tfconfig">TFConfig</span></h2><p>这个类很简单就是用来表示tensorflow cluster spec的</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class TFConfig &#123;</span><br><span class="line"></span><br><span class="line">  private Map&lt;String, List&lt;String&gt;&gt; clusterSpec;</span><br><span class="line">  private Task task;</span><br><span class="line"></span><br><span class="line">  public static class Task &#123;</span><br><span class="line">    private String type;</span><br><span class="line">    private int index;</span><br></pre></td></tr></table></figure></p><h2><span id="constants常量类">Constants常量类</span></h2><p>常量类，代码里的魔法值都在这里</p><h2><span id="tfpolicyprovider">TFPolicyProvider</span></h2><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> *  * PolicyProvider for Client to AM protocol.</span><br><span class="line"> *  */</span><br><span class="line">public class TFPolicyProvider extends PolicyProvider &#123;</span><br><span class="line"></span><br><span class="line">  private static final Service[] TF_AM_SERVICE =</span><br><span class="line">    new Service[]&#123;</span><br><span class="line">      new Service(</span><br><span class="line">        &quot;security.tf.client-am-protocol.acl&quot;,</span><br><span class="line">        TensorFlowCluster.class)&#125;;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public Service[] getServices() &#123;</span><br><span class="line">    return TF_AM_SERVICE;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>只有一个静态方法，返回的是hadoop authorize server.应该是client到AM的protocol</p><h2><span id="tonyconfigurationkeys">TonyConfigurationKeys</span></h2><p>Tony的配置类</p><h2><span id="tonyjobmetadata">TonyJobMetadata</span></h2><p>Tony application job的头信息</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * meta data for job</span><br><span class="line"> */</span><br><span class="line">public class TonyJobMetadata &#123;</span><br><span class="line">  private String id;</span><br><span class="line">  private String url;</span><br><span class="line">  private long started;</span><br><span class="line">  private long completed;</span><br><span class="line">  private String status;</span><br><span class="line">  private String user;</span><br></pre></td></tr></table></figure></p><h2><span id="下方是三个重要类">下方是三个重要类</span></h2><h2><span id="tonyclient">TonyClient</span></h2><p>用来提交tonyApp的客户端</p><h3><span id="先说类成员">先说类成员</span></h3><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private YarnClient yarnClient;</span><br><span class="line">private HdfsConfiguration hdfsConf = new HdfsConfiguration();</span><br><span class="line">private YarnConfiguration yarnConf = new YarnConfiguration();</span><br><span class="line">private Options opts;</span><br></pre></td></tr></table></figure></p><p>yarnClient: 用来提交yarnApp的客户端hdfsConf: HdfsConfiguration hdfs的配置yarnConf: YarnConfiguration yarn的配置opts:Options Option类，启动yarnClient的一些command option选项</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private String amHost;</span><br><span class="line">private int amRpcPort;</span><br><span class="line">private boolean amRpcServerInitialized = false;</span><br><span class="line">private ApplicationRpcClient amRpcClient;</span><br></pre></td></tr></table></figure></p><p>amHost: am所在的host地址amRpcPort: am监听的端口amRpcServerInitialized: 判断amRpc是否已经初始化ApplicationRpcClient: App用grpc通信的客户端</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// Containers set up.</span><br><span class="line">private String hdfsConfAddress = null;  hdfsConf的地址</span><br><span class="line">private String yarnConfAddress = null;  yarnConf的地址</span><br><span class="line">private long amMemory; am的Memory</span><br><span class="line">private int amVCores; am的cpu cores</span><br><span class="line">private int amGpus; am需要gpu???</span><br><span class="line">private String taskParams = null; task的一些参数</span><br><span class="line">private String pythonBinaryPath = null; python的binary path</span><br><span class="line">private String pythonVenv = null; python的virtual env</span><br><span class="line">private String srcDir = null; source目录，应该是依赖jar包地址</span><br><span class="line">private String hdfsClasspath = null; hdfs的类路径</span><br><span class="line">private String executes; 执行类的位置</span><br><span class="line">private long appTimeout; app的TimeOut</span><br><span class="line">private boolean secureMode; 是否要secureMode</span><br><span class="line">private Map&lt;String, String&gt; shellEnv = new HashMap&lt;&gt;(); 环境变量</span><br><span class="line">private Map&lt;String, String&gt; containerEnv = new HashMap&lt;&gt;(); container所需的环境变量</span><br></pre></td></tr></table></figure></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private String tonyFinalConfPath;</span><br><span class="line">private Configuration tonyConf;</span><br><span class="line">private final long clientStartTime = System.currentTimeMillis();</span><br><span class="line">private Path appResourcesPath;</span><br><span class="line">private int hbInterval;</span><br><span class="line">private int maxHbMisses;</span><br></pre></td></tr></table></figure></p><p>tonyFinalConfPath: 这个设计绝对有问题，后续参考xlearn来改改，这什么鬼tonyConf: Tony的configurationclientStartTime: client提交开始时间appResourcesPath: 运行这个app所需的资源路径 类似spark的 --jarshbInterval: 心跳检测maxHbMisses: 最多心跳检测miss次数</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private Set&lt;TaskUrl&gt; taskUrls = new HashSet&lt;&gt;(); 任务的urls</span><br></pre></td></tr></table></figure></p><h3><span id="constructor">constructor</span></h3><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public TonyClient(Configuration conf) &#123;</span><br><span class="line">  initOptions();</span><br><span class="line">  tonyConf = conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>类构建没什么特别，会有一个command option的加载<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">private void initOptions() &#123;</span><br><span class="line">  opts = Utils.getCommonOptions();</span><br><span class="line">  opts.addOption(&quot;conf&quot;, true, &quot;User specified configuration, as key=val pairs&quot;);</span><br><span class="line">  opts.addOption(&quot;conf_file&quot;, true, &quot;Name of user specified conf file, on the classpath&quot;);</span><br><span class="line">  opts.addOption(&quot;src_dir&quot;, true, &quot;Name of directory of source files.&quot;);</span><br><span class="line">  opts.addOption(&quot;help&quot;, false, &quot;Print usage&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3><span id="methods">methods</span></h3><p>先来看看所有方法</p><p><img src="./TonY/clien1.png" alt=""><img src="./TonY/clien2.png" alt=""></p><p>多且乱 后续肯定要优化，至少也要接口化，这个肯定不能直接用</p><h3><span id="run">run</span></h3><p>入参 null返回 boolean</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yarnClient.start();</span><br><span class="line">YarnClientApplication app = yarnClient.createApplication();</span><br><span class="line">GetNewApplicationResponse appResponse = app.getNewApplicationResponse();</span><br></pre></td></tr></table></figure></p><p>老三样，几乎所有的yarnAppClient开始都是如此第一步： start yarnClient第二步： 创建app第三步： app拿到response</p><p>这三步就是向resource manager拿到一些基本信息用的。</p><p>后续都会接一个资源验证，如：</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// Truncate resource request to cluster&apos;s max resource capability.</span><br><span class="line">   if (amMemory &gt; maxMem) &#123;</span><br><span class="line">     LOG.warn(&quot;Truncating requested AM memory: &quot; + amMemory + &quot; to cluster&apos;s max: &quot; + maxMem);</span><br><span class="line">     amMemory = maxMem;</span><br><span class="line">   &#125;</span><br><span class="line">   int maxVCores = appResponse.getMaximumResourceCapability().getVirtualCores();</span><br><span class="line"></span><br><span class="line">   if (amVCores &gt; maxVCores) &#123;</span><br><span class="line">     LOG.warn(&quot;Truncating requested AM vcores: &quot; + amVCores + &quot; to cluster&apos;s max: &quot; + maxVCores);</span><br><span class="line">     amVCores = maxVCores;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p><p>appResponse会拿到两个信息 memory和Vcores，这里没有拿到gpu,yarn对gpu的隔离应该只是在io层面，后续再看</p><p>下一步一般都是先拿到hdfs的操作类FileSystem</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FileSystem fs = FileSystem.get(hdfsConf);</span><br><span class="line">ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();</span><br><span class="line">ApplicationId appId = appContext.getApplicationId();</span><br></pre></td></tr></table></figure></p><p>这里做了三步，其实appId也可以通过appResponse来拿</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appResourcesPath = new Path(fs.getHomeDirectory(), Constants.TONY_FOLDER + Path.SEPARATOR + appId.toString());</span><br></pre></td></tr></table></figure></p><p>这个是app运行时的资源路径</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if (srcDir != null) &#123;</span><br><span class="line">  if (Utils.isArchive(srcDir)) &#123;</span><br><span class="line">    uploadFileAndSetConfResources(appResourcesPath, new Path(srcDir), Constants.TONY_SRC_ZIP_NAME, tonyConf, fs);</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    Utils.zipFolder(Paths.get(srcDir), Paths.get(Constants.TONY_SRC_ZIP_NAME));</span><br><span class="line">    uploadFileAndSetConfResources(appResourcesPath, new Path(Constants.TONY_SRC_ZIP_NAME),</span><br><span class="line">      Constants.TONY_SRC_ZIP_NAME, tonyConf, fs);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们知道srcDir是运行app所需的jar包本地位置，这一步是把依赖的jars压缩下然后上传到appResourcesPath路径下</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (pythonVenv != null) &#123;</span><br><span class="line">   uploadFileAndSetConfResources(appResourcesPath, new Path(pythonVenv), Constants.PYTHON_VENV_ZIP, tonyConf, fs);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> if (yarnConfAddress != null) &#123;</span><br><span class="line">   uploadFileAndSetConfResources(appResourcesPath, new Path(yarnConfAddress),</span><br><span class="line">     Constants.YARN_SITE_CONF, tonyConf, fs);</span><br><span class="line"> &#125;</span><br><span class="line"> if (hdfsConfAddress != null) &#123;</span><br><span class="line">   uploadFileAndSetConfResources(appResourcesPath, new Path(hdfsConfAddress),</span><br><span class="line">     Constants.HDFS_SITE_CONF, tonyConf, fs);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>同理对yarnConf， hdfsConf还有pythonVenv也上传到appResourcePath. 这样app运行python文件就有了所有的依赖这个实现很不错</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">this.tonyFinalConfPath = Utils.getClientResourcesPath(appId.toString(), Constants.TONY_FINAL_XML);</span><br><span class="line">// Write user&apos;s overridden conf to an xml to be localized.</span><br><span class="line">try (OutputStream os = new FileOutputStream(this.tonyFinalConfPath)) &#123;</span><br><span class="line">  tonyConf.writeXml(os);</span><br><span class="line">&#125; catch (IOException e) &#123;</span><br><span class="line">  throw new RuntimeException(&quot;Failed to create &quot; + this.tonyFinalConfPath + &quot; conf file. Exiting.&quot;, e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个是把最终的xml文件全部保存到本地，用来查看container启动的环境吗？</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String appName = tonyConf.get(TonyConfigurationKeys.APPLICATION_NAME,</span><br><span class="line">     TonyConfigurationKeys.DEFAULT_APPLICATION_NAME);</span><br><span class="line">   appContext.setApplicationName(appName);</span><br><span class="line">   appContext.setApplicationType(APP_TYPE);</span><br></pre></td></tr></table></figure></p><p>set下app名字和app的type</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Set up resource type requirements</span><br><span class="line">  Resource capability = Resource.newInstance(amMemory, amVCores);</span><br><span class="line">  Utils.setCapabilityGPU(capability, amGpus);</span><br><span class="line">  appContext.setResource(capability);</span><br></pre></td></tr></table></figure></p><p>这个是set am所需的资源 分别为memory, cpu cores和 gpu资源。gpu的设置很奇怪</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Set the queue to which this application is to be submitted in the RM</span><br><span class="line">String yarnQueue = tonyConf.get(TonyConfigurationKeys.YARN_QUEUE_NAME,</span><br><span class="line">  TonyConfigurationKeys.DEFAULT_YARN_QUEUE_NAME);</span><br><span class="line">appContext.setQueue(yarnQueue);</span><br></pre></td></tr></table></figure></p><p>设置下提交队列</p><p>最后一步</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Set the ContainerLaunchContext to describe the Container ith which the TonyApplicationMaster is launched.</span><br><span class="line">  ContainerLaunchContext amSpec =</span><br><span class="line">    createAMContainerSpec(appId, this.amMemory, this.taskParams, this.pythonBinaryPath, this.executes, getTokens());</span><br><span class="line">  appContext.setAMContainerSpec(amSpec);</span><br></pre></td></tr></table></figure></p><p>创建ContainerLaunchContext这个类然后setAMContainerSpec 后续会重点讲这个方法，很关键</p><p>然后提交app,</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">String nodeLabel = tonyConf.get(TonyConfigurationKeys.APPLICATION_NODE_LABEL);</span><br><span class="line">    if (nodeLabel != null) &#123;</span><br><span class="line">      appContext.setNodeLabelExpression(nodeLabel);</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.info(&quot;Submitting YARN application&quot;);</span><br><span class="line">    yarnClient.submitApplication(appContext);</span><br><span class="line">    ApplicationReport report = yarnClient.getApplicationReport(appId);</span><br><span class="line">    logTrackingAndRMUrls(report);</span><br><span class="line">    return monitorApplication(appId)</span><br></pre></td></tr></table></figure></p><p>中间还有几个report相关的检测类，后面再看。</p><p>至此整个提交任务的完成，我们简单总结下1.首先创建app然后拿到appReponse2.资源校验3.设置amContext4.最后提交appContext</p><h3><span id="logtrackingandrmurls">logTrackingAndRMUrls</span></h3><p>log的方法</p><h3><span id="createyarnclient">createYarnClient</span></h3><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">private void createYarnClient() &#123;</span><br><span class="line">   if (this.yarnConfAddress != null) &#123;</span><br><span class="line">     this.yarnConf.addResource(new Path(this.yarnConfAddress));</span><br><span class="line">   &#125;</span><br><span class="line">   if (this.hdfsConfAddress != null) &#123;</span><br><span class="line">     this.hdfsConf.addResource(new Path(this.hdfsConfAddress));</span><br><span class="line">   &#125;</span><br><span class="line">   int numRMConnectRetries = tonyConf.getInt(TonyConfigurationKeys.RM_CLIENT_CONNECT_RETRY_MULTIPLIER,</span><br><span class="line">     TonyConfigurationKeys.DEFAULT_RM_CLIENT_CONNECT_RETRY_MULTIPLIER);</span><br><span class="line">   long rmMaxWaitMS = yarnConf.getLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,</span><br><span class="line">     YarnConfiguration.DEFAULT_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS) * numRMConnectRetries;</span><br><span class="line">   yarnConf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS, rmMaxWaitMS);</span><br><span class="line"></span><br><span class="line">   if (System.getenv(Constants.HADOOP_CONF_DIR) != null) &#123;</span><br><span class="line">     hdfsConf.addResource(new Path(System.getenv(Constants.HADOOP_CONF_DIR) + File.separatorChar + Constants.CORE_SITE_CONF));</span><br><span class="line">     yarnConf.addResource(new Path(System.getenv(Constants.HADOOP_CONF_DIR) + File.separatorChar + Constants.CORE_SITE_CONF));</span><br><span class="line">     hdfsConf.addResource(new Path(System.getenv(Constants.HADOOP_CONF_DIR) + File.separatorChar + Constants.HDFS_SITE_CONF));</span><br><span class="line">   &#125;</span><br><span class="line">   yarnClient = YarnClient.createYarnClient();</span><br><span class="line">   yarnClient.init(yarnConf);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>这个方法就是初始化tony的conf然后创建一个yarnClient</p><h3><span id="init">init</span></h3><p>不贴代码了 也是初始化conf的一些操作，然后调用createYarnClientinit+createYarnClient就是在设置运行必须的配置</p><h3><span id="inittonyconf">initTonyConf</span></h3><p>同上</p><h3><span id="createamcontainerspec">createAMContainerSpec</span></h3><p>这个类是我们的关注重点</p><p>首先是</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);</span><br></pre></td></tr></table></figure></p><p>这是创建一个新的CLC,就是container运行需要的上下文</p><p>然后注意都需要set哪些</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">amContainer.setApplicationACLs(acls);</span><br><span class="line"></span><br><span class="line">   String command = TonyClient.buildCommand(amMemory, taskParams, pythonBinaryPath,</span><br><span class="line">     executes, shellEnv, containerEnv);</span><br><span class="line"></span><br><span class="line">   LOG.info(&quot;Completed setting up Application Master command &quot; + command);</span><br><span class="line">   amContainer.setCommands(ImmutableList.of(command));</span><br><span class="line">   if (tokens != null) &#123;</span><br><span class="line">     amContainer.setTokens(tokens);</span><br><span class="line">   &#125;</span><br><span class="line">   amContainer.setEnvironment(containerEnv);</span><br><span class="line">   amContainer.setLocalResources(localResources);</span><br></pre></td></tr></table></figure></p><p>分别是acls 一个控制listcommands:运行程序的命令tokens: tokenssetEnvironment: 运行的环境变量setLocalResources： 运行am所依赖的本地资源</p><p>最后renturn clc</p><h3><span id="buildcommand">buildCommand</span></h3><p>java command</p><h3><span id="gettokens">getTokens</span></h3><p>delegation tokens</p><h3><span id="monitorapplication">monitorApplication</span></h3><p>检测app的运行情况</p><h3><span id="initrpcclient">initRpcClient</span></h3><p>初始化rpcClient</p><h2><span id=""></span></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;tensorflow-on-yarn源码详解&quot;&gt;TensorFlow On Yarn源码详解&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;./TonY/tony.png&quot; alt=&quot;&quot;&gt;
&lt;img src=&quot;tony.p
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>dt</title>
    <link href="http://www.yifanguo.top/2018/12/20/dt/"/>
    <id>http://www.yifanguo.top/2018/12/20/dt/</id>
    <published>2018-12-20T10:56:32.000Z</published>
    <updated>2018-12-21T02:33:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>https://blog.csdn.net/niaolianjiulin/article/details/76574216</p><p>LGB阐释的很好的文章：https://blog.csdn.net/shine19930820/article/details/79123216</p><p>[toc]</p><h1><span id="aggregation-model">Aggregation Model</span></h1><p>blending(混合） and bagging（装袋）</p><p>aggreation model就是混合模型</p><p>blending: voting for classification</p><h1><span id="xgboost-vs-gbdt-vs-lightgbm">XGBoost vs GBDT vs LightGBM</span></h1><h2><span id="gbdt-梯度提升提升决策树回归问题">GBDT -- 梯度提升，提升决策树，回归问题</span></h2><p>本质模型为加法模型基函数为决策树迭代拟合标注和模型的残差来不断逼近损失函数最小化</p><p>以当前模型在L负梯度方向的值，作为残差的近似</p><h2><span id="xgb的特点">XGB的特点</span></h2><p>1） booster可以是gbtree也可以是linear model</p><ol start="2"><li>gbdt优化只用到一阶导数信息（负梯度），xgboost则对代价函数进行了二阶泰勒展开，同时用到一阶和二阶导数.同时支持自定义代价函数，只要函数可一阶和二阶求导3） 更多的正则项 包含树的叶节点个数4） shrinkage缩减和column_subsamplingshrinkage缩减：类似学习速率column_subsampling: 列抽样5） split finding alg: xgboost还提出了一种可并行的近似approximate algorithm直方图算法Weighted Quantile Sketch，用于高效地生成候选的分割点6）对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。 稀疏感知算法 Sparsity-aware Split Finding7）Built-in Cross-Validation： XGBoost allows user to run a cross-validation at each iteration of the boosting process and thus it is easy to get the exact optimum number of boosting iterations in a single run.This is unlike GBM where we have to run a grid-search and only a limited values can be tested.8）</li></ol><h2><span id="lgb">LGB</span></h2><h3><span id="abtract">abtract</span></h3><p>xgboost一个效率问题就是 对于每一个特征的每一个分裂点，都需要遍历全部数据计算信息增益 这一过程非常耗时</p><p>针对这一个问题，lgb提出</p><h3><span id="goss-gradient-based-one-side-sampling">GOSS - gradient-based One-Side Sampling</span></h3><p>GOSS会排除对entropy贡献小的instances.</p><h3><span id="efb-exclusive-feature-bundling基于梯度的one-side采样和互斥的特征捆绑">EFB - Exclusive Feature Bundling(基于梯度的one-side采样和互斥的特征捆绑）</span></h3><p>不损害分割点准确率，有效减少特征的数量</p><h3><span id="gbdt的缺点">GBDT的缺点</span></h3><p>GBDT缺点：**对于每一个特征的每一个分裂点，都需要遍历全部数据来计算信息增益。**因此，其计算复杂度将受到特征数量和数据量双重影响，造成处理大数据时十分耗时。</p><p>解决这个问题最直接的方法就是减少特征量和数据量但同时不影响精度。一个简单的做法就是根据数据权重采样来加速boosting的过程。由于gbdt没有样本权重不能应用，lgb提出两种新方法：</p><h3><span id="goss-通过采样降低样本数">GOSS -- 通过采样降低样本数</span></h3><p>GBDT虽然没有数据权重，但每个数据实例有不同的梯度，根据计算信息增益的定义，梯度大的实例对信息增益有更大的影响，因此在下采样时，我们应该尽量保留梯度大的样本（预先设定阈值，或者最高百分位间），随机去掉梯度小的样本。我们证明此措施在相同的采样率下比随机采样获得更准确的结果，尤其是在信息增益范围较大时</p><p>GOSS保留所有的梯度较大的实例，在梯度小的实例上使用随机采样。为了抵消对数据分布的影响，计算信息增益的时候，GOSS对小梯度的数据引入常量乘数。GOSS首先根据数据的梯度绝对值排序，选取top a个实例。然后在剩余的数据中随机采样b个实例。接着计算信息增益时为采样出的小梯度数据乘以(1-a)/b，这样算法就会更关注训练不足的实例，而不会过多改变原数据集的分布。</p><h3><span id="efb-通过捆绑降低特征数量主要是针对sparse">EFB -- 通过捆绑降低特征数量（主要是针对sparse)</span></h3><p>虽然特征量比较多，但是由于特征空间十分稀疏，是否可以设计一种无损的方法来减少有效特征呢？特别在稀疏特征空间上，许多特征几乎是互斥的（例如许多特征不会同时为非零值，像one-hot），我们可以捆绑互斥的特征。最后，我们将捆绑问题归约到图着色问题，通过贪心算法求得近似解。</p><h3><span id="gbdt-复杂度分析">GBDT 复杂度分析</span></h3><p>GBDT是一种集成模型的决策树，顺序训练决策树。每次迭代中，GBDT通过拟合负梯度（残差）来学到决策树。</p><p>学习决策树是GBDT主要的时间花销，而学习决策树中找到最优切分点最消耗时间</p><p>广泛采用的预排序算法来找到最优切分点，这种方法会列举预排序中所有可能的切分点。这种算法虽然能够找到最优的切分点，但对于训练速度和内存消耗上都效率低</p><p>另一种流行算法是直方图算法（histogram-based algorithm）。直方图算法并不通过特征排序找到最优的切分点，而是将连续的特征值抽象成离散的分箱，并使用这些分箱在训练过程中构建特征直方图，这种算法更加训练速度和内存消耗上都更加高效，lightGBM使用此种算法。</p><h3><span id="histogram-based算法">histogram-based算法</span></h3><p>histogram-based算法通过直方图寻找最优切分点，其建直方图消耗O(#data * #feature)，寻找最优切分点消耗O(#bin * # feature)，而#bin的数量远小于#data，所以建直方图为主要时间消耗。如果能够减少数据量或特征量，那么还能够够加速GBDT的训练。</p><p><img src="goss.png" alt=""><img src="./dt/goss.png" alt=""></p><h3><span id="goss-过程">GOSS 过程</span></h3><ol><li>首先根据数据的梯度来训练将许排序</li><li>保留top a个数据，作为数据子集A</li><li>对于剩下的数据，随机采样获得大小为b的数据子集B</li><li>最后计算信息增益</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;https://blog.csdn.net/niaolianjiulin/article/details/76574216&lt;/p&gt;
&lt;p&gt;LGB阐释的很好的文章：https://blog.csdn.net/shine19930820/article/details/7912
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://www.yifanguo.top/2018/12/19/test/"/>
    <id>http://www.yifanguo.top/2018/12/19/test/</id>
    <published>2018-12-19T06:00:15.000Z</published>
    <updated>2018-12-19T06:29:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="test">test</span></h1><p><img src="./test/pslite.jpg" alt=""></p><p><img src="./pslite.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;test&quot;&gt;test&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;./test/pslite.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;./pslite.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>pslite</title>
    <link href="http://www.yifanguo.top/2018/12/19/pslite/"/>
    <id>http://www.yifanguo.top/2018/12/19/pslite/</id>
    <published>2018-12-19T01:58:03.000Z</published>
    <updated>2018-12-19T06:32:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><p>https://zhuanlan.zhihu.com/p/48794558http://www.cnblogs.com/heguanyou/p/7868596.htmlhttps://blog.csdn.net/KangRoger/article/details/73307685</p><p>https://blog.csdn.net/xln0130/article/details/5696001https://www.jianshu.com/p/d3e503ddd68ehttps://www.zybuluo.com/Dounm/note/517675</p><h1><span id="rpc-vs-socket">RPC vs socket</span></h1><p>两个老板手下各有一个负责接通MSN的秘书.这两个秘书就是基于RPC协议建立的会话层通信.老本不需要知道怎么使用MSN,只要告诉秘书,秘书就会通过MSN与对方建立会话请求和响应.而基于Socket的通信,老板需要会使用MSN,这样尽管老板需要事先培训一下MSN的简单使用常识,但若与对方通信时,无需经过秘书,效率更高.</p><h1><span id="pslite全解析">Pslite全解析</span></h1><p><img src="./pslite/pslite.jpg" alt=""><img src="./pslite.jpg" alt=""></p><ul><li>虚线实心箭头：依赖关系</li><li>实心菱形： 合成关系，simpleApp中有一个customer成员</li><li>空心三角+实线： 继承关系</li></ul><p><img src="./pslite/class.png" alt=""></p><h2><span id="postoffice">PostOffice</span></h2><p>全局管理类,每个node只有一个该类的对象</p><p>主要用来配置当前node的一些信息，例如当前node是哪种类型(server,worker,scheduler)，nodeid是啥，以及worker/server 的rank 到 node id的转换。</p><p>Postoffice类利用Singleton模式来保证只有一个对象。</p><h2><span id="van">Van</span></h2><p>核心通信类，每个节点只有一个该对象，是Postoffice对象的成员。</p><p>Van类负责建立起节点之间的互相连接（例如Worker与Scheduler之间的连接），并且开启本地的receiving thread用来监听收到的message。</p><p>Van的子类为ZMQVan，即为用zmq库实现了连接的底层细节（zmq库是一个开源库，对socket进行了优良的封装</p><h2><span id="customer">Customer</span></h2><p>用于通信的对象。</p><p>每个Customer都与某个node id相绑定，代表当前节点发送到对应node id节点。</p><p>Customer对象维护request和response的状态，其中tracker_成员记录每个请求可能发送给了多少节点以及从多少个节点返回。tracker_ 下标为每个req标识的timestamp。</p><p>Customer也会启动一个receiving thread，而它接受到的消息来自于Van的receiving thread，即每个节点的Van对象收到message后，根据message的不同，推送到不同的customer对象中。</p><h2><span id="simpleapp">SimpleApp</span></h2><p>简单的通信类。每次通信发送int型的head和string型的body。</p><p>SimpleApp对象中包括一个Customer对象用来控制请求连接。</p><h2><span id="kvworker">KVWorker</span></h2><p>继承自SimpleApp，包括如下方法： Push(),Pull(),Wait()。</p><p>Push()和Pull()最后都会调用Send()函数，Send()对KVPairs进行切分，因为每个Server只保留一部分参数，因此切分后的SlicedKVpairs就会被发送给不同的Server。</p><p>切分函数可以由用户自行重写，默认为DefaultSlicer，每个SlicedKVPairs被包装成Message对象，然后用van::send()发送。</p><h2><span id="kvserver">KVServer</span></h2><p>继承自SimpleApp，包含如下方法：Process()和Response()。</p><p>Process()被注册到Customer对象中，当Customer对象的receiving thread接受到消息时，就调用Process()对数据进行处理。Process()内部的逻辑是调用 用户自行实现的一个std::function函数对象 对数据进行处理。</p><p>Response()就仅仅是向调用的worker发送信息</p><h2><span id="kvpairs">KVPairs</span></h2><p>拥有keys, values, lens等3个数组。lens和keys大小相等，表示每个key对应的value的个数。lens可为空，此时values被平分。</p><p>举例而言，若keys=[1,5]，lens=[2,3]，那么values[0],values[1]就对应的是keys[0]，而values[2],values[3],values[5]对应的就是keys[1]。而如果len为空，则values.size()必须是keys.size()（此处为2）的倍数，key[0]和key[1]各对应一半的values。</p><h2><span id="sarray">SArray</span></h2><p>shared array，用std::shared_ptr实现的数组，用于替代std::vector，避免数组的深拷贝。</p><p>#消息处理流程</p><p>无论是worker节点还是server节点，在程序的最开始都会执行Postoffice::start()。Postoffice::start()会初始化节点信息，并且调用Van::start()。而Van::start()则会让当前节点与Scheduler节点相连，并且启动一个本地线程recv thread来持续监听收到的message。</p><p>worker和server都继承自SimpleApp类，所以都有一个customer对象。customer对象本身也会启动一个recv thread，其中调用注册的recv_handle_函数对消息进行处理。</p><p>对于worker来说，其注册的recv_handle_是KVWorker::Process()函数。因为worker的recv thread接受到的消息主要是从server处pull下来的KV对，因此该Process()主要是接收message中的KV对；</p><p>而对于Server来说，其注册的recv_handle_是KVServer::Process()函数。因此server接受的是worker们push上来的KV对，需要对其进行处理，因此该Process()函数中调用的用户通过KVServer::set_request_handle()传入的函数对象。</p><p>每个customer对象都拥有一个tracker_(std::vector&lt;std::pair&lt;int, int&gt;&gt;类型)用来记录每个请求发送和返回的数量。tracker_的下标即为请求的timestamp，tracker_[t].first是该请求发送给了多少节点，tracker[t]<em>.second是该请求收到了多少节点的回复。customer::Wait()就是一直阻塞直到tracker</em>[t].first == tracker[t].second，用这个来控制同步异步依赖。</p><p>每当Van的recv thread收到一个message时，就会根据customer id的不同将message发给不同的customer的recv thread。同时该message对应的请求（设为req）则tracker_[req.timestamp].second++</p><h1><span id="node">Node</span></h1><p><img src="./pslite/node.png" alt=""></p><p>真的是非常巧妙的表示，学到了</p><h1><span id="消息封装">消息封装</span></h1><p><img src="./pslite/msg.png" alt=""></p><p>Node 存放ip port id等信息Control存放command类型 command=BARRIERMeta timeStamp, 发送者id,接受者id, 控制信息controlMessage. 消息头Meta, 消息体data</p><h1><span id="node之间协同工作">Node之间协同工作</span></h1><p><img src="./pslite/node_work.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;p&gt;https://zhuanlan.zhihu.com/p/48794558
http://www.cnblogs.com/heguanyou/p/7868596.html
https://blog.csdn.net/KangRoger/articl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>parameter_server</title>
    <link href="http://www.yifanguo.top/2018/10/29/parameter-server/"/>
    <id>http://www.yifanguo.top/2018/10/29/parameter-server/</id>
    <published>2018-10-28T19:53:51.000Z</published>
    <updated>2018-10-30T02:32:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="parameter-server技术内幕">parameter server技术内幕</span></h1><p>深入解析parameter server架构设计与实现原理</p><h1><span id="第一章-回顾分布式机器学习的历史进程">第一章 回顾分布式机器学习的历史进程</span></h1><h2><span id="1背景">1.背景</span></h2><p>自从 google 发表著名的 GFS、MapReduce、BigTable 三篇 paper 以后，互联网正式迎来了大数据时代。大数据的显著特点是大，哪里都大的大。本篇主要针对 volume 大的数据时，使用机器学习来进行数据处理过程中遇到的架构方面的问题做一个系统的梳理。</p><p>有了 GFS 我们有能力积累海量的数据样本，比如在线广告的曝光和点击数据，天然具有正负样本的特性，累积一两个月往往就能轻松获得百亿、千亿级的训练样本。这样海量的样本如何存储？用什么样的模型可以学习海量样本中有用的 pattern？这些问题不止是工程问题，也值得每个做算法的同学去深入思考。</p><h3><span id="11-简单模型-or-复杂模型">1.1 简单模型 or 复杂模型</span></h3><p>在深度学习概念提出之前，算法工程师手头能用的工具其实并不多，就 LR、SVM、感知机等寥寥可数、相对固定的若干个模型和算法；那时候要解决一个实际的问题，算法工程师更多的工作主要是在特征工程方面。而特征工程本身并没有很系统化的指导理论（至少目前没有看到系统介绍特征工程的书籍），所以很多时候特征的构造技法显得光怪陆离，是否有用也取决于问题本身、数据样本、模型以及运气。</p><p>在特征工程作为算法工程师主要工作内容的时候，构造新特征的尝试往往很大部分都不能在实际工作中发挥作用。据我了解，国内几家大公司在特征构造方面的成功率在后期一般不会超过 20%。也就是 80% 的新构造特征往往并没什么正向提升效果。如果给这种方式起一个名字的话，大概是简单模型 + 复杂特征。简单模型说的是算法比如 LR、SVM 本身并不复杂，参数和表达能力基本呈现一种线性关系，易于理解。复杂特征则是指特征工程方面不断尝试使用各种奇技淫巧构造的可能有用、可能没用的特征，这部分特征的构造方式可能会有各种 trick，比如窗口滑动、离散化、归一化、开方、平方、笛卡尔积、多重笛卡尔积等等；顺便提一句，因为特征工程本身并没有特别系统的理论和总结，所以初入行的同学想要构造特征就需要多读 paper，特别是和自己业务场景一样或类似的场景的 paper，从里面学习作者分析、理解数据的方法以及对应的构造特征的技法；久而久之，有望形成自己的知识体系。</p><p>深度学习概念提出以后，人们发现通过深度神经网络可以进行一定程度的表示学习（representation learning）。例如在图像领域，通过 CNN 提取图像 feature 并在此基础上进行分类的方法，一举打破了之前算法的天花板，而且是以极大的差距打破。这给所有算法工程师带来了新的思路，既然深度学习本身有提取特征的能力，干嘛还要苦哈哈的自己去做人工特征设计呢？</p><p>深度学习虽然一定程度上缓解了特征工程的压力，但这里要强调两点：</p><ol><li><p>缓解并不等于彻底解决，除了图像这种特定领域，在个性化推荐等领域，深度学习目前还没有完全取得绝对的优势。究其原因，可能还是数据自身内在结构的问题，使得在其他领域目前还没有发现类似图像+CNN 这样的完美 comple。</p></li><li><p>深度学习在缓解特征工程的同时，也带来了模型复杂、不可解释的问题。算法工程师在网络结构设计方面一样要花很多心思来提升效果。概括起来，深度学习代表的简单特征 + 复杂模型是解决实际问题的另一种方式。</p></li></ol><p>两种模式孰优孰劣还难有定论，以点击率预测为例，在计算广告领域往往以海量特征 +LR 为主流，根据 VC 维理论，LR 的表达能力和特征个数成正比，因此海量的 feature 也完全可以使 LR 拥有足够的描述能力。而在个性化推荐领域，深度学习刚刚萌芽，目前 google play 采用了 WDL 的结构 [1]，youtube 采用了双重 DNN 的结构 [2]。</p><p>不管是那种模式，当模型足够庞大的时候，都会出现模型参数一台机器无法存放的情况。比如百亿级 feature 的 LR 对应的权重 w 有好几十个 G，这在很多单机上存储都是困难的，大规模神经网络则更复杂，不仅难以单机存储，而且参数和参数之间还有逻辑上的强依赖；要对超大规模的模型进行训练势必要借用分布式系统的技法，本文主要是系统总结这方面的一些思路。</p><h3><span id="12-数据并行-vs-模型并行">1.2 数据并行 vs 模型并行</span></h3><p>数据并行和模型并行是理解大规模机器学习框架的基础概念，其缘起未深究，第一次看到是在姐夫（Jeff Dean）的 blog 里，当时匆匆一瞥，以为自己懂了。多年以后，再次开始调研这个问题的时候才想起长者的教训，年轻人啊，还是图样，图森破。如果你和我一样曾经忽略过这个概念，今天不妨复习一下。</p><p>这两个概念在 [3] 中沐帅曾经给出了一个非常直观而经典的解释，可惜不知道什么原因，当我想引用时却发现已经被删除了。我在这里简单介绍下这个比喻：如果要修两栋楼，有一个工程队，怎么操作？第一个方案是将人分成两组，分别盖楼，盖好了就装修；第二种做法是一组人盖楼，等第一栋楼盖好，另一组装修第一栋，然后第一组继续盖第二栋楼，改完以后等装修队装修第二栋楼。乍一看，第二种方法似乎并行度并不高，但第一种方案需要每个工程人员都拥有“盖楼”和“装修”两种能力，而第二个方案只需要每个人拥有其中一种能力即可。第一个方案和数据并行类似，第二个方案则道出了模型并行的精髓。</p><p>数据并行理解起来比较简单，当样本比较多的时候，为了使用所有样本来训练模型，我们不妨把数据分布到不同的机器上，然后每台机器都来对模型参数进行迭代，如下图所示。</p><p><img src="sdp.png" alt=""></p><p>图片取材于 TensorFlow 的 paper[4]，图中 ABC 代表三台不同的机器，上面存储着不同的样本，模型 P 在各台机器上计算对应的增量，然后在参数存储的机器上进行汇总和更新，这就是数据并行。先忽略 synchronous，这是同步机制相关的概念，在第三节会有专门介绍。</p><p>数据并行概念简单，而且不依赖于具体的模型，因此数据并行机制可以作为框架的一种基础功能，对所有算法都生效。与之不同的是，模型并行因为参数间存在依赖关系（其实数据并行参数更新也可能会依赖所有的参数，但区别在于往往是依赖于上一个迭代的全量参数。而模型并行往往是同一个迭代内的参数之间有强依赖关系，比如 DNN 网络的不同层之间的参数依照 BP 算法形成的先后依赖），无法类比数据并行这样直接将模型参数分片而破坏其依赖关系，所以模型并行不仅要对模型分片，同时需要调度器来控制参数间的依赖关系。而每个模型的依赖关系往往并不同，所以模型并行的调度器因模型而异，较难做到完全通用。关于这个问题，CMU 的 Erix Xing 在 [5] 中有所介绍，感兴趣的可以参考。</p><p>模型并行的问题定义可以参考姐夫的 [6]，这篇 paper 也是 tensorflow 的前身相关的总结，其中如下图：</p><p><img src="tf_ps.png" alt=""></p><p>解释了模型并行的物理图景，当一个超大神经网络无法存储在一台机器上时，我们可以切割网络存到不同的机器上，但是为了保持不同参数分片之间的依赖，如图中粗黑线的部分，则需要在不同的机器之间进行 concurrent 控制；同一个机器内部的参数依赖，即图中细黑线部分在机器内即可完成控制。</p><p>黑线部分如何有效控制呢？如下图所示：</p><p><img src="tf_ps_2.png" alt=""></p><p>在将模型切分到不同机器以后，我们将参数和样本一起在不同机器间流转，图中 ABC 代表模型的不同部分的参数；假设 C 依赖 B，B 依赖 A，机器 1 上得到 A 的一个迭代后，将 A 和必要的样本信息一起传到机器 2，机器 2 根据 A 和样本对 P2 更新得到，以此类推；当机器 2 计算 B 的时候，机器 1 可以展开 A 的第二个迭代的计算。了解 CPU 流水线操作的同学一定感到熟悉，是的，模型并行是通过数据流水线来实现并行的。想想那个盖楼的第二种方案，就能理解模型并行的精髓了。</p><p><img src="tf_ps_3.png" alt=""></p><p>上图则是对控制模型参数依赖的调度器的一个示意图，实际框架中一般都会用 DAG（有向无环图）调度技术来实现类似功能，未深入研究，以后有机会再补充说明。</p><p>理解了数据并行和模型并行对后面参数服务器的理解至关重要，但现在让我先荡开一笔，简单介绍下并行计算框架的一些背景信息。</p><h2><span id="2并行算法演进">2.并行算法演进</span></h2><h3><span id="21-mapreduce-路线">2.1 MapReduce 路线</span></h3><p>从函数式编程中受到启发，Google 发布了 MapReduce[7] 的分布式计算方式；通过将任务切分成多个叠加的 Map+Reduce 任务，来完成复杂的计算任务，示意图如下：</p><p><img src="mr.png" alt=""></p><p>MapReduce 的主要问题有两个，一是原语的语义过于低级，直接使用其来写复杂算法，开发量比较大；另一个问题是依赖于磁盘进行数据传递，性能跟不上业务需求。</p><p>为了解决 MapReduce 的两个问题，Matei 在 [8] 中提出了一种新的数据结构 RDD，并构建了 Spark 框架。Spark 框架在 MR 语义之上封装了 DAG 调度器，极大降低了算法使用的门槛。较长时间内 Spark 几乎可以说是大规模机器学习的代表，直至后来沐帅的参数服务器进一步开拓了大规模机器学习的领域以后，Spark 才暴露出一点点不足。如下图：</p><p><img src="spark.png" alt=""></p><p>从图中可以看出，Spark 框架以 Driver 为核心，任务调度和参数汇总都在 Driver，而 Driver 是单机结构，所以 Spark 的瓶颈非常明显，就在 Driver 这里。当模型规模大到一台机器存不下的时候，Spark 就无法正常运行了。所以从今天的眼光来看，Spark 只能称为一个中等规模的机器学习框架。</p><p>MapReduce 不仅是一个框架，还是一种思想，Google 开创性的工作为我们找到了大数据分析的一个可行方向，时至今日，仍不过时。只是逐渐从业务层下沉到底层语义应该处于的框架下层。</p><h3><span id="22-mpi">2.2 MPI</span></h3><p>沐帅在 [9] 中对 MPI 的前景做了简要介绍；和 Spark 不同，MPI 是类似 socket 的一种系统通信 API，只是支持了消息广播等功能。因为对 MPI 研究不深入，这里简单介绍下优点和缺点吧。优点是系统级支持，性能杠杠的；缺点也比较多，一是和 MR 一样因为原语过于低级，用 MPI 写算法，往往代码量比较大；另一方面是基于 MPI 的集群，如果某个任务失败，往往需要重启整个集群，而 MPI 集群的任务成功率并不高。阿里在 [10] 中给出了下图：</p><p><img src="mpi.png" alt=""></p><p>从图中可以看出，MPI 作业失败的几率接近五成。MPI 也并不是完全没有可取之处，正如沐帅所说，在超算集群上还是有场景的。对于工业届依赖于云计算、依赖于 commodity 计算机来说，则显得性价比不够高。当然如果在参数服务器的框架下，对单组 worker 再使用 MPI 未尝不是个好的尝试，[10] 的鲲鹏系统正是这么设计的。</p><h2><span id="3-参数服务器演进">3. 参数服务器演进</span></h2><p>沐帅在 [12] 中将参数服务器的历史划分为三个阶段，第一代参数服务器萌芽于沐帅的导师 Smola 的 [11]，如下图所示：</p><p><img src="ps_h1.png" alt=""></p><p>这个工作中仅仅引入 memcached 来存放 key-value 数据，不同的处理进程并行对其进行处理。[13] 中也有类似的想法，第二代参数服务器叫 application-specific 参数服务器，主要针对特定应用而开发，其中最典型的代表应该是 TensorFlow 的前身 [6]。</p><p>第三代参数服务器，也即是通用参数服务器框架是由百度少帅李沐正式提出的，和前两代不同，第三代参数服务器从设计上就是作为一个通用大规模机器学习框架来定位的。要摆脱具体应用、算法的束缚，做一个通用的大规模机器学习框架，首先就要定义好框架的功能；而所谓框架，往往就是把大量重复的、琐碎的、做了一次就不想再来第二次的脏活、累活进行良好而优雅的封装，让使用框架的人可以只关注于自己的核心逻辑。第三代参数服务器要对那些功能进行封装呢？沐帅总结了这几点，我照搬如下：</p><p>1）高效的网络通信：因为不管是模型还是样本都十分巨大，因此对网络通信的高效支持以及高配的网络设备都是大规模机器学习系统不可缺少的；</p><p>2）灵活的一致性模型：不同的一致性模型其实是在模型收敛速度和集群计算量之间做 tradeoff；要理解这个概念需要对模型性能的评价做些分析，暂且留到下节再介绍。</p><p>3）弹性可扩展：显而易见</p><p>4）容灾容错：大规模集群协作进行计算任务的时候，出现 Straggler 或者机器故障是非常常见的事，因此系统设计本身就要考虑到应对；没有故障的时候，也可能因为对任务时效性要求的变化而随时更改集群的机器配置。这也需要框架能在不影响任务的情况下能做到机器的热插拔。</p><p>5）易用性：主要针对使用框架进行算法调优的工程师而言，显然，一个难用的框架是没有生命力的。</p><p>在正式介绍第三代参数服务器的主要技术之前，先从另一个角度来看下大规模机器学习框架的演进。</p><p><img src="ps_h2.png" alt=""></p><p>这张图可以看出，在参数服务器出来之前，人们已经做了多方面的并行尝试，不过往往只是针对某个特定算法或特定领域，比如 YahooLDA 是针对 LDA 算法的。当模型参数突破十亿以后，则可以看出参数服务器一统江湖，再无敌手。</p><p>首先我们看看第三代参数服务器的基本架构。</p><p><img src="ps_h3.png" alt=""></p><p>上图的 resource manager 可以先放一放，因为实际系统中这部分往往是复用现有的资源管理系统，比如 yarn 或者 mesos；底下的 training data 毋庸置疑的需要类似 GFS 的分布式文件系统的支持；剩下的部分就是参数服务器的核心组件了。</p><p>图中画了一个 server group 和三个 worker group；实际应用中往往也是类似，server group 用一个，而 worker group 按需配置；server manager 是 server group 中的管理节点，一般不会有什么逻辑，只有当有 server node 加入或退出的时候，为了维持一致性哈希而做一些调整。</p><p>Worker group 中的 task schedule 则是一个简单的任务协调器，一个具体任务运行的时候，task schedule 负责通知每个 worker 加载自己对应的数据，然后去 server node 上拉取一个要更新的参数分片，用本地数据样本计算参数分片对应的变化量，然后同步给 server node；server node 在收到本机负责的参数分片对应的所有 worker 的更新后，对参数分片做一次 update。</p><p><img src="ps_h4.png" alt=""></p><p>如图所示，不同的 worker 同时并行运算的时候，可能因为网络、机器配置等外界原因，导致不同的 worker 的进度是不一样的，如何控制 worker 的同步机制是一个比较重要的课题。详见下节分解。</p><h2><span id="32-同步协议">3.2 同步协议</span></h2><p>本节假设读者已经对随机梯度优化算法比较熟悉，如果不熟悉的同学请参考吴恩达经典课程机器学习中对 SGD 的介绍，或者我之前多次推荐过的书籍《最优化导论》。</p><p>我们先看一个单机算法的运行过程，假设一个模型的参数切分成三个分片 k1，k2，k3；比如你可以假设是一个逻辑回归算法的权重向量被分成三段。我们将训练样本集合也切分成三个分片 s1，s2，s3；在单机运行的情况下，我们假设运行的序列是（k1，s1）、（k2，s1）、（k3、s1）、（k1、s2）、（k2、s2）、（k3、s2）……看明白了吗？就是假设先用 s1 中的样本一次对参数分片 k1、k2、k3 进行训练，然后换 s2；这就是典型的单机运行的情况，而我们知道这样的运行序列最后算法会收敛。</p><p>现在我们开始并行化，假设 k1、k2、k3 分布在三个 server node 上，s1、s2、s3 分布在三个 worker 上，这时候如果我们还要保持之前的计算顺序，则会变成怎样？work1 计算的时候，work2 和 worker3 只能等待，同样 worker2 计算的时候，worker1 和 work3 都得等待，以此类推；可以看出这样的并行化并没有提升性能；但是也算简单解决了超大规模模型的存储问题。</p><p>为了解决性能的问题，业界开始探索这里的一致性模型，最先出来的版本是前面提到的 [11] 中的 ASP 模式，就是完全不顾 worker 之间的顺序，每个 worker 按照自己的节奏走，跑完一个迭代就 update，然后继续，这应该是大规模机器学习中的 freestyle 了，如图所示：</p><p><img src="asp.png" alt="">ASP 的优势是最大限度利用了集群的计算能力，所有的 worker 所在的机器都不用等待，但缺点也显而易见，除了少数几个模型，比如 LDA，ASP 协议可能导致模型无法收敛。也就是 SGD 彻底跑飞了，梯度不知道飞到哪里去了。</p><p>在 ASP 之后提出了另一种相对极端的同步协议 BSP，Spark 用的就是这种方式，如图所示：</p><p><img src="bsp.png" alt=""></p><p>每个 worker 都必须在同一个迭代运行，只有一个迭代任务所有的 worker 都完成了，才会进行一次 worker 和 server 之间的同步和分片更新。这个算法和严格一直的算法非常类似，区别仅仅在于单机版本的 batch size 在 BSP 的时候变成了有所有 worker 的单个 batch size 求和得到的总的 butch size 替换。毫无疑问，BSP 的模式和单机串行因为仅仅是 batch size 的区别，所以在模型收敛性上是完全一样的。同时，因为每个 worker 在一个周期内是可以并行计算的，所以有了一定的并行能力。</p><p>以此协议为基础的 Spark 在很长时间内成为机器学习领域实际的霸主，不是没有理由的。此种协议的缺陷之处在于，整个 worker group 的性能由其中最慢的 worker 决定；这个 worker 一般称为 straggler。读过 GFS 文章的同学应该都知道 straggler 的存在是非常普遍的现象。</p><p>能否将 ASP 和 BSP 做一下折中呢？答案当然是可以的，这就是目前我认为最好的同步协议 SSP；SSP 的思路其实很简单，既然 ASP 是允许不同 worker 之间的迭代次数间隔任意大，而 BSP 则只允许为 0，那我是否可以取一个常数 s？如图所示：</p><p>能否将 ASP 和 BSP 做一下折中呢？答案当然是可以的，这就是目前我认为最好的同步协议 SSP；SSP 的思路其实很简单，既然 ASP 是允许不同 worker 之间的迭代次数间隔任意大，而 BSP 则只允许为 0，那我是否可以取一个常数 s？如图所示：</p><p><img src="ssp.png" alt=""></p><p>不同的 worker 之间允许有迭代的间隔，但这个间隔数不允许超出一个指定的数值 s，图中 s=3.</p><p>SSP 协议的详细介绍参见 [14]，CMU 的大拿 Eric Xing 在其中详细介绍了 SSP 的定义，以及其收敛性的保证。理论推导证明常数 s 不等于无穷大的情况下，算法一定可以在若干次迭代以后进入收敛状态。其实在 Eric 提出理论证明之前，工业界已经这么尝试过了：）</p><p>顺便提一句，考察分布式算法的性能，一般会分为 statistical performance 和 hard performance 来看。前者指不同的同步协议导致算法收敛需要的迭代次数的多少，后者是单次迭代所对应的耗时。两者的关系和 precision\recall 关系类似，就不赘述了。有了 SSP，BSP 就可以通过指定 s=0 而得到。而 ASP 同样可以通过制定 s=∞来达到。</p><h2><span id="33-核心技术">3.3 核心技术</span></h2><p>除了参数服务器的架构、同步协议之外，本节再对其他技术做一个简要的介绍，详细的了解请直接阅读沐帅的博士论文和相关发表的论文。</p><p>热备、冷备技术：为了防止 server node 挂掉，导致任务中断，可以采用两个技术，一个是对参数分片进行热备，每个分片存储在三个不同的 server node 中，以 master-slave 的形式存活。如果 master 挂掉，可以快速从 slave 获取并重启相关 task。</p><p>除了热备，还可以定时写入 checkpoint 文件到分布式文件系统来对参数分片及其状态进行备份。进一步保证其安全性。</p><p>Server node 管理：可以使用一致性哈希技术来解决 server node 的加入和退出问题，如图所示：</p><p><img src="snl.png" alt=""></p><p>当有 server node 加入或退出的时候，server manager 负责对参数进行重新分片或者合并。注意在对参数进行分片管理的情况下，一个分片只需要一把锁，这大大提升了系统的性能，也是参数服务器可以实用的一个关键点。</p><h2><span id="4-大规模机器学习的四重境界">4. 大规模机器学习的四重境界</span></h2><p>到这里可以回到我们的标题了，大规模机器学习的四重境界到底是什么呢？</p><p>这四重境界的划分是作者个人阅读总结的一种想法，并不是业界标准，仅供大家参考。</p><p>境界 1：参数可单机存储和更新</p><p>此种境界较为简单，但仍可以使用参数服务器，通过数据并行来加速模型的训练。</p><p>境界 2：参数不可单机存储，可以单机更新</p><p>此种情况对应的是一些简单模型，比如 sparse logistic regression；当 feature 的数量突破百亿的时候，LR 的权重参数不太可能在一台机器上完全存下，此时必须使用参数服务器架构对模型参数进行分片。但是注意一点，SGD 的更新公式：</p><p>(点击放大图像)</p><p>其中可以分开到单个维度进行计算，但是单个维度的 wi=f(w)xi，这里的 f(w) 表示是全部参数 w 的一个函数，具体推导比较简单，这里篇幅所限就不赘述了。只是想说明 worker 在计算梯度的时候可能需要使用到上一轮迭代的所有参数。</p><p>而我们之所以对参数进行分片就是因为我们无法将所有参数存放到一台机器，现在单个 worker 有需要使用所有的参数才能计算某个参数分片的梯度，这不是矛盾吗？可能吗？</p><p>答案是可能的，因为单个样本的 feature 具有很高的稀疏性（sparseness）。例如一个百亿 feature 的模型，单个训练样本往往只在其中很小一部分 feature 上有取值，其他都为 0（假设 feature 取值都已经离散化了）。因此计算 f(w) 的时候可以只拉取不为 0 的 feature 对应的那部分 w 即可。有文章统计，一般这个级别的系统，稀疏性往往在 0.1%（or 0.01%，记得不是很准，大致这样）以下。这样的稀疏性，可以让单机没有任何阻碍的计算 f(w)。</p><p>目前公司开源的 Angel 和 AILab 正在做的系统都处于这个境界。而原生 Spark 还没有达到这个境界，只能在中小规模的圈子里厮混。Angel 改造的基于 Angel 的 Spark 则达到了这个境界。</p><p>境界 3：参数不可单机存储，不可单机更新，但无需模型并行</p><p>境界 3 顺延境界 2 而来，当百亿级 feature 且 feature 比较稠密的时候，就需要计算框架进入到这层境界了，此时单个 worker 的能力有限，无法完整加载一个样本，也无法完整计算 f(w)。怎么办呢？其实很简单，学过线性代数的都知道，矩阵可以分块。向量是最简单的矩阵，自然可以切成一段一段的来计算。只是调度器需要支持算符分段而已了。</p><p>境界 4：参数不可单机存储，不可单机更新，需要模型并行</p><p>进入到这个层次的计算框架，可以算是世界一流了。可以处理超大规模的神经网络。这也是最典型的应用场景。此时不仅模型的参数不能单机存储，而且同一个迭代内，模型参数之间还有强的依赖关系，可以参见姐夫对 distbelief 的介绍里的模型切分。</p><p>此时首先需要增加一个 coordinator 组件来进行模型并行的 concurrent 控制。同时参数服务器框架需要支持 namespace 切分，coordinator 将依赖关系通过 namespace 来进行表示。</p><p>一般参数间的依赖关系因模型而已，所以较难抽象出通用的 coordinator 来，而必须以某种形式通过脚本 parser 来生产整个计算任务的 DAG 图，然后通过 DAG 调度器来完成。对这个问题的介绍可以参考 Erix Xing 的分享 [5]。</p><h2><span id="tensorflow">Tensorflow</span></h2><p>目前业界比较知名的深度学习框架有 Caffee、MXNet、Torch、Keras、Theano 等，但目前最炙手可热的应该是 Google 发布的 Tensorflow。这里单独拿出来稍微分解下。</p><p>前面不少图片引自此文，从 TF 的论文来看，TF 框架本身是支持模型并行和数据并行的，内置了一个参数服务器模块，但从开源版本所曝光的 API 来看，TF 无法用来 10B 级别 feature 的稀疏 LR 模型。原因是已经曝光的 API 只支持在神经网络的不同层和层间进行参数切分，而超大规模 LR 可以看做一个神经单元，TF 不支持单个神经单元参数切分到多个参数服务器 node 上。</p><p>当然，以 Google 的实力，绝对是可以做到第四重境界的，之所以没有曝光，可能是基于其他商业目的的考量，比如使用他们的云计算服务。</p><p>综上，个人认为如果能做到第四重境界，目前可以说的上是世界一流的大规模机器学习框架。仅从沐帅的 ppt 里看他曾经达到过，Google 内部应该也是没有问题的。第三重境界应该是国内一流，第二重应该是国内前列吧。</p><h2><span id="5-其他">5. 其他</span></h2><h3><span id="51-资源管理">5.1 资源管理</span></h3><p>本文没有涉及到的部分是资源管理，大规模机器学习框架部署的集群往往资源消耗也比较大，需要专门的资源管理工具来维护。这方面 Yarn 和 Mesos 都是佼佼者，细节这里也就不介绍了。</p><h3><span id="52-设备">5.2 设备</span></h3><p>除了资源管理工具，本身部署大规模机器学习集群本身对硬件也还是有些要求的，虽然理论上来说，所有 commodity 机器都可以用来搭建这类集群，但是考虑到性能，我们建议尽量用高内存的机器 + 万兆及以上的网卡。没有超快速的网卡，玩参数传递和样本加载估计会比较苦逼。</p><h2><span id="parameter-server介绍">parameter server介绍</span></h2><p>机器学习系统相比于其他系统而言，有一些自己的独特特点。例如：</p><p>迭代性：模型的更新并非一次完成，需要循环迭代多次容错性：即使在每个循环中产生一些错误，模型最终仍能收敛参数收敛的非均匀性：有些参数几轮迭代就会收敛，而有的参数却需要上百轮迭代。而且工业界需要训练大型的机器学习模型，一些广泛应用的特定的模型在规模上有两个特点：</p><p>参数很大，超过单个机器的容纳的能力（大型LR和神经网络）训练数据太大，需要并行提速（大数据）</p><h2><span id="发展历史">发展历史</span></h2><p>参数服务器的概念最早来自于Alex Smola于2010年提出的并行LDA的框架。它通过采用一个分布式的Memcached作为存放参数的存储，这样就提供了有效的机制用于分布式系统中不同的Worker之间同步模型参数，而每个Worker只需要保存他计算时所以来的一小部分参数即可。</p><p>后来由Google的Jeff Dean进一步提出了第一代Google大脑的解决方案：DistBelief。DistBelief将巨大的深度学习模型分布存储在全局的参数服务器中，计算节点通过参数服务器进行信息传递，很好地解决了SGD和L-BFGS算法的分布式训练问题。</p><p>在后来就是李沐所在的DMLC组所设计的参数服务器。根据论文中所写，该parameter server属于第三代参数服务器，就是提供了更加通用的设计。架构上包括一个Server Group和若干个Worker Group。</p><h2><span id="框架介绍">框架介绍</span></h2><p>2.1 框架介绍首先，该PS框架所假设的硬件情况是机器并不可靠，可能在训练中会重启，移动；数据有可能丢失；网络延迟同样也可能很高。因此，在这种情况下，对于那些使用sychronous iterative communication pattern的框架来说，如基于Hadoop的Mahout，就会在训练过程中由于机器的性能表现不均匀而变得非常的慢。</p><p>而对于Parameter Server来说，计算节点被分成两种：worker和servers。workers保留一部分的训练数据，并且执行计算。而servers则共同维持全局共享的模型参数。而worker只和server有通信，互相之间没有通信。</p><p>parameter server具有以下特点：</p><p>Efficient Communication：高效的通信。网络通信开销是机器学习分布式系统中的大头，因此parameter server基本尽了所有的努力来降低网络开销。其中最重要的一点就是：异步通信。因为是异步通信，所以不需要停下来等一些慢的机器执行完一个iter，这就大大减少了延迟。当然并非所有算法都天然的支持异步和随机性，有的算法引入异步后可能收敛会变慢，因此就需要自行在算法收敛和系统效率之间权衡。Elastic Scalability：使用一致性哈希算法，使得新的Server可以随时动态插入集合中，无需重新运行系统Fault Tolerance and Durability：节点故障是不可避免的。对于server节点来说，使用链备份来应对；而对于Worker来说，因为worker之间互相不通信，因此在某个worker失败后，新的worker可以直接加入Ease of Use：全局共享的参数可以被表示成各种形式：vector, matrices或是sparse类型，同时框架还提供对线性代数类型提供高性能的多线程计算库。</p><p><img src="ps_h3.png" alt=""></p><p>Parameter Server框架中，每个server都只负责分到的部分参数（server共同维持一个全局共享参数）。server节点可以和其他server节点通信，每个server负责自己分到的参数，server group共同维持所有参数的更新。server manage node负责维护一些元数据的一致性，例如各个节点的状态，参数的分配情况。</p><p>worker节点之间没有通信，只和对应的server有通信。每个worker group有一个task scheduler，负责向worker分配任务，并且监控worker的运行情况。当有worker退出或加入时，task scheduler重新分配任务。</p><p>##2.2.1 (Key,Value) Vectors参数都被认为是(key, value)集合。例如对于常见的LR来说，key就是feature ID，value就是其权值。对于不存在的key，可认为其权值为0。</p><p>大多数的已有的框架都是这么对(key, value)进行抽象的。但是PS框架除此之外还把这些(k,v)对看作是稀疏的线性代数对象（通过保证key是有序的情况下），因此在对vector进行计算操作的时候，也会在某些操作上使用BLAS库等线性代数库进行优化。</p><h2><span id="222-range-pushpull">2.2.2 Range Push/Pull</span></h2><p>PS框架中，workers和servers之间通信是通过 push() 和 pull() 方法进行的。worker通过push()将计算好的梯度发送到server，然后通过pull()从server获取更新参数。</p><p>为了提高通信效率，PS允许用户使用Range Push/Range Pull操作。</p><p>w.push(R, dest)w.pull(R, dest)</p><h2><span id="223-asynchronous-tasks-and-dependency">2.2.3 Asynchronous Tasks and Dependency</span></h2><p>task即为一个RPC调用函数。举例而言，worker对server的RPC调用push()或pull()都是算作一个task，又或是scheduler中用户自定义的一个用来对任意其他节点进行RPC调用的函数都算做是task。</p><p>而异步指的是，Tasks在被caller调用后立刻返回，但只有当caller收到callee的回复后，才将该task标记为结束。（在push()和pull()的例子中，worker==caller调用者，server==callee被调用者）默认而言，callee为了性能执行tasks都是并行的，但是如果caller希望串行执行task的话，可以在不同的task之间添加execute-after-finished依赖。</p><p><img src="dsd.png" alt=""></p><p>上图中，Task Scheduler的 调用了Worker中的WORKERITERATE()，这算做是一个task。其中Task Scheduler是caller，worker是callee。</p><p>而WORKERITERATE()这个task却包括3步，第一步是计算梯度，因为是本地的，所以不算task。但是后续的push()和pull()都是subtask。</p><p>假设，Scheduler要求iter10和iter11是独立的，但是iter11和iter12是添加了依赖的。那么对于其中某个worker来说，他的执行过程就类似于下图<img src="dsd1.png" alt=""></p><p>该worker在iter10的梯度计算后就立刻计算iter11的梯度，然而在iter11的梯度计算完后，却等待push()+pull()两个subtask结束才开始iter12的计算。</p><h2><span id="224-flexible-consistency">2.2.4 Flexible Consistency</span></h2><p>异步task能够提高系统的效率，但是却会造成数据不一致，从而降低算法的收敛速率。</p><p>上例中，该worker在iter10的结果参数被pull()之前就开始计算iter11的梯度，因此他使用的模型参数仍然是，所以iter11计算得到的梯度和iter10相同，这就拖慢了算法的收敛速率。</p><p>但有些算法对于数据的不一致性不那么敏感，因此这需要开发者自行权衡系统性能和算法收敛速率，这就需要考虑：</p><p>算法对于参数非一致性的敏感度训练数据特征之间的关联度硬盘的存储容量</p><h2><span id="225-user-defined-filters">2.2.5 User-defined Filters</span></h2><p>PS所支持的另外一个减少网络带宽的方法是支持用户自定义过滤器来过滤掉那些比较小的被push的entry。</p><p>常用的过滤器有significantly modified filter，即只push大于某一门槛的entry。也有KKT filter，利用最优化问题的一些条件过滤掉对weights影响不大的entry。</p><h2><span id="23-parameter-server的异步性与非凸问题">2.3 parameter server的异步性与非凸问题</span></h2><p>参数服务器模型更新的时候，worker的模型参数与server的模型参数可能有所不一致。</p><p>举例而言，梯度计算需要基于某个特定的参数值（相当于下山，我们只能找到针对特定某点的下山最快的方向，一旦该点变化，则下山最快的方向也就不对了）。问题在于：节点A从server获得参数值后，当计算完梯度后，此时server端的参数值可能已经被节点B所更新了。</p><p>但是在非凸问题（例如深度学习的优化）中，这反而是个好事，引入了随机性。这是因为非凸问题本身就不是梯度下降能够解决的，正常的单机迭代肯定会收敛到局部最优。有时我们常常会用一些额外的方法来跳出局部最优：</p><p>多组参数值初始化模拟退火随机梯度下降而上面所说的PS框架正好利用异步性引入了随机性，有助于跳出局部最优。因此在Google的DistBelief框架中，提出了Downpour SGD算法，就是尽最大可能利用了这种随机性。</p><h2><span id="241-vector-clock">2.4.1 Vector Clock</span></h2><p>PS使用vector clock来记录每个节点的参数，用来跟踪数据状态或避免数据重复发送。但假设有n个节点，m个参数，那么vector clock的空间复杂度就是O(nm)，无法承受。</p><p>幸运的是，parameter server在push和pull的时候，都是range-based，因此这个range里参数共享的是同一个时间戳，这就降低了复杂度（具体实现见下面ps-lite源码剖析）。</p><h2><span id="242-messages">2.4.2 Messages</span></h2><p>一条message包括时间戳，和(k,v)对。但是由于机器学习问题频繁的参数访问，导致信息的压缩是必然的。有两种优化来压缩网络带宽：</p><p>key的压缩：因为训练数据在分配之后通常不会改变，因此worker没必要每次都发送相同的key，只需要在接受方第一次接收时缓存起来即可。后续只需发送value用户自定义的过滤器：有些参数更新并非对最终优化有价值，因此用户可以自定义过滤规则来过滤掉一些不必要的传送。例如对于梯度下降来说，很小的梯度值是低效的，可以忽略；同样当更新接近最优的时候，值也是低效的，可以忽略。（这个通过KKT条件来判断）2.4.3 Replication and ConsistencyPS在数据一致性方面，使用的是一致性哈希算法，然后每个节点备份其逆时针的k个节点的参数。</p><p>一致性哈希算法：即将数据按照某种hash算法映射到环上，然后将机器按照同样的hash算法映射到环上，将数据存储到环上顺时针最近的机器上。</p><p><img src="css.png" alt=""></p><p>如图，k=3，则S2，S3和S4复制了S1的参数。</p><h1><span id="第二章-参数服务器设计理念与基本架构">第二章 参数服务器设计理念与基本架构</span></h1><h1><span id="第三章-pslite的分析">第三章 pslite的分析</span></h1><h1><span id="第四章-tensorflow-ps分析">第四章 tensorflow ps分析</span></h1><h1><span id="第五章-angel-ps分析">第五章 angel ps分析</span></h1><h1><span id="第六章-实现参数服务器">第六章 实现参数服务器</span></h1><h1><span id="第七章-调度框架的简要分析">第七章 调度框架的简要分析</span></h1><h1><span id="第八章-对参数服务器的思考和展望">第八章 对参数服务器的思考和展望</span></h1><h1><span id="引用">引用</span></h1><ol><li>Wide &amp; Deep Learning for Recommender Systems</li><li>Deep Neural Networks for YouTube Recommendations</li><li>https://www.zhihu.com/question/53851014</li><li>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</li><li>http://www.jianshu.com/p/00736aa21dc8</li><li>Large Scale Distributed Deep Networks</li><li>MapReduce: Simplified Data Processing on Large Clusters</li><li>Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</li><li>https://www.zhihu.com/question/55119470</li><li>KunPeng: Parameter Server based Distributed Learning Systems and Its Applications in Alibaba and Ant Financial</li><li>An Architecture for Parallel Topic Models</li><li>Scaling Distributed Machine Learning with the Parameter Server</li><li>Piccolo: Building fast, distributed pro- grams with partitioned tables</li><li>More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server</li><li>Angel-A Flexible and Powerful Parameter Server；黄明 ppt</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;parameter-server技术内幕&quot;&gt;parameter server技术内幕&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;深入解析parameter server架构设计与实现原理&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;第一章-回顾分
      
    
    </summary>
    
    
      <category term="参数服务器" scheme="http://www.yifanguo.top/tags/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>在线最优化求解</title>
    <link href="http://www.yifanguo.top/2018/10/23/%E5%9C%A8%E7%BA%BF%E6%9C%80%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3/"/>
    <id>http://www.yifanguo.top/2018/10/23/在线最优化求解/</id>
    <published>2018-10-22T18:09:32.000Z</published>
    <updated>2018-10-24T02:00:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>SGD或L-BFGS</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SGD或L-BFGS&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="online learning" scheme="http://www.yifanguo.top/tags/online-learning/"/>
    
  </entry>
  
  <entry>
    <title>ftrl</title>
    <link href="http://www.yifanguo.top/2018/10/23/ftrl/"/>
    <id>http://www.yifanguo.top/2018/10/23/ftrl/</id>
    <published>2018-10-22T18:01:48.000Z</published>
    <updated>2018-10-23T09:08:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="ftrl-follow-the-regularized-leader">FTRL -- Follow the Regularized Leader</span></h1><h1><span id="背景">背景</span></h1><p>在工业界，越来越多的业务需要大规模机器学习，不单参与训练的数据量大，模型特征量的规模也大。例如点击率预估，训练数据量在TB量级，特征量在亿这个量级，业内常用LR（Logistic Regression）和FM（Factorization Machines）为点击率预估建模。对LR、FM这类模型的参数学习，传统的学习算法是batch learning算法，它无法有效地处理大规模的数据集，也无法有效地处理大规模的在线数据流。这时，有效且高效的online learning算法显得尤为重要。</p><pre><code>   SGD算法[1]是常用的online learning算法，它能学习出不错的模型，但学出的模型不是稀疏的。为此，学术界和工业界都在研究这样一种online learning算法，它能学习出有效的且稀疏的模型。FTRL（Follow the Regularized Leader）算法正是这样一种算法，它由Google的H. Brendan McMahan在2010年提出的[2]，后来在2011年发表了一篇关于FTRL和AOGD、FOBOS、RDA比较的论文[3]，2013年又和Gary Holt, D. Sculley, Michael Young等人发表了一篇关于FTRL工程化实现的论文[4]。如论文[4]的内容所述，FTRL算法融合了RDA算法能产生稀疏模型的特性和SGD算法能产生更有效模型的特性。它在处理诸如LR之类的带非光滑正则化项（例如1范数，做模型复杂度控制和稀疏化）的凸优化问题上性能非常出色，国内各大互联网公司都已将该算法应用到实际产品中。   文章[5]是篇很好的介绍FTRL算法的中文资料，从TG算法、FOBOS算法开始，到RDA算法，最后到FTRL算法，一脉相承，而且各个算法都有推导过程，值得认真体会。   这篇文章不会赘述文章[5]中的内容，而是介绍FTRL算法与SGD算法之间存在的另一种联系。这个联系在网络上似乎没有文章介绍，可能是因为这个细节不那么重要，但倘若了解了此细节，能更好的体会到FTRL算法为啥跟SGD算法有联系。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;ftrl-follow-the-regularized-leader&quot;&gt;FTRL -- Follow the Regularized Leader&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;在工业界
      
    
    </summary>
    
    
      <category term="ftrl" scheme="http://www.yifanguo.top/tags/ftrl/"/>
    
  </entry>
  
  <entry>
    <title>socket</title>
    <link href="http://www.yifanguo.top/2018/10/22/socket/"/>
    <id>http://www.yifanguo.top/2018/10/22/socket/</id>
    <published>2018-10-21T20:33:40.000Z</published>
    <updated>2018-10-22T11:50:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="socket是什么">socket是什么</span></h1><p><img src="socket.png" alt=""></p><p>Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议</p><p><img src="server.png" alt=""></p><p>先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。</p><h1><span id="网络中进程之间如何通信">网络中进程之间如何通信</span></h1><p>本地的进程间通信（IPC）有很多种方式，但可以总结为下面4类：</p><ul><li>消息传递（管道、FIFO、消息队列）</li><li>同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）</li><li>共享内存（匿名的和具名的）</li><li>远程过程调用（Solaris门和Sun RPC）</li></ul><p>但这些都不是本文的主题！我们要讨论的是网络中进程之间如何通信？首要解决的问题是如何唯一标识一个进程，否则通信无从谈起！在本地可以通过进程PID来唯一标识一个进程，但是在网络中这是行不通的。其实TCP/IP协议族已经帮我们解决了这个问题，网络层的“ip地址”可以唯一标识网络中的主机，而传输层的“协议+端口”可以唯一标识主机中的应用程序（进程）。这样利用三元组（ip地址，协议，端口）就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互。</p><p>使用TCP/IP协议的应用程序通常采用应用编程接口：UNIX BSD的套接字（socket）和UNIX System V的TLI（已经被淘汰），来实现网络进程之间的通信。就目前而言，几乎所有的应用程序都是采用socket，而现在又是网络时代，网络中进程通信是无处不在，这就是我为什么说“一切皆socket”</p><h1><span id="什么是socket">什么是socket</span></h1><p>上面我们已经知道网络中的进程是通过socket来通信的，那什么是socket呢？socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭</p><h1><span id="socket的基本操作">socket的基本操作</span></h1><p>既然socket是“open—write/read—close”模式的一种实现，那么socket就提供了这些操作对应的函数接口。下面以TCP为例，介绍几个基本的socket接口函数</p><h2><span id="31-socket函数">3.1 socket()函数</span></h2><p>int socket(int domain, int type, int protocol);</p><p>socket函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而socket()用于创建一个socket描述符（socket descriptor），它唯一标识一个socket。这个socket描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。</p><p>正如可以给fopen的传入不同参数值，以打开不同的文件。创建socket的时候，也可以指定不同的参数创建不同的socket描述符，socket函数的三个参数分别为：</p><ul><li>domain：即协议域，又称为协议族（family）。常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。</li><li>type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等（socket的类型有哪些？）。</li><li>protocol：故名思意，就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议</li></ul><p>注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。</p><p>当我们调用socket创建一个socket时，返回的socket描述字它存在于协议族（address family，AF_XXX）空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用bind()函数，否则就当调用connect()、listen()时系统会自动随机分配一个端口</p><h2><span id="32-bind函数">3.2 bind()函数</span></h2><p>int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</p><p>通常服务器在启动的时候都会绑定一个众所周知的地址（如ip地址+端口号），用于提供服务，客户就可以通过它来接连服务器；而客户端就不用指定，有系统自动分配一个端口号和自身的ip地址组合。这就是为什么通常服务器端在listen之前会调用bind()，而客户端就不会调用，而是在connect()时由系统随机生成一个</p><h2><span id="33-listen-connect函数">3.3 listen()、connect()函数</span></h2><p>如果作为一个服务器，在调用socket()、bind()之后就会调用listen()来监听这个socket，如果客户端这时调用connect()发出连接请求，服务器端就会接收到这个请求。int listen(int sockfd, int backlog);int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</p><p>listen函数的第一个参数即为要监听的socket描述字，第二个参数为相应socket可以排队的最大连接个数。socket()函数创建的socket默认是一个主动类型的，listen函数将socket变为被动类型的，等待客户的连接请求。</p><p>connect函数的第一个参数即为客户端的socket描述字，第二参数为服务器的socket地址，第三个参数为socket地址的长度。客户端通过调用connect函数来建立与TCP服务器的连接。</p><h2><span id="34-accept函数">3.4 accept()函数</span></h2><p>TCP服务器端依次调用socket()、bind()、listen()之后，就会监听指定的socket地址了。TCP客户端依次调用socket()、connect()之后就想TCP服务器发送了一个连接请求。TCP服务器监听到这个请求之后，就会调用accept()函数取接收请求，这样连接就建立好了。之后就可以开始网络I/O操作了，即类同于普通文件的读写I/O操作。</p><p>int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);accept函数的第一个参数为服务器的socket描述字，第二个参数为指向struct sockaddr *的指针，用于返回客户端的协议地址，第三个参数为协议地址的长度。如果accpet成功，那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的TCP连接。</p><p>注意：accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept函数返回的是已连接的socket描述字。一个服务器通常通常仅仅只创建一个监听socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接受的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就被关闭。</p><h1><span id="35-read-write等函数">3.5 read()、write()等函数</span></h1><p>read函数是负责从fd中读取内容.当读成功时，read返回实际所读的字节数，如果返回的值是0表示已经读到文件的结束了，小于0表示出现了错误。如果错误为EINTR说明读是由中断引起的，如果是ECONNREST表示网络连接出了问题。</p><p>write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节 数。失败时返回-1，并设置errno变量。在网络程序中，当我们向套接字文件描述符写时有俩种可能。1)write的返回值大于0，表示写了部分或者是 全部的数据。2)返回的值小于0，此时出现了错误。我们要根据错误类型来处理。如果错误为EINTR表示在写的时候出现了中断错误。如果为EPIPE表示 网络连接出现了问题(对方已经关闭了连接)。</p><p>其它的我就不一一介绍这几对I/O函数了，具体参见man文档或者baidu、Google，下面的例子中将使用到send/recv。</p><h1><span id="36-close函数">3.6 close()函数</span></h1><p>在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的socket描述字，好比操作完打开的文件要调用fclose关闭打开的文件。</p><p>#includeint close(int fd);close一个TCP socket的缺省行为时把该socket标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为read或write的第一个参数。</p><p>注意：close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求。</p><h1><span id="4-socket中tcp的三次握手建立连接详解">4、socket中TCP的三次握手建立连接详解</span></h1><p>我们知道tcp建立连接要进行“三次握手”，即交换三个分组。大致流程如下：</p><p>客户端向服务器发送一个SYN J服务器向客户端响应一个SYN K，并对SYN J进行确认ACK J+1客户端再想服务器发一个确认ACK K+1只有就完了三次握手，但是这个三次握手发生在socket的那几个函数中呢？请看下图：</p><p><img src="shakehands.png" alt=""></p><p>从图中可以看出，当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。</p><p>总结：客户端的connect在三次握手的第二个次返回，而服务器端的accept在三次握手的第三次返回。</p><h1><span id="5-socket中tcp的四次握手释放连接详解">5、socket中TCP的四次握手释放连接详解</span></h1><p>上面介绍了socket中TCP的三次握手建立过程，及其涉及的socket函数。现在我们介绍socket中的四次握手释放连接的过程，请看下图：</p><p><img src="offhands.png" alt=""></p><p>图示过程如下：</p><ul><li>某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；</li><li>另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；</li><li>一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；</li><li>接收到这个FIN的源发送端TCP对它进行确认。这样每个方向上都有一个FIN和ACK。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;socket是什么&quot;&gt;socket是什么&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;socket.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实
      
    
    </summary>
    
    
      <category term="socket" scheme="http://www.yifanguo.top/tags/socket/"/>
    
  </entry>
  
  <entry>
    <title>xgboost</title>
    <link href="http://www.yifanguo.top/2018/10/17/xgboost/"/>
    <id>http://www.yifanguo.top/2018/10/17/xgboost/</id>
    <published>2018-10-17T11:41:44.000Z</published>
    <updated>2018-10-19T02:10:13.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="xgboost" scheme="http://www.yifanguo.top/tags/xgboost/"/>
    
  </entry>
  
  <entry>
    <title>lightgbm</title>
    <link href="http://www.yifanguo.top/2018/10/17/lightgbm-0/"/>
    <id>http://www.yifanguo.top/2018/10/17/lightgbm-0/</id>
    <published>2018-10-17T10:49:34.000Z</published>
    <updated>2018-10-18T02:42:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="background">background</span></h1><p>In recent years, with the emergence of big data (in terms of both the number of features and the number of instances), GBDT is facing new challenges, especially in the tradeoff between accuracy and efficiency.</p><h1><span id="why-introduct-lightgbm">why introduct lightgbm</span></h1><p>A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming.</p><h1><span id="what-is-lightgbm">what is lightgbm</span></h1><p>GOSS: Gradient-based One-Side SamplingEFB: Exclusive Feature Bundling</p><h1><span id="goss">GOSS</span></h1><p>ince the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size.</p><h1><span id="efb">EFB</span></h1><p>With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features.</p><h1><span id="gbdt">GBDT</span></h1><p>GBDT is an ensemble model of decision trees,In each iteration, GBDT learns the decision trees by fitting the negative gradients (also known as residual errors).</p><p>The main cost in GBDT lies in learning the decision trees, and the most time-consuming part in learning a decision tree is to find the best split points</p><h1><span id="goss-implementaion">GOSS implementaion</span></h1><p>GOSS keeps all the instances with large gradients and performs random sampling on the instances with small gradients.</p><p><img src="/Users/yifanguo/Desktop/xgb.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;background&quot;&gt;background&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;In recent years, with the emergence of big data (in terms of both the number of features
      
    
    </summary>
    
    
      <category term="lightgbm" scheme="http://www.yifanguo.top/tags/lightgbm/"/>
    
  </entry>
  
  <entry>
    <title>lightGBM on spark</title>
    <link href="http://www.yifanguo.top/2018/10/08/mmlSpark/"/>
    <id>http://www.yifanguo.top/2018/10/08/mmlSpark/</id>
    <published>2018-10-07T18:28:18.000Z</published>
    <updated>2018-10-12T07:44:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1><span id="lightgbm-on-spark-参数配置">LightGBM on Spark 参数配置</span></h1><h1><span id="官方参数说明">官方参数说明</span></h1><p>http://lightgbm.apachecn.org/cn/latest/Parameters.html</p><h1><span id="工程地址">工程地址</span></h1><p>https://g.hz.netease.com/guoyifan01/lightgbmOnSpark</p><h1><span id="configuration">configuration</span></h1><h2><span id="通用">通用</span></h2><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>prePartition</td><td>is_pre_partition</td><td>True</td><td>bool</td><td>true 如果训练数据 pre-partitioned, 不同的机器使用不同的分区</td></tr><tr><td>boostingType</td><td>boosting_type</td><td>gbdt</td><td>string</td><td>gbdt,rf, dart, goss</td></tr><tr><td>parallelism</td><td>tree_learner</td><td>data_parallel</td><td>string</td><td>数据并行的 tree learner</td></tr><tr><td>defaultListenPort</td><td>无</td><td>12400</td><td>int</td><td>The default listen port on executors, used for testing</td></tr><tr><td>numIterations</td><td>num_iterations</td><td>100</td><td>int</td><td>boosting 的迭代次数</td></tr><tr><td>learningRate</td><td>learning_rate</td><td>0.1</td><td>double</td><td>学习率</td></tr><tr><td>numLeaves</td><td>num_leaves</td><td>31</td><td>int</td><td>一棵树上的叶子数</td></tr><tr><td>maxBin</td><td>max_bin</td><td>255</td><td>int</td><td>工具箱的最大数特征值决定了容量 工具箱的最小数特征值可能会降低训练的准确性, 但是可能会增加一些一般的影响（处理过度学习）LightGBM 将根据 max_bin 自动压缩内存。 例如, 如果 maxbin=255, 那么 LightGBM 将使用 uint8t 的特性值</td></tr><tr><td>baggingFraction</td><td>bagging_fraction</td><td>1.0</td><td>double</td><td>类似于 feature_fraction, 但是它将在不进行重采样的情况下随机选择部分数据 可以用来加速训练 可以用来处理过拟合 Note: 为了启用 bagging, bagging_freq 应该设置为非零值</td></tr><tr><td>baggingFreq</td><td>bagging_freq</td><td>0</td><td>int</td><td>bagging 的频率, 0 意味着禁用 bagging. k 意味着每 k 次迭代执行bagging Note: 为了启用 bagging, bagging_fraction 设置适当</td></tr><tr><td>baggingSeed</td><td>bagging_seed</td><td>3</td><td>int</td><td>Bagging seed</td></tr><tr><td>earlyStoppingRound</td><td>early_stopping_round</td><td>0</td><td>int</td><td>Early stopping round</td></tr><tr><td>featureFraction</td><td>feature_fraction</td><td>1.0</td><td>double</td><td>Feature fraction</td></tr><tr><td>maxDepth</td><td>max_depth</td><td>-1</td><td>int</td><td>-1意味着没有限制</td></tr><tr><td>minSumHessianInLeaf</td><td>min_sum_hessian_in_leaf</td><td>1e-3</td><td>Double</td><td>Minimal sum hessian in one leaf</td></tr><tr><td>无</td><td>num_machines</td><td>1</td><td>int</td><td>并行运行的机器数量，在spark上，有多少个executor就有多少个机器</td></tr><tr><td>timeout</td><td>无</td><td>120s</td><td>second</td><td>socket超时</td></tr><tr><td>objective</td><td>application</td><td>regression</td><td>enum</td><td>regression, regression_l1, huber, fair, poisson, quantile, quantile_l2, binary, multiclass, multiclassova, xentropy, xentlambda, lambdarank</td></tr><tr><td>min_data_in_leaf</td><td>min_data_in_leaf</td><td>20</td><td>int</td><td>min_data_in_leaf</td></tr><tr><td>min_data_in_bin</td><td>min_data_in_bin</td><td>3</td><td>int</td><td>min_data_in_bin</td></tr><tr><td>lambda_l1</td><td>lambda_l1</td><td>0</td><td>double</td><td>lambda_l1</td></tr><tr><td>lambda_l2</td><td>lambda_l2</td><td>0</td><td>double</td><td>lambda_l2</td></tr><tr><td>modelString</td><td>无</td><td>“”</td><td>String</td><td>model存成String格式</td></tr></tbody></table><p>##分类</p><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>无</td><td>metric</td><td>binary_logloss,auc</td><td>String</td><td>度量</td></tr></tbody></table><p>##回归</p><table><thead><tr><th>parameter</th><th>lightgbm param</th><th>default</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>alpha</td><td>alpha</td><td>0.9</td><td>double</td><td>Huber loss 和 Quantile regression 的参数. 将用于 regression 任务</td></tr><tr><td>tweedieVariancePower</td><td>tweedie_variance_power</td><td>1.5</td><td>double</td><td>control the variance of tweedie distribution, must be between 1 and 2</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;lightgbm-on-spark-参数配置&quot;&gt;LightGBM on Spark 参数配置&lt;/span&gt;&lt;/h1&gt;
&lt;h1&gt;&lt;span id=&quot;官方参数说明&quot;&gt;官方参数说明&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;http://lig
      
    
    </summary>
    
    
      <category term="ml" scheme="http://www.yifanguo.top/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM</title>
    <link href="http://www.yifanguo.top/2018/10/08/LightGBM/"/>
    <id>http://www.yifanguo.top/2018/10/08/LightGBM/</id>
    <published>2018-10-07T17:07:39.000Z</published>
    <updated>2018-10-08T08:08:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="light-gbm">light gbm</span></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;light-gbm&quot;&gt;light gbm&lt;/span&gt;&lt;/h1&gt;

      
    
    </summary>
    
    
      <category term="ml" scheme="http://www.yifanguo.top/tags/ml/"/>
    
  </entry>
  
</feed>
